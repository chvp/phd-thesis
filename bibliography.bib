@article{abutairMiningEducationalData2012,
  title = {Mining Educational Data to Improve Students' Performance: A Case Study},
  shorttitle = {Mining Educational Data to Improve Students' Performance},
  author = {Abu Tair, Mohammed M. and {El-Halees}, Alaa M.},
  year = {2012},
  journal = {International Journal of Information},
  volume = {Volume: 2, Number: 2},
  number = {Volume: 2, Number: 2},
  url = {https://iugspace.iugaza.edu.ps/handle/20.500.12358/25066},
  urldate = {2021-09-20},
  abstract = {Educational data mining concerns with developing methods for discovering knowledge from data that come from educational domain. In this paper we used educational data mining to improve graduate students' performance, and overcome the problem of low grades of graduate students. In our case study we try to extract useful knowledge from graduate students data collected from the college of Science and Technology--Khanyounis. The data include fifteen years period [1993-2007]. After preprocessing the data, we applied data mining techniques to discover association, classification, clustering and outlier detection rules. In each of these four tasks, we present the extracted knowledge and describe its importance in educational domain.},
  copyright = {Creative Commons (CC-BY)},
  langid = {english},
  annotation = {Accepted: 2018-11-19T09:24:34Z},
  file = {/home/charlotte/sync/Zotero/storage/UTI4XVZ2/Abu Tair and El-Halees - 2012 - Mining educational data to improve students' perfo.pdf;/home/charlotte/sync/Zotero/storage/II5LNING/25066.html}
}

@article{akcapinarUsingLearningAnalytics2019,
  title = {Using Learning Analytics to Develop Early-Warning System for at-Risk Students},
  author = {Ak{\c c}ap{\i}nar, G{\"o}khan and Altun, Arif and A{\c s}kar, Petek},
  year = {2019},
  month = oct,
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {16},
  number = {1},
  pages = {40},
  issn = {2365-9440},
  doi = {10.1186/s41239-019-0172-z},
  url = {https://doi.org/10.1186/s41239-019-0172-z},
  urldate = {2024-02-14},
  abstract = {In the current study interaction data of students in an online learning setting was used to research whether the academic performance of students at the end of term could be predicted in the earlier weeks. The study was carried out with 76\,second-year university students registered in a Computer Hardware course. The study aimed to answer two principle questions: which algorithms and features best predict the end of term academic performance of students by comparing different classification algorithms and pre-processing techniques and whether or not academic performance can be predicted in the earlier weeks using these features and the selected algorithm. The results of the study indicated that the kNN algorithm accurately predicted unsuccessful students at the end of term with a rate of 89\%. When findings were examined regarding the analysis of data obtained in weeks 3, 6, 9, 12,~and 14~to predict whether the end-of-term academic performance of students could be predicted in the earlier weeks, it was observed that students who were unsuccessful at the end of term could be predicted with a rate of 74\% in as short as 3\,weeks' time. The findings obtained from this study are important for the determination of features for early warning systems that can be developed for online learning systems and as indicators of student success. At the same time, it will aid researchers in the selection of algorithms and pre-processing techniques in the analysis of educational data.},
  langid = {english},
  keywords = {Academic performance prediction,At-risk students,Early-warning systems,Educational data mining,Learning analytics,Online learning},
  file = {/home/charlotte/sync/Zotero/storage/C58SJ23T/Akçapınar et al. - 2019 - Using learning analytics to develop early-warning .pdf;/home/charlotte/sync/Zotero/storage/RMSJIVAI/10.1186@s41239-019-0172-z.pdf.pdf}
}

@article{akcayirFlippedClassroomReview2018,
  title = {The Flipped Classroom: {{A}} Review of Its Advantages and Challenges},
  shorttitle = {The Flipped Classroom},
  author = {Ak{\c c}ay{\i}r, G{\"o}k{\c c}e and Ak{\c c}ay{\i}r, Murat},
  year = {2018},
  month = nov,
  journal = {Computers \& Education},
  volume = {126},
  pages = {334--345},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2018.07.021},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131518302045},
  urldate = {2022-08-16},
  abstract = {This study presents a large-scale systematic review of the literature on the flipped classroom, with the goals of examining its reported advantages and challenges for both students and instructors, and to note potentially useful areas of future research on the flipped model's in and out-of-class activities. The full range of Social Sciences Citation Indexed journals was surveyed through the Web of Science site, and a total of 71 research articles were selected for the review. The findings reveal that the most frequently reported advantage of the flipped classroom is the improvement of student learning performance. We also found a number of challenges in this model. The majority of these are related to out-of-class activities, such as much reported inadequate student preparation prior to class. Several other challenges and the numerous advantages of the flipped classroom are discussed in detail. We then offer suggestions for future research on flipped model activities.},
  langid = {english},
  keywords = {Improving classroom teaching,Teaching/learning strategies},
  file = {/home/charlotte/sync/Zotero/storage/A7LBQIEQ/Akçayır and Akçayır - 2018 - The flipped classroom A review of its advantages .pdf;/home/charlotte/sync/Zotero/storage/A6Q8IY3R/S0360131518302045.html}
}

@article{ala-mutkaSurveyAutomatedAssessment2005,
  title = {A {{Survey}} of {{Automated Assessment Approaches}} for {{Programming Assignments}}},
  author = {{Ala-Mutka}, Kirsti M},
  year = {2005},
  month = jun,
  journal = {Computer Science Education},
  volume = {15},
  number = {2},
  pages = {83--102},
  publisher = {{Routledge}},
  issn = {0899-3408},
  doi = {10.1080/08993400500150747},
  url = {https://doi.org/10.1080/08993400500150747},
  urldate = {2022-08-16},
  abstract = {Practical programming is one of the basic skills pursued in computer science education. On programming courses, the coursework consists of programming assignments that need to be assessed from different points of view. Since the submitted assignments are executable programs with a formal structure, some features can be assessed automatically. The basic requirement for automated assessment is the numerical measurability of assessment targets, but semiautomatic approaches can overcome this restriction. Recognizing automatically assessable features can help teachers to create educational models, where automatic tools let teachers concentrate their work on the learning issues that need student-teacher interaction the most. Several automatic tools for both static and dynamic assessment of computer programs have been reported in the literature. This article promotes these issues by surveying several automatic approaches for assessing programming assignments. Not all the existing tools will be covered, simply because of the vast number of them. The article concentrates on bringing forward different assessment techniques and approaches to give an interested reader starting points for finding further information in the area. Automatic assessment tools can be used to help teachers in grading tasks as well as to support students' working process with automatic feedback. Common advantages of automation are the speed, availability, consistency and objectivity of assessment. However, automatic tools emphasize the need for careful pedagogical design of the assignment and assessment settings. To effectively share the knowledge and good assessment solutions already developed, better interoperability and portability of the tools is needed.}
}

@inproceedings{albashairehSurveyOnlineLearning2018,
  title = {A {{Survey}} of {{Online Learning Platforms}} with {{Initial Investigation}} of {{Situation-Awareness}} to {{Facilitate Programming Education}}},
  booktitle = {2018 {{International Conference}} on {{Computational Science}} and {{Computational Intelligence}} ({{CSCI}})},
  author = {Albashaireh, Rasha and Ming, Hua},
  year = {2018},
  month = dec,
  pages = {631--637},
  doi = {10.1109/CSCI46756.2018.00126},
  url = {https://ieeexplore.ieee.org/abstract/document/8947659},
  urldate = {2023-10-02},
  abstract = {With the advancement of today's ubiquitous technology, and due to the increasing number of technologies supported by the Internet, a variety of Online Learning Platforms have rapidly grown as modern learning methods. This fast-emerging learning option interests researchers to study and investigate the main features and functionality of the most popular Online Learning Platforms. This paper surveys the state-of-the-art Online Learning Platforms that aim to teach computer programming, in terms of principles, design, and implementations. In addition, the paper investigates the feasibility of incorporating human-oriented Situation-Awareness as the driving factor to facilitate the delivery of improved user learning experiences.},
  file = {/home/charlotte/sync/Zotero/storage/T767PWYN/Albashaireh and Ming - 2018 - A Survey of Online Learning Platforms with Initial.pdf;/home/charlotte/sync/Zotero/storage/P34UIQEK/8947659.html}
}

@inproceedings{alfadelUseDependabotSecurity2021,
  title = {On the {{Use}} of {{Dependabot Security Pull Requests}}},
  booktitle = {2021 {{IEEE}}/{{ACM}} 18th {{International Conference}} on {{Mining Software Repositories}} ({{MSR}})},
  author = {Alfadel, Mahmoud and Costa, Diego Elias and Shihab, Emad and Mkhallalati, Mouafak},
  year = {2021},
  month = may,
  pages = {254--265},
  issn = {2574-3864},
  doi = {10.1109/MSR52588.2021.00037},
  abstract = {Vulnerable dependencies are a major problem in modern software development. As software projects depend on multiple external dependencies, developers struggle to constantly track and check for corresponding security vulnerabilities that affect their project dependencies. To help mitigate this issue, Dependabot has been created, a bot that issues pull-requests to automatically update vulnerable dependencies. However, little is known about the degree to which developers adopt Dependabot to help them update vulnerable dependencies.In this paper, we investigate 2,904 JavaScript open-source GitHub projects that subscribed to Dependabot. Our results show that the vast majority (65.42\%) of the created security-related pull-requests are accepted, often merged within a day. Through manual analysis, we identify 7 main reasons for Dependabot security pull-requests not being merged, mostly related to concurrent modifications of the affected dependencies rather than Dependabot failures. Interestingly, only 3.2\% of the manually examined pull-requests suffered from build breakages. Finally, we model the time it takes to merge a Dependabot security pull-request using characteristics from projects, the fixed vulnerabilities and issued pull requests. Our model reveals 5 significant features to explain merge times, e.g., projects with relevant experience with Dependabot security pull-requests are most likely associated with rapid merges. Surprisingly, the severity of the dependency vulnerability and the potential risk of breaking changes are not strongly associated with the merge time. To the best of our knowledge, this study is the first to evaluate how developers receive Dependabot's security contributions. Our findings indicate that Dependabot provides an effective platform for increasing awareness of dependency vulnerabilities and helps developers mitigate vulnerability threats in JavaScript projects.},
  keywords = {Data mining,Dependabot,dependency,Manuals,Open source software,pull request,Security,security vulnerability,Software development management},
  file = {/home/charlotte/sync/Zotero/storage/UWVKGK2D/Alfadel et al. - 2021 - On the Use of Dependabot Security Pull Requests.pdf;/home/charlotte/sync/Zotero/storage/398DZ2EZ/9463148.html}
}

@article{andersonFairnessReactionsPersonnel2008,
  title = {Fairness {{Reactions}} to {{Personnel Selection Methods}}: {{An}} International Comparison between the {{Netherlands}}, the {{United States}}, {{France}}, {{Spain}}, {{Portugal}}, and {{Singapore}}},
  shorttitle = {Fairness {{Reactions}} to {{Personnel Selection Methods}}},
  author = {Anderson, Neil and Witvliet, Carlijn},
  year = {2008},
  journal = {International Journal of Selection and Assessment},
  volume = {16},
  number = {1},
  pages = {1--13},
  issn = {1468-2389},
  doi = {10.1111/j.1468-2389.2008.00404.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-2389.2008.00404.x},
  urldate = {2021-04-30},
  abstract = {This paper reports reactions to employee selection methods in the Netherlands and compares these findings internationally against six other previously published samples covering the United States, France, Spain, Portugal, and Singapore. A sample of 167 participants rated 10 popular assessment techniques using a translated version of Steiner and Gilliland's measure. In common with other country samples, we found that the most popular methods among applicants were interviews, work sample tests, and resumes. Least popular methods were graphology, personal contacts, and honesty and integrity tests. Generally, method favorability was found to be highly similar to the US and other published studies internationally. Across the six countries mean process favorability correlated at .87 and mean cross-national procedural justice correlated .68. Process dimension ratings correlated at between .79 and .97 between the United States and the Netherlands. Only medium effect size differences (Cohen's d) were found between Dutch and US reactions to resumes and personality tests, the former being more favorably rated in the United States (d=.62) and the latter being more positively rated in the Netherlands (d=-.76). Implications for the design of selection procedures are discussed, especially implications for likely similarities and differences in applicant reactions internationally.},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/5B4GS4EW/Anderson and Witvliet - 2008 - Fairness Reactions to Personnel Selection Methods.pdf;/home/charlotte/sync/Zotero/storage/9ENV6EED/j.1468-2389.2008.00404.html}
}

@article{andrade-arenasUniversityLearningStyle2023,
  title = {University Learning Style Model: {{Bibliometrics}} and Systematic Literature Review},
  shorttitle = {University Learning Style Model},
  author = {{Andrade-Arenas}, Laberiano and Bogdanovich, Mar{\'i}a Mini Martin and Celis, Domingo Hern{\'a}ndez and Jaico, Katerine Romero and Pe{\~n}a, Gustavo Bernnet Alfaro},
  year = {2023},
  month = dec,
  journal = {International Journal of Evaluation and Research in Education (IJERE)},
  volume = {12},
  number = {4},
  pages = {2302--2315},
  issn = {2620-5440},
  doi = {10.11591/ijere.v12i4.25859},
  url = {https://ijere.iaescore.com/index.php/IJERE/article/view/25859},
  urldate = {2023-12-04},
  abstract = {The university learning style worldwide was analyzed to obtain a model adapted to Peru, that was complemented in the initial part with the study of the biliometric analysis. In the first steps that were developed, the information search was done in a general way with Scopus. Then specifically adding the Dimensions database, obtaining 59 items from the selection. The Prism statement was used, which allowed it to be developed in the methodology sequentially until the selected articles were obtained. The objective was to carry out a study of the systematic review of the literature (RSL) that allowed analysis by categories such as academic performance, teaching strategy and competencies related to the learning style. Where the data obtained was with the use of VOSviewer and Rstudio. The result obtained was an innovative model that relates the categories with the most relevant models that studied the learning style. As a conclusion, the different learning styles can be adapted to the different study programs and their different courses to plan it from the macrocurricular to the microcurricular, taking into account the strategy and the didactics of teaching, the contribution for the university sector.},
  copyright = {Copyright (c) 2023 Institute of Advanced Engineering and Science},
  langid = {english},
  keywords = {Academic performance,Competencies,Learning style,Prism statement,Teaching strategy},
  file = {/home/charlotte/sync/Zotero/storage/BYGS8IMH/Andrade-Arenas et al. - 2023 - University learning style model Bibliometrics and.pdf}
}

@article{asaiEfficientSubstructureDiscovery2004,
  title = {Efficient {{Substructure Discovery}} from {{Large Semi-Structured Data}}},
  author = {Asai, Tatsuya and Abe, Kenji and Kawasoe, Shinji and Sakamoto, Hiroshi and Arimura, Hiroki and Arikawa, Setsuo},
  year = {2004},
  month = dec,
  journal = {IEICE TRANSACTIONS on Information and Systems},
  volume = {E87-D},
  number = {12},
  pages = {2754--2763},
  publisher = {{The Institute of Electronics, Information and Communication Engineers}},
  issn = {, 0916-8532},
  url = {https://search.ieice.org/bin/summary.php?id=e87-d_12_2754&category=D&year=2004&lang=E&abst=},
  urldate = {2022-07-06},
  abstract = {In this paper, we consider a data mining problem for semi-structured data. Modeling semi-structured data as labeled ordered trees, we present an efficient algorithm for discovering frequent substructures from a large collection of semi-structured data. By extending the enumeration technique developed by Bayardo (SIGMOD'98) for discovering long itemsets, our algorithm scales almost linearly in the total size of maximal tree patterns contained in an input collection depending mildly on the size of the longest pattern. We also developed several pruning techniques that significantly speed-up the search. Experiments on Web data show that our algorithm runs efficiently on real-life datasets combined with proposed pruning techniques in the wide range of parameters.},
  file = {/home/charlotte/sync/Zotero/storage/I46PGVCC/Asai et al. - 2004 - Efficient Substructure Discovery from Large Semi-S.pdf;/home/charlotte/sync/Zotero/storage/PNH8LAUL/summary.html}
}

@article{asifAnalyzingUndergraduateStudents2017,
  title = {Analyzing Undergraduate Students' Performance Using Educational Data Mining},
  author = {Asif, Raheela and Merceron, Agathe and Ali, Syed Abbas and Haider, Najmi Ghani},
  year = {2017},
  month = oct,
  journal = {Computers \& Education},
  volume = {113},
  pages = {177--194},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2017.05.007},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131517301124},
  urldate = {2021-02-19},
  abstract = {The tremendous growth in electronic data of universities creates the need to have some meaningful information extracted from these large volumes of data. The advancement in the data mining field makes it possible to mine educational data in order to improve the quality of the educational processes. This study, thus, uses data mining methods to study the performance of undergraduate students. Two aspects of students' performance have been focused upon. First, predicting students' academic achievement at the end of a four-year study programme. Second, studying typical progressions and combining them with prediction results. Two important groups of students have been identified: the low and high achieving students. The results indicate that by focusing on a small number of courses that are indicators of particularly good or poor performance, it is possible to provide timely warning and support to low achieving students, and advice and opportunities to high performing students.},
  langid = {english},
  keywords = {Clustering,Data mining,Decision trees,Performance prediction,Performance progression,Quality of educational processes},
  file = {/home/charlotte/sync/Zotero/storage/MFBFQAE3/Asif et al. - 2017 - Analyzing undergraduate students' performance usin.pdf;/home/charlotte/sync/Zotero/storage/LMS96U8D/S0360131517301124.html}
}

@article{averySimilarityRankingPython2015,
  title = {A {{Similarity Ranking}} of {{Python Programs}}},
  author = {Avery, Jonathan Wardell},
  year = {2015},
  publisher = {{University of Canterbury}},
  url = {https://ir.canterbury.ac.nz/handle/10092/14446},
  urldate = {2022-07-06},
  abstract = {Detection of similar programs is a highly studied problem. Detecting similar code is an important strategy for detecting badly modularized code, finding vulnerabilities due to error prone copy-paste programming methodologies, and detecting academic dishonesty in online code assignment submissions following the copy-paste-adapt-it pattern. The latter is the impetus for this work. A novel system is presented that is specifically adapted to programs that may be small, and similar by virtue of being written to solve the same problem. The system is also adapted toward specific expected behaviors of plagiarists, making use of algorithms custom built to both recognize these behaviors while satisfying hierarchical properties. A defining and novel property of the proposed method is the categorical information it provides. A hierarchy of categories with an implication relationship are leveraged in the production of descriptive, rank-able results.},
  copyright = {All Right Reserved},
  langid = {english},
  annotation = {Accepted: 2017-10-03T02:53:23Z},
  file = {/home/charlotte/sync/Zotero/storage/3SWAEQHJ/Avery - 2015 - A Similarity Ranking of Python Programs.pdf;/home/charlotte/sync/Zotero/storage/83HXZXCM/14446.html}
}

@article{bakerStateEducationalData2009,
  title = {The {{State}} of {{Educational Data Mining}} in 2009: {{A Review}} and {{Future Visions}}},
  shorttitle = {The {{State}} of {{Educational Data Mining}} in 2009},
  author = {Baker, Ryan SJD and Yacef, Kalina},
  year = {2009},
  month = oct,
  journal = {Journal of Educational Data Mining},
  volume = {1},
  number = {1},
  pages = {3--17},
  issn = {2157-2100},
  doi = {10.5281/zenodo.3554657},
  url = {https://jedm.educationaldatamining.org},
  urldate = {2021-04-30},
  copyright = {Copyright (c) 2014 JEDM - Journal of Educational Data Mining},
  langid = {english},
  keywords = {clustering,discovery with models,educational data mining,prediction,relationship mining,visualization},
  file = {/home/charlotte/sync/Zotero/storage/49E82ICH/Baker and Yacef - 2009 - The State of Educational Data Mining in 2009 A Re.pdf;/home/charlotte/sync/Zotero/storage/2QTQLSQD/8.html}
}

@article{barabDesignBasedResearchPutting2004,
  title = {Design-{{Based Research}}: {{Putting}} a {{Stake}} in the {{Ground}}},
  shorttitle = {Design-{{Based Research}}},
  author = {Barab, Sasha and Squire, Kurt},
  year = {2004},
  month = jan,
  journal = {Journal of the Learning Sciences},
  volume = {13},
  number = {1},
  pages = {1--14},
  publisher = {{Routledge}},
  issn = {1050-8406},
  doi = {10.1207/s15327809jls1301_1},
  url = {https://doi.org/10.1207/s15327809jls1301_1},
  urldate = {2021-09-15},
  file = {/home/charlotte/sync/Zotero/storage/I5L3SPUC/Barab and Squire - 2004 - Design-Based Research Putting a Stake in the Grou.pdf;/home/charlotte/sync/Zotero/storage/AMUNRJ5E/s15327809jls1301_1.html}
}

@inproceedings{bareissCoachingCognitiveApprenticeship2010,
  title = {Coaching via Cognitive Apprenticeship},
  booktitle = {Proceedings of the 41st {{ACM}} Technical Symposium on {{Computer}} Science Education},
  author = {Bareiss, Ray and Radley, Martin},
  year = {2010},
  month = mar,
  series = {{{SIGCSE}} '10},
  pages = {162--166},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1734263.1734319},
  url = {https://doi.org/10.1145/1734263.1734319},
  urldate = {2022-02-24},
  abstract = {At Carnegie Mellon's Silicon Valley campus we employ a learn-by-doing educational approach in which nearly all student learning, and thus instruction, is in the context of realistic, team-based projects. Consequently, we have adopted coaching as our predominant teaching model. In this paper we reflect on our experience with the nature of teaching by coaching using a framework derived from Cognitive Apprenticeship, and explain how we employ the techniques it suggests in our teaching. We also discuss a range of instructional tensions that arise in teaching by coaching and present a survey of student attitudes regarding the effectiveness of our approach.},
  isbn = {978-1-4503-0006-3},
  keywords = {active learning,cognitive apprenticeship,cs ed research,experience report,graduate studies,information systems,instructional technologies,learning by doing,professional practice,software engineering,story-centered curricula},
  file = {/home/charlotte/sync/Zotero/storage/RHAWWHCQ/Bareiss and Radley - 2010 - Coaching via cognitive apprenticeship.pdf}
}

@inproceedings{barendsenNewInformaticsCurriculum2016,
  title = {A {{New Informatics Curriculum}} for {{Secondary Education}} in {{The Netherlands}}},
  booktitle = {Informatics in {{Schools}}: {{Improvement}} of {{Informatics Knowledge}} and {{Perception}}},
  author = {Barendsen, Erik and Grgurina, Nata{\v s}a and Tolboom, Jos},
  editor = {Brodnik, Andrej and Tort, Fran{\c c}oise},
  year = {2016},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {105--117},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-46747-4_9},
  abstract = {In The Netherlands, the current informatics curriculum for upper secondary education was introduced in 1998 and only slightly modified in 2007. Meanwhile, both the scientific discipline and its impact on society have developed substantially. For this main reason, a curriculum reform has been carried out which has led to a new curriculum specifying the intended learning outcomes. This country report specifies the educational context in which the reform takes place. Moreover, it decribes the reform process from various perspectives, highlights and explains the underlying design principles that guided the development of the new curriculum, and presents its main results.},
  isbn = {978-3-319-46747-4},
  langid = {english},
  keywords = {Curriculum,Informatics,Reform,Secondary education},
  file = {/home/charlotte/sync/Zotero/storage/ENYGLNEI/barendsen2016.pdf.pdf;/home/charlotte/sync/Zotero/storage/UTTBGSTP/Barendsen et al. - 2016 - A New Informatics Curriculum for Secondary Educati.pdf}
}

@article{baresiIntroductionSoftwareTesting2006,
  title = {An {{Introduction}} to {{Software Testing}}},
  author = {Baresi, Luciano and Pezz{\`e}, Mauro},
  year = {2006},
  month = feb,
  journal = {Electronic Notes in Theoretical Computer Science},
  series = {Proceedings of the {{School}} of {{SegraVis Research Training Network}} on {{Foundations}} of {{Visual Modelling Techniques}} ({{FoVMT}} 2004)},
  volume = {148},
  number = {1},
  pages = {89--111},
  issn = {1571-0661},
  doi = {10.1016/j.entcs.2005.12.014},
  url = {https://www.sciencedirect.com/science/article/pii/S1571066106000442},
  urldate = {2022-03-03},
  abstract = {The development of large software systems is a complex and error prone process. Faults might occur at any development stage and they must be identified and removed as early as possible to stop their propagation and reduce verification costs. Quality engineers must be involved in the development process since the very early phases to identify required qualities and estimate their impact on the development process. Their tasks span over the whole development cycle and go beyond the product deployment through maintenance and post mortem analysis. Developing and enacting an effective quality process is not a simple task, but it requires that we integrate many quality-related activities with product characteristics, process organization, available resources and skills, and budget constraints. This paper discusses the main characteristics of a good quality process, then surveys the key testing phases and presents modern functional and model-based testing approaches.},
  langid = {english},
  keywords = {Functional Testing,Integration Testing,Model-based Testing,Software Quality,Software Testing,System and Acceptance Testing},
  file = {/home/charlotte/sync/Zotero/storage/J8N9PBZ7/Baresi and Pezzè - 2006 - An Introduction to Software Testing.pdf;/home/charlotte/sync/Zotero/storage/UHP7GGL3/S1571066106000442.html}
}

@inproceedings{beckerCompilerErrorMessages2019,
  title = {Compiler {{Error Messages Considered Unhelpful}}: {{The Landscape}} of {{Text-Based Programming Error Message Research}}},
  shorttitle = {Compiler {{Error Messages Considered Unhelpful}}},
  booktitle = {Proceedings of the {{Working Group Reports}} on {{Innovation}} and {{Technology}} in {{Computer Science Education}}},
  author = {Becker, Brett A. and Denny, Paul and Pettit, Raymond and Bouchard, Durell and Bouvier, Dennis J. and Harrington, Brian and Kamil, Amir and Karkare, Amey and McDonald, Chris and Osera, Peter-Michael and Pearce, Janice L. and Prather, James},
  year = {2019},
  month = dec,
  series = {{{ITiCSE-WGR}} '19},
  pages = {177--210},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3344429.3372508},
  url = {https://doi.org/10.1145/3344429.3372508},
  urldate = {2022-02-21},
  abstract = {Diagnostic messages generated by compilers and interpreters such as syntax error messages have been researched for over half of a century. Unfortunately, these messages which include error, warning, and run-time messages, present substantial difficulty and could be more effective, particularly for novices. Recent years have seen an increased number of papers in the area including studies on the effectiveness of these messages, improving or enhancing them, and their usefulness as a part of programming process data that can be used to predict student performance, track student progress, and tailor learning plans. Despite this increased interest, the long history of literature is quite scattered and has not been brought together in any digestible form. In order to help the computing education community (and related communities) to further advance work on programming error messages, we present a comprehensive, historical and state-of-the-art report on research in the area. In addition, we synthesise and present the existing evidence for these messages including the difficulties they present and their effectiveness. We finally present a set of guidelines, curated from the literature, classified on the type of evidence supporting each one (historical, anecdotal, and empirical). This work can serve as a starting point for those who wish to conduct research on compiler error messages, runtime errors, and warnings. We also make the bibtex file of our 300+ reference corpus publicly available. Collectively this report and the bibliography will be useful to those who wish to design better messages or those that aim to measure their effectiveness, more effectively.},
  isbn = {978-1-4503-7567-2},
  keywords = {compiler error messages,considered harmful,cs-1,cs1,design guidelines,diagnostic error messages,error messages,hci,human computer interaction,introduction to programming,novice programmers,programming error messages,programming errors,review,run-time errors,survey,syntax errors,warnings},
  file = {/home/charlotte/sync/Zotero/storage/WCKRFVLW/Becker et al. - 2019 - Compiler Error Messages Considered Unhelpful The .pdf}
}

@article{bellConnectivismItsPlace2011,
  title = {Connectivism: {{Its Place}} in {{Theory-Informed Research}} and {{Innovation}} in {{Technology-Enabled Learning}}},
  shorttitle = {Connectivism},
  author = {Bell, Frances},
  year = {2011},
  journal = {International Review of Research in Open and Distributed Learning},
  volume = {12},
  number = {3},
  pages = {98--118},
  publisher = {{Athabasca University Press (AU Press)}},
  issn = {1492-3831},
  doi = {10.19173/irrodl.v12i3.902},
  url = {https://www.erudit.org/en/journals/irrodl/2011-v12-n3-irrodl05132/1067617ar/},
  urldate = {2022-08-16},
  abstract = {The sociotechnical context for learning and education is dynamic and makes great demands on those trying to seize the opportunities presented by emerging technologies. The goal of this paper is to explore certain theories for our plans and actions in technology-enabled learning. Although presented as a successor to previous learning theories, connectivism alone is insufficient to inform learning and its support by technology in an internetworked world. However, because of its presence in massive open online courses (MOOCs), connectivism is influential in the practice of those who take these courses and who wish to apply it in teaching and learning. Thus connectivism is perceived as relevant by its practitioners but as lacking in rigour by its critics. Five scenarios of change are presented with frameworks of different theories to explore the variety of approaches educators can take in the contexts for change and their associated research/evaluation. I argue that the choice of which theories to use depends on the scope and purposes of the intervention, the funding available to resource the research/evaluation, and the experience and philosophical stances of the researchers/practitioners.},
  langid = {english},
  keywords = {activity theory,actor network theory,change management,connectivism,evaluation,implementation,learning,research,social shaping of technology,theory,zone of proximal development},
  file = {/home/charlotte/sync/Zotero/storage/BPH3T7WF/Bell - 2011 - Connectivism Its Place in Theory-Informed Researc.pdf;/home/charlotte/sync/Zotero/storage/W85J63KC/abstract.html}
}

@article{ben-ariConstructivismComputerScience2001,
  title = {Constructivism in {{Computer Science Education}}},
  author = {{Ben-Ari}, Mordechai},
  year = {2001},
  journal = {Journal of Computers in Mathematics and Science Teaching},
  volume = {20},
  number = {1},
  pages = {45--73},
  publisher = {{Association for the Advancement of Computing in Education (AACE)}},
  issn = {0731-9258},
  url = {https://www.learntechlib.org/primary/p/8505/},
  urldate = {2022-02-24},
  abstract = {Constructivism is a theory of learning, which claims that stu-dents construct knowledge rather than merely receive and store knowledge transmitted by the teacher. Constructivism has been extremely influential in science and mathematics education, but much less so in computer science education (CSE). This paper surveys constructivism in the context of CSE, and shows how the theory can supply a theoretical ba-sis for debating issues and evaluating proposals. An analysis of constructivism in computer science education leads to two claims: (a) students do not have an effective model of...},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/4MGZUI2N/8505.html}
}

@inproceedings{benacearleAutomaticGradingProgramming2016,
  title = {Automatic {{Grading}} of {{Programming Exercises}} Using {{Property-Based Testing}}},
  booktitle = {Proceedings of the 2016 {{ACM Conference}} on {{Innovation}} and {{Technology}} in {{Computer Science Education}}},
  author = {Benac Earle, Clara and Fredlund, Lars-{\AA}ke and Hughes, John},
  year = {2016},
  month = jul,
  series = {{{ITiCSE}} '16},
  pages = {47--52},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2899415.2899443},
  url = {https://dl.acm.org/doi/10.1145/2899415.2899443},
  urldate = {2023-10-05},
  abstract = {We present a framework for automatic grading of programming exercises using property-based testing, a form of model-based black-box testing. Models are developed to assess both the functional behaviour of programs and their algorithmic complexity. From the functional correctness model a large number of test cases are derived automatically. Executing them on the body of exercises gives rise to a (partial) ranking of programs, so that a program A is ranked higher than program B if it fails a strict subset of the test cases failed by B. The model for algorithmic complexity is used to compute worst-case complexity bounds. The framework moreover considers code structural metrics, such as McCabe's cyclomatic complexity, giving rise to a composite program grade that includes both functional, non-functional, and code structural aspects. The framework is evaluated in a course teaching algorithms and data structures using Java.},
  isbn = {978-1-4503-4231-5},
  keywords = {automated assessment,java,testing},
  file = {/home/charlotte/sync/Zotero/storage/8EPYGW7V/Benac Earle et al. - 2016 - Automatic Grading of Programming Exercises using P.pdf}
}

@article{bennedsenFailureRatesIntroductory2007,
  title = {Failure Rates in Introductory Programming},
  author = {Bennedsen, Jens and Caspersen, Michael E.},
  year = {2007},
  month = jun,
  journal = {ACM SIGCSE Bulletin},
  volume = {39},
  number = {2},
  pages = {32--36},
  issn = {0097-8418},
  doi = {10.1145/1272848.1272879},
  url = {https://doi.org/10.1145/1272848.1272879},
  urldate = {2021-02-19},
  abstract = {It is a common conception that CS1 is a very difficult course and that failure rates are high. However, until now there has only been anecdotal evidence for this claim. This article reports on a survey among institutions around the world regarding failure rates in introductory programming courses. The article describes the design of the survey and the results. The number of institutions answering the call for data was unfortunately rather low, so it is difficult to make firm conclusions. It is our hope that this article can be the starting point for a systematic collection of data in order to find solid proof of the actual failure and pass rates of CS1.},
  keywords = {CS1,failure rate,introductory programming,pass rate},
  file = {/home/charlotte/sync/Zotero/storage/LQXT69IA/Bennedsen and Caspersen - 2007 - Failure rates in introductory programming.pdf}
}

@inproceedings{bennedsenProgrammingContextModelfirst2004,
  title = {Programming in Context: A Model-First Approach to {{CS1}}},
  shorttitle = {Programming in Context},
  booktitle = {Proceedings of the 35th {{SIGCSE}} Technical Symposium on {{Computer}} Science Education},
  author = {Bennedsen, Jens and Caspersen, Michael E.},
  year = {2004},
  month = mar,
  series = {{{SIGCSE}} '04},
  pages = {477--481},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/971300.971461},
  url = {https://doi.org/10.1145/971300.971461},
  urldate = {2022-02-24},
  abstract = {The recommendations of the Joint Task Force on Computing Curricula 2001 encompass suggestions for an object-first introductory programming course. We have identified conceptual modeling as a lacking perspective in the suggestions for CS1. Conceptual modeling is the defining characteristic of object-orientation and provides a unifying perspective and a pedagogical approach focusing upon the modelling aspects of object-orientation. Reinforcing conceptual modelling as a basis for CS1 provides an appealing course structure based on core elements from a conceptual framework for object-orientation as well as a systematic approach to programming; both of these are a big help to newcomers. The approach has a very positive impact on the number of students passing the course.},
  isbn = {978-1-58113-798-9},
  keywords = {conceptual modelling,CS1,design,objects-first,pedagogy,programming education,systematic programming,UML},
  file = {/home/charlotte/sync/Zotero/storage/IMAEDND9/Bennedsen and Caspersen - 2004 - Programming in context a model-first approach to .pdf}
}

@article{berners-leeWorldWideWeb1992,
  title = {World-{{Wide Web}}: {{The Information Universe}}},
  shorttitle = {World-{{Wide Web}}},
  author = {Berners-Lee, Tim and Cailliau, Robert and Groff, Jean-Fran{\c c}ois and Pollermann, Bernd},
  year = {1992},
  month = jan,
  journal = {Internet Research},
  volume = {2},
  number = {1},
  pages = {52--58},
  publisher = {{MCB UP Ltd}},
  issn = {1066-2243},
  doi = {10.1108/eb047254},
  url = {https://doi.org/10.1108/eb047254},
  urldate = {2024-02-08},
  abstract = {The World-Wide Web (W3) initiative is a practical project designed to bring a global information universe into existence using available technology. This article describes the aims, data model, and protocols needed to implement the ``web'' and compares them with various contemporary systems.},
  file = {/home/charlotte/sync/Zotero/storage/D4DFLNVS/10.1108@eb047254.pdf.pdf;/home/charlotte/sync/Zotero/storage/6X7DIDMX/html.html}
}

@article{berniusMachineLearningBased2022,
  title = {Machine Learning Based Feedback on Textual Student Answers in Large Courses},
  author = {Bernius, Jan Philip and Krusche, Stephan and Bruegge, Bernd},
  year = {2022},
  month = jan,
  journal = {Computers and Education: Artificial Intelligence},
  volume = {3},
  pages = {100081},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2022.100081},
  url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000364},
  urldate = {2024-01-10},
  abstract = {Many engineering disciplines require problem-solving skills, which cannot be learned by memorization alone. Open-ended textual exercises allow students to acquire these skills. Students can learn from their mistakes when instructors provide individual feedback. However, grading these exercises is often a manual, repetitive, and time-consuming activity. The number of computer science students graduating per year has steadily increased over the last decade. This rise has led to large courses that cause a heavy workload for instructors, especially if they provide individual feedback to students. This article presents CoFee, a framework to generate and suggest computer-aided feedback for textual exercises based on machine learning. CoFee utilizes a segment-based grading concept, which links feedback to text segments. CoFee automates grading based on topic modeling and an assessment knowledge repository acquired during previous assessments. A language model builds an intermediate representation of the text segments. Hierarchical clustering identifies groups of similar text segments to reduce the grading overhead. We first demonstrated the CoFee framework in a small laboratory experiment in 2019, which showed that the grading overhead could be reduced by 85\%. This experiment confirmed the feasibility of automating the grading process for problem-solving exercises. We then evaluated CoFee in a large course at the Technical University of Munich from 2019 to 2021, with up to 2, 200 enrolled students per course. We collected data from 34 exercises offered in each of these courses. On average, CoFee suggested feedback for 45\% of the submissions. 92\% (Positive Predictive Value) of these suggestions were precise and, therefore, accepted by the instructors.},
  keywords = {Assessment support system,Automatic assessment,Education,Feedback,Grading,Interactive learning,Learning,Software engineering},
  file = {/home/charlotte/sync/Zotero/storage/UWSG2P4L/Bernius et al. - 2022 - Machine learning based feedback on textual student.pdf;/home/charlotte/sync/Zotero/storage/TLLKP87F/S2666920X22000364.html}
}

@article{berryGraderPrograms1966,
  title = {Grader {{Programs}}},
  author = {Berry, R. E.},
  year = {1966},
  month = nov,
  journal = {The Computer Journal},
  volume = {9},
  number = {3},
  pages = {252--256},
  issn = {0010-4620},
  doi = {10.1093/comjnl/9.3.252},
  url = {https://doi.org/10.1093/comjnl/9.3.252},
  urldate = {2024-02-07},
  abstract = {This paper examines the possibility of using automatic grading programs for checking some of the practical work of students on a Numerical Analysis course. Two existing programs for checking root-finding techniques were tested to gain experience in using grader programs. A program to check solutions to a system of n first order differential equations was written.},
  file = {/home/charlotte/sync/Zotero/storage/M66WNCES/berry1966.pdf.pdf;/home/charlotte/sync/Zotero/storage/WEVW8H9W/Berry - 1966 - Grader Programs.pdf;/home/charlotte/sync/Zotero/storage/34CCGYRS/406256.html}
}

@inproceedings{bethkeryExploringExploratoryProgramming2017,
  title = {Exploring Exploratory Programming},
  booktitle = {2017 {{IEEE Symposium}} on {{Visual Languages}} and {{Human-Centric Computing}} ({{VL}}/{{HCC}})},
  author = {Beth Kery, Mary and Myers, Brad A.},
  year = {2017},
  month = oct,
  pages = {25--29},
  issn = {1943-6106},
  doi = {10.1109/VLHCC.2017.8103446},
  abstract = {In open-ended tasks where a program's behavior cannot be specified in advance, exploratory programming is a key practice in which programmers actively experiment with different possibilities using code. Exploratory programming is highly relevant today to a variety of professional and end-user programmer domains, including prototyping, learning through play, digital art, and data science. However, prior research has largely lacked clarity on what exploratory programming is, and what behaviors are characteristic of this practice. Drawing on this data and prior literature, we provide an organized description of what exploratory programming has meant historically and a framework of four dimensions for studying exploratory programming tasks: (1) applications, (2) required code quality, (3) ease or difficulty of exploration, and (4) the exploratory process. This provides a basis for better analyzing tool support for exploratory programming.},
  keywords = {Creativity Support,Debugging,End-user programming,Exploratory Programming,Games,Programming profession,Tools,Visualization},
  file = {/home/charlotte/sync/Zotero/storage/PPD78QCN/Beth Kery and Myers - 2017 - Exploring exploratory programming.pdf;/home/charlotte/sync/Zotero/storage/8TD2CSXN/8103446.html}
}

@inproceedings{billsSharingIntroductoryProgramming2007,
  title = {Sharing Introductory Programming Curriculum across Disciplines},
  booktitle = {Proceedings of the 8th {{ACM SIGITE}} Conference on {{Information}} Technology Education},
  author = {Bills, Dianne P. and Canosa, Roxanne L.},
  year = {2007},
  month = oct,
  series = {{{SIGITE}} '07},
  pages = {99--106},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1324302.1324324},
  url = {https://dl.acm.org/doi/10.1145/1324302.1324324},
  urldate = {2024-01-10},
  abstract = {Originally there was one computing curriculum, computer science, which provided a "one-size-fits-all" education in programming and computing in general. Today, computing education has diverged into an array of sub-discipline areas as educators try to meet the changing computing needs of business and industry. Information technology, software engineering, computer engineering, and information systems have emerged from computer science as distinct computing disciplines. Plus, additional "micro-disciplines" are quickly emerging: games and networking from information technology, for example. The foundation skill for all computing disciplines is programming. However as computing technologies advance, discipline-specific differences increase. Each computing sub-discipline needs to approach programming from a slightly different viewpoint to meet student expectations of being highly marketable and employer expectations of quick productivity. How can colleges and universities economically meet the competing demands for a focused computing education while maintaining a strong foundation in programming fundamentals. This paper discusses how an introductory programming sequence can be designed with a common base to support multiple computing sub-disciplines as well as differentiated to address the specific, focused needs of a given sub-discipline. We identify both commonalities that support economy of scale and important differences that distinguish sub-discipline curricula.},
  isbn = {978-1-59593-920-3},
  keywords = {computer programming,curriculum,curriculum comparison,information technology education,sharing curriculum},
  file = {/home/charlotte/sync/Zotero/storage/99SBRYF9/Bills and Canosa - 2007 - Sharing introductory programming curriculum across.pdf;/home/charlotte/sync/Zotero/storage/ECNMV5H7/bills2007.pdf.pdf}
}

@inproceedings{binnsItReducingHuman2018,
  title = {'{{It}}'s {{Reducing}} a {{Human Being}} to a {{Percentage}}': {{Perceptions}} of {{Justice}} in {{Algorithmic Decisions}}},
  shorttitle = {'{{It}}'s {{Reducing}} a {{Human Being}} to a {{Percentage}}'},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Binns, Reuben and Van Kleek, Max and Veale, Michael and Lyngs, Ulrik and Zhao, Jun and Shadbolt, Nigel},
  year = {2018},
  month = apr,
  series = {{{CHI}} '18},
  pages = {1--14},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3173574.3173951},
  url = {https://doi.org/10.1145/3173574.3173951},
  urldate = {2021-04-30},
  abstract = {Data-driven decision-making consequential to individuals raises important questions of accountability and justice. Indeed, European law provides individuals limited rights to 'meaningful information about the logic' behind significant, autonomous decisions such as loan approvals, insurance quotes, and CV filtering. We undertake three experimental studies examining people's perceptions of justice in algorithmic decision-making under different scenarios and explanation styles. Dimensions of justice previously observed in response to human decision-making appear similarly engaged in response to algorithmic decisions. Qualitative analysis identified several concerns and heuristics involved in justice perceptions including arbitrariness, generalisation, and (in)dignity. Quantitative analysis indicates that explanation styles primarily matter to justice perceptions only when subjects are exposed to multiple different styles---under repeated exposure of one style, scenario effects obscure any explanation effects. Our results suggests there may be no 'best' approach to explaining algorithmic decisions, and that reflection on their automated nature both implicates and mitigates justice dimensions.},
  isbn = {978-1-4503-5620-6},
  keywords = {algorithmic decision-making,explanation,fairness,justice,machine learning,transparency},
  file = {/home/charlotte/sync/Zotero/storage/IKJY2PR9/Binns et al. - 2018 - 'It's Reducing a Human Being to a Percentage' Per.pdf}
}

@inproceedings{bishopFlippedClassroomSurvey2013,
  title = {The {{Flipped Classroom}}: {{A Survey}} of the {{Research}}},
  shorttitle = {The {{Flipped Classroom}}},
  booktitle = {2013 {{ASEE Annual Conference}} \& {{Exposition}}},
  author = {Bishop, Jacob and Verleger, Matthew A.},
  year = {2013},
  month = jun,
  pages = {23.1200.1-23.1200.18},
  issn = {2153-5965},
  url = {https://peer.asee.org/the-flipped-classroom-a-survey-of-the-research},
  urldate = {2022-08-16},
  file = {/home/charlotte/sync/Zotero/storage/NK937ZL5/Bishop and Verleger - 2013 - The Flipped Classroom A Survey of the Research.pdf;/home/charlotte/sync/Zotero/storage/849MXNUK/the-flipped-classroom-a-survey-of-the-research.html}
}

@article{blackAssessmentClassroomLearning1998,
  title = {Assessment and {{Classroom Learning}}},
  author = {Black, Paul and Wiliam, Dylan},
  year = {1998},
  month = mar,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {5},
  number = {1},
  pages = {7--74},
  publisher = {{Routledge}},
  issn = {0969-594X},
  doi = {10.1080/0969595980050102},
  url = {https://doi.org/10.1080/0969595980050102},
  urldate = {2021-08-10},
  abstract = {This article is a review of the literature on classroom formative assessment. Several studies show firm evidence that innovations designed to strengthen the frequent feedback that students receive about their learning yield substantial learning gains. The perceptions of students and their role in self-assessment are considered alongside analysis of the strategies used by teachers and the formative strategies incorporated in such systemic approaches as mastery learning. There follows a more detailed and theoretical analysis of the nature of feedback, which provides a basis for a discussion of the development of theoretical models for formative assessment and of the prospects for the improvement of practice.}
}

@article{bliksteinProgrammingPluralismUsing2014,
  title = {Programming {{Pluralism}}: {{Using Learning Analytics}} to {{Detect Patterns}} in the {{Learning}} of {{Computer Programming}}},
  shorttitle = {Programming {{Pluralism}}},
  author = {Blikstein, Paulo and Worsley, Marcelo and Piech, Chris and Sahami, Mehran and Cooper, Steven and Koller, Daphne},
  year = {2014},
  month = oct,
  journal = {Journal of the Learning Sciences},
  volume = {23},
  number = {4},
  pages = {561--599},
  publisher = {{Routledge}},
  issn = {1050-8406},
  doi = {10.1080/10508406.2014.954750},
  url = {https://doi.org/10.1080/10508406.2014.954750},
  urldate = {2023-10-18},
  abstract = {New high-frequency, automated data collection and analysis algorithms could offer new insights into complex learning processes, especially for tasks in which students have opportunities to generate unique open-ended artifacts such as computer programs. These approaches should be particularly useful because the need for scalable project-based and student-centered learning is growing considerably. In this article, we present studies focused on how students learn computer programming, based on data drawn from 154,000 code snapshots of computer programs under development by approximately 370 students enrolled in an introductory undergraduate programming course. We use methods from machine learning to discover patterns in the data and try to predict final exam grades. We begin with a set of exploratory experiments that use fully automated techniques to investigate how much students change their programming behavior throughout all assignments in the course. The results show that students' change in programming patterns is only weakly predictive of course performance. We subsequently hone in on 1 single assignment, trying to map students' learning process and trajectories and automatically identify productive and unproductive (sink) states within these trajectories. Results show that our process-based metric has better predictive power for final exams than the midterm grades. We conclude with recommendations about the use of such methods for assessment, real-time feedback, and course improvement.},
  file = {/home/charlotte/sync/Zotero/storage/XVUQVM6A/Blikstein et al. - 2014 - Programming Pluralism Using Learning Analytics to.pdf}
}

@article{bloom1956handbook,
  title = {Handbook {{I}}: Cognitive Domain},
  author = {Bloom, Benjamin S and Engelhart, Max D and Furst, {\relax EJ} and Hill, Walker H and Krathwohl, David R},
  year = {1956},
  journal = {New York: David McKay},
  file = {/home/charlotte/sync/Zotero/storage/32VDQ3EH/Bloom et al. - 1956 - Handbook I cognitive domain.pdf}
}

@article{boctorActivelearningStrategiesUse2013,
  title = {Active-Learning Strategies: {{The}} Use of a Game to Reinforce Learning in Nursing Education. {{A}} Case Study},
  shorttitle = {Active-Learning Strategies},
  author = {Boctor, Lisa},
  year = {2013},
  month = mar,
  journal = {Nurse Education in Practice},
  volume = {13},
  number = {2},
  pages = {96--100},
  issn = {1471-5953},
  doi = {10.1016/j.nepr.2012.07.010},
  url = {https://www.sciencedirect.com/science/article/pii/S1471595312001424},
  urldate = {2021-09-30},
  abstract = {The majority of nursing students are kinesthetic learners, preferring a hands-on, active approach to education. Research shows that active-learning strategies can increase student learning and satisfaction. This study looks at the use of one active-learning strategy, a Jeopardy-style game, `Nursopardy', to reinforce Fundamentals of Nursing material, aiding in students' preparation for a standardized final exam. The game was created keeping students varied learning styles and the NCLEX blueprint in mind. The blueprint was used to create 5 categories, with 26 total questions. Student survey results, using a five-point Likert scale showed that they did find this learning method enjoyable and beneficial to learning. More research is recommended regarding learning outcomes, when using active-learning strategies, such as games.},
  langid = {english},
  keywords = {Active learning,Games,Nursing education},
  file = {/home/charlotte/sync/Zotero/storage/YYYN8LQ6/Boctor - 2013 - Active-learning strategies The use of a game to r.pdf}
}

@article{boelensConjectureMappingSupport2020,
  title = {Conjecture Mapping to Support Vocationally Educated Adult Learners in Open-Ended Tasks},
  author = {Boelens, Ruth and De Wever, Bram and McKenney, Susan},
  year = {2020},
  month = may,
  journal = {Journal of the Learning Sciences},
  volume = {29},
  number = {3},
  pages = {430--470},
  publisher = {{Routledge}},
  issn = {1050-8406},
  doi = {10.1080/10508406.2020.1759605},
  url = {https://doi.org/10.1080/10508406.2020.1759605},
  urldate = {2021-09-15},
  abstract = {Background This case reports on a teacher education course that aimed to support adult learners with a vocational education background to accomplish open-ended tasks. Conjecture mapping was used to identify the most salient design features, and to test if, how, and why these course features supported learners. Methods: Inspired by ethnographic approaches, sustained engagement and multiple data sources were used to explain the effects of the course design on participants' behavior and perceptions: student and teacher interviews, observations, and artifacts. Findings: The results reveal that almost all of the proposed design features stimulated the participants toward the intended enactment processes, which in turn yielded the intended learning outcomes. For instance, worked examples (i.e., design feature) not only engendered the production of artifacts that meet high standards (i.e., enactment process) because they clarify the task requirements, but also fostered a safe structure (i.e., enactment process) by providing an overall picture of the task. Contribution: The conjecture map resulting from this study provides a theoretical frame to describe, explain, and predict how specific course design features support vocationally educated adult learners (VEAL) in open-ended tasks, and assists those who aim to implement open-ended tasks in similar contexts.},
  file = {/home/charlotte/sync/Zotero/storage/QQ3Z4SAU/Boelens et al. - 2020 - Conjecture mapping to support vocationally educate.pdf;/home/charlotte/sync/Zotero/storage/TSZVRFQN/10508406.2020.html}
}

@techreport{bonarBridgeIntelligentTutoring1988,
  title = {Bridge: {{Intelligent}} Tutoring with Intermediate Representations},
  author = {Bonar, Jeffrey G and Cunningham, Robert},
  year = {1988},
  month = may,
  institution = {{CARNEGIE-MELLON UNIV PITTSBURGH PA ARTIFICIAL INTELLIGENCE AND PSYCHOLOGY}}
}

@article{borteBarriersStudentActive2020,
  title = {Barriers to Student Active Learning in Higher Education},
  author = {B{\o}rte, Kristin and Nesje, Katrine and Lillejord, S{\o}lvi},
  year = {2020},
  month = nov,
  journal = {Teaching in Higher Education},
  volume = {0},
  number = {0},
  pages = {1--19},
  publisher = {{Routledge}},
  issn = {1356-2517},
  doi = {10.1080/13562517.2020.1839746},
  url = {https://doi.org/10.1080/13562517.2020.1839746},
  urldate = {2022-03-03},
  abstract = {This article reviews research that consistently, across borders and over time, reveals inertia in Higher Education institutions related to innovation in academic teaching. Despite frequent calls for more student-active learning, studies find that teaching remains predominantly traditional and teacher-centred. While research is recognised as continuously developing, border-crossing, investigative and innovative collaborative activities that needs an infrastructure to succeed, the need for collaborative development and a supporting infrastructure is rarely mentioned in academic teaching, often described as individual and traditional in the research. To better understand this paradox, and to identify barriers to student active learning, we reanalysed articles from two systematic reviews, one on campus development and one on learning and teaching with technology. The article identified the following prerequisites for student active learning to succeed: (1) better alignment between research and teaching practices, (2) a supporting infrastructure for research and teaching, (3) staff professional development and learning designs.},
  keywords = {barriers,infrastructure,literature review,scholarly approach,Student active learning},
  file = {/home/charlotte/sync/Zotero/storage/LNLEXLHZ/Børte et al. - 2020 - Barriers to student active learning in higher educ.pdf;/home/charlotte/sync/Zotero/storage/ZHKF2YD4/13562517.2020.html}
}

@book{braden1965introductory,
  title = {An Introductory Course in Computer Programming},
  author = {Braden, Robert T and Perlis, Alan J},
  year = {1965},
  publisher = {{Clearinghouse for Federal Scientific and Technical Information, US {\dots}}}
}

@book{brooksNoSilverBullet1987,
  title = {No Silver Bullet},
  author = {Brooks, Frederick and Kugler, H},
  year = {1987},
  publisher = {{April}}
}

@misc{brunsfeldTreesitterTreesitterV02024,
  title = {Tree-Sitter/Tree-Sitter: V0.20.9},
  shorttitle = {Tree-Sitter/Tree-Sitter},
  author = {Brunsfeld, Max and Hlynskyi, Andrew and Qureshi, Amaan and Thomson, Amaan and Josh Vera and Phil Turnbull and Timothy Clem and Douglas Creager and Andrew Helwer and Rob Rix and {Hendrik van Antwerpen} and Daumantas Kavolis and Michael Davis and Ika and {Tuấn-Anh Nguyễn} and Matt Massicotte and Stafford Brunk and Amin Yahyaabadi and Niranjan Hasabnis and {bfredl} and Mingkai Dong and Samuel Moelius and Jonathan Arnett and Vladimir Panteleev and Kolja and Steven Kalt and Linda\_pp and George Fraser and Edgar},
  year = {2024},
  month = jan,
  doi = {10.5281/ZENODO.4619183},
  url = {https://zenodo.org/doi/10.5281/zenodo.4619183},
  urldate = {2024-02-05},
  abstract = {An incremental parsing system for programming tools},
  copyright = {Creative Commons Attribution 4.0 International},
  howpublished = {Zenodo}
}

@article{brusilovskyIndividualizedExercisesSelfassessment2005,
  title = {Individualized Exercises for Self-Assessment of Programming Knowledge: {{An}} Evaluation of {{QuizPACK}}},
  shorttitle = {Individualized Exercises for Self-Assessment of Programming Knowledge},
  author = {Brusilovsky, Peter and Sosnovsky, Sergey},
  year = {2005},
  month = sep,
  journal = {Journal on Educational Resources in Computing},
  volume = {5},
  number = {3},
  pages = {6--es},
  issn = {1531-4278},
  doi = {10.1145/1163405.1163411},
  url = {https://dl.acm.org/doi/10.1145/1163405.1163411},
  urldate = {2024-02-09},
  abstract = {Individualized exercises are a promising feature in promoting modern e-learning. The focus of this article is on the QuizPACK system, which is able to generate parameterized exercises for the C language and automatically evaluate the correctness of student answers. We introduce QuizPACK and present the results of its comprehensive classroom evaluation during four consecutive semesters. Our studies demonstrate that when QuizPACK is used for out-of-class self-assessment, it is an exceptional learning tool. The students' work with QuizPACK significantly improved their knowledge of semantics and positively affected higher-level knowledge and skills. The students themselves praised the system highly as a learning tool. We also demonstrated that the use of the system in self-assessment mode can be significantly increased by basing later classroom paper-and-pencil quizzes on QuizPACK questions, motivating students to practice them more.},
  keywords = {assessment,classroom study,code execution,E-learning,individualized exercises,introductory programming,parameterized questions},
  file = {/home/charlotte/sync/Zotero/storage/CRSCG93F/Brusilovsky and Sosnovsky - 2005 - Individualized exercises for self-assessment of pr.pdf;/home/charlotte/sync/Zotero/storage/UAJJT4E4/brusilovsky2005.pdf.pdf}
}

@inproceedings{caizaProgrammingAssignmentsAutomatic2013,
  title = {Programming Assignments Automatic Grading: Review of Tools and Implementations},
  shorttitle = {Programming Assignments Automatic Grading},
  booktitle = {7th {{International Technology}}, {{Education}} and {{Development Conference}} ({{INTED2013}}) {\textbar} 7th {{International Technology}}, {{Education}} and {{Development Conference}} ({{INTED2013}}) {\textbar} 04/03/2013 - 06/03/2013 {\textbar} {{Valencia}}, {{Spain}}},
  author = {Caiza, Julio C. and del {\'A}lamo Ramiro, Jos{\'e} Mar{\'i}a},
  year = {2013},
  pages = {5691--5700},
  publisher = {{E.T.S.I. Telecomunicaci{\'o}n (UPM)}},
  address = {{Valencia, Spain}},
  url = {https://oa.upm.es/25765/},
  urldate = {2022-08-16},
  abstract = {Automatic grading of programming assignments is an important topic in academic research. It aims at improving the level of feedback given to students and optimizing the professor time. Several researches have reported the development of software tools to support this process. Then, it is helpfulto get a quickly and good sight about their key features. This paper reviews an ample set of tools forautomatic grading of programming assignments. They are divided in those most important mature tools, which have remarkable features; and those built recently, with new features. The review includes the definition and description of key features e.g. supported languages, used technology, infrastructure, etc. The two kinds of tools allow making a temporal comparative analysis. This analysis infrastructure, etc. The two kinds of tools allow making a temporal comparative analysis. This analysis shows good improvements in this research field, these include security, more language support, plagiarism detection, etc. On the other hand, the lack of a grading model for assignments is identified as an important gap in the reviewed tools. Thus, a characterization of evaluation metrics to grade programming assignments is provided as first step to get a model. Finally new paths in this research field are proposed.},
  copyright = {https://creativecommons.org/licenses/by-nc-nd/3.0/es/},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/T6US678G/Caiza and Álamo Ramiro - 2013 - Programming assignments automatic grading review .pdf;/home/charlotte/sync/Zotero/storage/8FBZPPGA/25765.html}
}

@inproceedings{cambroneroWhenDeepLearning2019,
  title = {When Deep Learning Met Code Search},
  booktitle = {Proceedings of the 2019 27th {{ACM Joint Meeting}} on {{European Software Engineering Conference}} and {{Symposium}} on the {{Foundations}} of {{Software Engineering}}},
  author = {Cambronero, Jose and Li, Hongyu and Kim, Seohyun and Sen, Koushik and Chandra, Satish},
  year = {2019},
  month = aug,
  series = {{{ESEC}}/{{FSE}} 2019},
  pages = {964--974},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3338906.3340458},
  url = {https://dl.acm.org/doi/10.1145/3338906.3340458},
  urldate = {2023-11-23},
  abstract = {There have been multiple recent proposals on using deep neural networks for code search using natural language. Common across these proposals is the idea of embedding code and natural language queries into real vectors and then using vector distance to approximate semantic correlation between code and the query. Multiple approaches exist for learning these embeddings, including unsupervised techniques, which rely only on a corpus of code examples, and supervised techniques, which use an aligned corpus of paired code and natural language descriptions. The goal of this supervision is to produce embeddings that are more similar for a query and the corresponding desired code snippet. Clearly, there are choices in whether to use supervised techniques at all, and if one does, what sort of network and training to use for supervision. This paper is the first to evaluate these choices systematically. To this end, we assembled implementations of state-of-the-art techniques to run on a common platform, training and evaluation corpora. To explore the design space in network complexity, we also introduced a new design point that is a minimal supervision extension to an existing unsupervised technique. Our evaluation shows that: 1. adding supervision to an existing unsupervised technique can improve performance, though not necessarily by much; 2. simple networks for supervision can be more effective that more sophisticated sequence-based networks for code search; 3. while it is common to use docstrings to carry out supervision, there is a sizeable gap between the effectiveness of docstrings and a more query-appropriate supervision corpus.},
  isbn = {978-1-4503-5572-8},
  keywords = {code search,joint embedding,neural networks},
  file = {/home/charlotte/sync/Zotero/storage/EENERC5Z/Cambronero et al. - 2019 - When deep learning met code search.pdf}
}

@article{caswellOpenEducationalResources2008,
  title = {Open {{Educational Resources}}: {{Enabling}} Universal Education},
  shorttitle = {Open {{Educational Resources}}},
  author = {Caswell, Tom and Henson, Shelley and Jensen, Marion and Wiley, David},
  year = {2008},
  journal = {International Review of Research in Open and Distributed Learning},
  volume = {9},
  number = {1},
  pages = {1--11},
  publisher = {{Athabasca University Press (AU Press)}},
  issn = {1492-3831},
  doi = {10.19173/irrodl.v9i1.469},
  url = {https://www.erudit.org/en/journals/irrodl/2008-v9-n1-irrodl05535/1071813ar/},
  urldate = {2022-10-03},
  abstract = {The role of distance education is shifting. Traditionally distance education was limited in the number of people served because of production, reproduction, and distribution costs. Today, while it still costs the university time and money to produce a course, technology has made it such that reproduction costs are almost non-existent. This shift has significant implications, and allows distance educators to play an important role in the fulfillment of the promise of the right to universal education. At little or no cost, universities can make their content available to millions. This content has the potential to substantially improve the quality of life of learners around the world. New distance education technologies, such as OpenCourseWares, act as enablers to achieving the universal right to education. These technologies, and the associated changes in the cost of providing access to education, change distance education's role from one of classroom alternative to one of social transformer.},
  langid = {english},
  keywords = {access,distance education,new technologies,OpenCourseWare},
  file = {/home/charlotte/sync/Zotero/storage/A2G72CME/Caswell et al. - 2008 - Open Educational Resources Enabling universal edu.pdf;/home/charlotte/sync/Zotero/storage/SNVPCNAG/abstract.html}
}

@article{cavalcantiExplainablePredictionFeedback2023,
  title = {Towards {{Explainable Prediction Feedback Messages Using BERT}}},
  author = {Cavalcanti, Anderson Pinheiro and Mello, Rafael Ferreira and Ga{\v s}evi{\'c}, Dragan and Freitas, Fred},
  year = {2023},
  month = nov,
  journal = {International Journal of Artificial Intelligence in Education},
  issn = {1560-4306},
  doi = {10.1007/s40593-023-00375-w},
  url = {https://doi.org/10.1007/s40593-023-00375-w},
  urldate = {2024-01-10},
  abstract = {Educational feedback is a crucial factor in the student's learning journey, as through it, students are able to identify their areas of deficiencies and improve self-regulation. However, the literature shows that this is an area of great dissatisfaction, especially in higher education. Providing effective feedback becomes an increasingly challenging task as the number of students increases. Therefore, this article explores the use of automated content analysis to examine instructor feedback based on reputable models from the literature that provide best practices and classify feedback at different levels. For this, this article proposes using the transformer model BERT to classify feedback messages. The proposed method outperforms previous works by up to 35.71\% in terms of Cohen's kappa. Finally, this study adopted an explainable artificial intelligence to provide insights into the most predictive features for each classifier analyzed.},
  langid = {english},
  keywords = {BERT,Explainable artificial intelligence,Feedback,Online learning},
  file = {/home/charlotte/sync/Zotero/storage/6DLW2ES2/Cavalcanti et al. - 2023 - Towards Explainable Prediction Feedback Messages U.pdf}
}

@article{cervoneMathJaxPlatformMathematics2012,
  title = {{{MathJax}}: A Platform for Mathematics on the {{Web}}},
  author = {Cervone, Davide},
  year = {2012},
  journal = {Notices of the AMS},
  volume = {59},
  number = {2},
  pages = {312--316}
}

@article{chattiReferenceModelLearning2012,
  title = {A Reference Model for Learning Analytics},
  author = {Chatti, Mohamed Amine and Dyckhoff, Anna Lea and Schroeder, Ulrik and Th{\"u}s, Hendrik},
  year = {2012},
  month = jan,
  journal = {International Journal of Technology Enhanced Learning},
  volume = {4},
  number = {5-6},
  pages = {318--331},
  publisher = {{Inderscience Publishers}},
  issn = {1753-5255},
  doi = {10.1504/IJTEL.2012.051815},
  url = {https://www.inderscienceonline.com/doi/10.1504/IJTEL.2012.051815},
  urldate = {2024-02-13},
  abstract = {Recently, there is an increasing interest in learning analytics in Technology-Enhanced Learning (TEL). Generally, learning analytics deals with the development of methods that harness educational datasets to support the learning process. Learning analytics (LA) is a multi-disciplinary field involving machine learning, artificial intelligence, information retrieval, statistics and visualisation. LA is also a field in which several related areas of research in TEL converge. These include academic analytics, action analytics and educational data mining. In this paper, we investigate the connections between LA and these related fields. We describe a reference model for LA based on four dimensions, namely data and environments (what?), stakeholders (who?), objectives (why?) and methods (how?). We then review recent publications on LA and its related fields and map them to the four dimensions of the reference model. Furthermore, we identify various challenges and research opportunities in the area of LA in relation to each dimension.},
  keywords = {academic analytics,action research,educational data mining,learning analytics,literature review,reference model},
  file = {/home/charlotte/sync/Zotero/storage/3GV8IWBM/chatti2012.pdf.pdf}
}

@article{cheangAutomatedGradingProgramming2003,
  title = {On Automated Grading of Programming Assignments in an Academic Institution},
  author = {Cheang, Brenda and Kurnia, Andy and Lim, Andrew and Oon, Wee-Chong},
  year = {2003},
  month = sep,
  journal = {Computers \& Education},
  volume = {41},
  number = {2},
  pages = {121--131},
  issn = {0360-1315},
  doi = {10.1016/S0360-1315(03)00030-7},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131503000307},
  urldate = {2021-10-01},
  abstract = {Practise is one of the most important steps in learning the art of computer programming. Unfortunately, human grading of programming assignments is a tedious and error-prone task, a problem compounded by the large enrolments of many programming courses. As a result, students in such courses tend to be given fewer programming assignments than should be ideally given. One solution to this problem is to automate the grading process such that students can electronically submit their programming assignments and receive instant feedback. This paper studies the implementation of one such automated grading system, called the Online Judge, in the School of Computing of the National University of Singapore for a compulsory first-year course that teaches basic programming techniques with over 700 students, describing the student reactions and behavior as well as the difficulties encountered. The Online Judge was also successfully employed for an advanced undergraduate course and an introductory high school course.},
  langid = {english},
  keywords = {Automated grading,Computer science,Education,Online judge},
  file = {/home/charlotte/sync/Zotero/storage/AECADBN3/Cheang et al. - 2003 - On automated grading of programming assignments in.pdf;/home/charlotte/sync/Zotero/storage/KNUI69NI/S0360131503000307.html}
}

@article{chenAnalysisLearningBehavior2020,
  title = {Analysis of {{Learning Behavior}} in an {{Automated Programming Assessment Environment}}: {{A Code Quality Perspective}}},
  shorttitle = {Analysis of {{Learning Behavior}} in an {{Automated Programming Assessment Environment}}},
  author = {Chen, Hsi-Min and Nguyen, Bao-An and Yan, Yi-Xiang and Dow, Chyi-Ren},
  year = {2020},
  journal = {IEEE Access},
  volume = {8},
  pages = {167341--167354},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3024102},
  url = {https://ieeexplore.ieee.org/document/9195825},
  urldate = {2023-10-18},
  abstract = {Automated programming assessment systems are useful tools to track the learning progress of students automatically and thereby reduce the workload of educators. They can also be used to gain insights into how students learn, making it easier to formulate strategies aimed at enhancing learning performance. Rather than functional code which is always inspected, code quality remains an essential aspect to which not many educators consider when designing an automated programming assessment system. In this study, we applied data mining techniques to analyze the results of an automated assessment system to reveal unexpressed patterns in code quality improvement that are predictive of final achievements in the course. Cluster analysis is first utilized to categorize students according to their learning behavior and outcomes. Cluster profile analysis is then leveraged to highlight actionable factors that could affect their final grades. Finally, the same factors are employed to construct a classification model by which to make early predictions of the students' final results. Our empirical results demonstrate the efficacy of the proposed scheme in providing valuable insights into the learning behaviors of students in novice programming courses, especially in code quality assurance, which could be used to enhance programming performance at the university level.},
  file = {/home/charlotte/sync/Zotero/storage/C8KXJ7TR/Chen et al. - 2020 - Analysis of Learning Behavior in an Automated Prog.pdf;/home/charlotte/sync/Zotero/storage/V3F96LAQ/9195825.html}
}

@article{chickeringSevenPrinciplesGood1987,
  title = {Seven {{Principles}} for {{Good Practice}} in {{Undergraduate Education}}},
  author = {Chickering, Arthur W. and Gamson, Zelda F.},
  year = {1987},
  month = mar,
  journal = {AAHE Bulletin},
  url = {https://eric.ed.gov/?id=ed282491},
  urldate = {2022-09-09},
  abstract = {Seven principles that can help to improve undergraduate education are identified. Based on research on college teaching and learning, good practice in undergraduate education: (1) encourages contacts between students and faculty; (2) develops reciprocity and cooperation among students; (3) uses active learning techniques; (4) gives prompt feedback; (5) emphasizes time on task; (6) communicates high expectations; and (7) respects diverse talents and ways of learning. Examples of approaches that have been used in different kinds of college in the last few years are described. In addition, the implications of these principles for the way states fund and govern higher education and for the way institutions are run are briefly discussed. Examples of good approaches include: freshman  seminars on important topics taught by senior faculty; learning groups of five to seven students who meet regularly during class to solve problems set by the instructor; active learning using structured exercises, discussions, team projects, and peer critiques, as well as internships and independent study; and mastery learning, contract learning, and computer-assisted instruction approaches, which required adequate time on learning. (SW)},
  langid = {english},
  keywords = {College Instruction,Educational Principles,Expectation,Feedback,Higher Education,Instructional Improvement,Learning Activities,Peer Relationship,Student Participation,Teacher Student Relationship,Time on Task,Undergraduate Study},
  file = {/home/charlotte/sync/Zotero/storage/Y3IWLBAE/Chickering and Gamson - 1987 - Seven Principles for Good Practice in Undergraduat.pdf;/home/charlotte/sync/Zotero/storage/3MGELQSK/eric.ed.gov.html}
}

@inproceedings{chowAutomatedDataDrivenHints2017,
  title = {Automated {{Data-Driven Hints}} for {{Computer Programming Students}}},
  booktitle = {Adjunct {{Publication}} of the 25th {{Conference}} on {{User Modeling}}, {{Adaptation}} and {{Personalization}}},
  author = {Chow, Sammi and Yacef, Kalina and Koprinska, Irena and Curran, James},
  year = {2017},
  month = jul,
  series = {{{UMAP}} '17},
  pages = {5--10},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3099023.3099065},
  url = {https://doi.org/10.1145/3099023.3099065},
  urldate = {2022-08-02},
  abstract = {Formative feedback is essential for learning computer programming but is also a challenge to automate because of the many solutions a programming exercise can have. Whilst programming tutoring systems can easily generate automated feedback on how correct a program is, they less often provide some personalised guidance on how to improve or fix the code. In this paper, we present an approach for generating hints using previous student data. Utilising a range of techniques such as filtering, clustering and pattern mining, four different types of data-driven hints are generated: input suggestion, code-based, concept and pre-emptive hints. We evaluated our approach with data from 5529 students using the Grok Learning platform for teaching programming in Python. The results show that we can generate various types of hints for over 90\% of students with data from only 10 students, and hence, reduce the cold-start problem.},
  isbn = {978-1-4503-5067-9},
  keywords = {educational data mining,intelligent teaching systems,personalised feedback},
  file = {/home/charlotte/sync/Zotero/storage/GKVBYZS4/Chow et al. - 2017 - Automated Data-Driven Hints for Computer Programmi.pdf}
}

@article{ciprianoDropProjectAutomatic2022,
  title = {Drop {{Project}}: {{An}} Automatic Assessment Tool for Programming Assignments},
  shorttitle = {Drop {{Project}}},
  author = {Cipriano, Bruno Pereira and Fachada, Nuno and Alves, Pedro},
  year = {2022},
  month = jun,
  journal = {SoftwareX},
  volume = {18},
  pages = {101079},
  issn = {2352-7110},
  doi = {10.1016/j.softx.2022.101079},
  url = {https://www.sciencedirect.com/science/article/pii/S2352711022000577},
  urldate = {2022-11-23},
  abstract = {Automated assessment tools (AATs) are software systems used in teaching environments to automate the evaluation of computer programs implemented by students. These tools can be used to stimulate the interest of computer science students in programming courses by providing quick feedback on their work and highlighting their mistakes. Despite the abundance of such tools, most of them are developed for a specific course and are not production-ready. Others lack advanced features that are required for certain pedagogical goals (e.g. Git integration) and/or are not flexible enough to be used with students having different computer literacy levels, such as first year and second year students. In this paper we present Drop Project (DP), an automated assessment tool built on top of the Maven build automation software. We have been using DP in our teaching activity since 2018, having received more than fifty thousand submissions between projects, classroom exercises, tests and homework assignments. The tool's automated feedback has allowed us to raise the difficulty level of the course's projects, while the grading process has become more efficient and consistent between different teachers. DP is an extensively tested, production-ready tool. The software's code and documentation are available in GitHub under an open-source software license.},
  langid = {english},
  keywords = {Automated assessment,Computer science education,Programming education,Unit testing},
  file = {/home/charlotte/sync/Zotero/storage/3M9RAMYG/Cipriano et al. - 2022 - Drop Project An automatic assessment tool for pro.pdf;/home/charlotte/sync/Zotero/storage/LJ3KZHVY/S2352711022000577.html}
}

@book{CodeCloneAnalysis,
  title = {Code {{Clone Analysis}}},
  url = {https://link.springer.com/book/10.1007/978-981-16-1927-4},
  urldate = {2022-07-05},
  abstract = {This book selects past research results that are important to the progress of code clone analysis and updates them with new results and future directions.},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/4V9XFUZX/Code Clone Analysis.pdf;/home/charlotte/sync/Zotero/storage/5UWWES36/978-981-16-1927-4.html}
}

@article{cooperFacilitatingLearningFormative2000,
  title = {Facilitating {{Learning}} from {{Formative Feedback}} in {{Level}} 3 {{Assessment}}},
  author = {Cooper, Neil J.},
  year = {2000},
  month = sep,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {25},
  number = {3},
  pages = {279--291},
  publisher = {{Routledge}},
  issn = {0260-2938},
  doi = {10.1080/713611435},
  url = {https://doi.org/10.1080/713611435},
  urldate = {2022-08-16},
  abstract = {This paper presents the development, through action research, of formative elements in assessment in a level 3 compulsory module of the BSc Health Studies and BSc Nursing programmes at the University of Sunderland. The paper reviews three cycles of planning, implementing and evaluating change in assessment strategy and is written in the first person to emphasise the connections between the writer and the material. From a consideration of the format and characteristics of the assessment within the module, the action research is reported through the implementation of actions taken to facilitate more effective use of formative feedback. The evaluation of these actions through my own reflections, student performance, dialogue with team colleagues and student feedback through the production of short narrative accounts of their learning experience is outlined. The paper demonstrates that through explicitly using the learning potential within assessment, learning can be facilitated through challenging students to move from 'doing' assignments, to reflexive thinking about their writing.}
}

@inproceedings{cortesSupportVectorNetworks1995,
  title = {Support-{{Vector Networks}}},
  booktitle = {Machine {{Learning}}},
  author = {Cortes, Corinna and Vapnik, Vladimir},
  year = {1995},
  pages = {273--297},
  abstract = {The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the supportvector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.},
  file = {/home/charlotte/sync/Zotero/storage/UWV6AEE5/Cortes and Vapnik - 1995 - Support-Vector Networks.pdf;/home/charlotte/sync/Zotero/storage/K3GBYBQ7/summary.html}
}

@inproceedings{cortezUsingDataMining2008,
  title = {Using Data Mining to Predict Secondary School Student Performance},
  author = {Cortez, Paulo and Silva, Alice Maria Gon{\c c}alves},
  year = {2008},
  month = apr,
  publisher = {{EUROSIS-ETI}},
  url = {http://repositorium.sdum.uminho.pt/},
  urldate = {2021-09-16},
  abstract = {Although the educational level of the Portuguese population has improved in the last decades, the statistics keep Portugal at Europe's tail end due to its high student failure rates. In particular, lack of success in the core classes of Mathematics and the Portuguese language is extremely serious. On the other hand, the fields of Business Intelligence (BI)/Data Mining (DM), which aim at extracting high-level knowledge from raw data, offer interesting automated tools that can aid the education domain. The present work intends to approach student achievement in secondary education using BI/DM techniques. Recent real-world data (e.g. student grades, demographic, social and school related features) was collected by using school reports and questionnaires. The two core classes (i.e. Mathematics and Portuguese) were modeled under binary/five-level classification and regression tasks. Also, four DM models (i.e. Decision Trees, Random Forest, Neural Networks and Support Vector Machines) and three input selections (e.g. with and without previous grades) were tested. The results show that a good predictive accuracy can be achieved, provided that the first and/or second school period grades are available. Although student achievement is highly influenced by past evaluations, an explanatory analysis has shown that there are also other relevant features (e.g. number of absences, parent's job and education, alcohol consumption). As a direct outcome of this research, more efficient student prediction tools can be be developed, improving the quality of education and enhancing school resource management.},
  copyright = {openAccess},
  isbn = {978-90-77381-39-7},
  langid = {english},
  annotation = {Accepted: 2008-08-20T18:31:05Z},
  file = {/home/charlotte/sync/Zotero/storage/PCJIYPJI/Cortez and Silva - 2008 - Using data mining to predict secondary school stud.pdf;/home/charlotte/sync/Zotero/storage/2RGMNRJS/8024.html}
}

@article{costaEvaluatingEffectivenessEducational2017,
  title = {Evaluating the Effectiveness of Educational Data Mining Techniques for Early Prediction of Students' Academic Failure in Introductory Programming Courses},
  author = {Costa, Evandro B. and Fonseca, Baldoino and Santana, Marcelo Almeida and {de Ara{\'u}jo}, Fabr{\'i}sia Ferreira and Rego, Joilson},
  year = {2017},
  month = aug,
  journal = {Computers in Human Behavior},
  volume = {73},
  pages = {247--256},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2017.01.047},
  url = {https://www.sciencedirect.com/science/article/pii/S0747563217300596},
  urldate = {2023-10-18},
  abstract = {The data about high students' failure rates in introductory programming courses have been alarming many educators, raising a number of important questions regarding prediction aspects. In this paper, we present a comparative study on the effectiveness of educational data mining techniques to early predict students likely to fail in introductory programming courses. Although several works have analyzed these techniques to identify students' academic failures, our study differs from existing ones as follows: (i) we investigate the effectiveness of such techniques to identify students likely to fail at early enough stage for action to be taken to reduce the failure rate; (ii) we analyse the impact of data preprocessing and algorithms fine-tuning tasks, on the effectiveness of the mentioned techniques. In our study we evaluated the effectiveness of four prediction techniques on two different and independent data sources on introductory programming courses available from a Brazilian Public University: one comes from distance education and the other from on-campus. The results showed that the techniques analyzed in our study are able to early identify students likely to fail, the effectiveness of some of these techniques is improved after applying the data preprocessing and/or algorithms fine-tuning, and the support vector machine technique outperforms the other ones in a statistically significant way.},
  keywords = {Artificial intelligence in education,Automatic instructional planner,Automatic prediction,Educational data mining,Interactive learning environment,Learner modeling},
  file = {/home/charlotte/sync/Zotero/storage/WRKXYMV5/Costa et al. - 2017 - Evaluating the effectiveness of educational data m.pdf;/home/charlotte/sync/Zotero/storage/BGHUVLVT/S0747563217300596.html}
}

@article{crickAnalysisIntroductoryProgramming2017,
  title = {An {{Analysis}} of {{Introductory Programming Courses}} at {{UK Universities}}},
  author = {Crick, Tom},
  year = {2017},
  journal = {The Art, Science, and Engineering of Programming},
  volume = {1},
  number = {2},
  issn = {2473-7321},
  file = {/home/charlotte/sync/Zotero/storage/X4THCVSY/cronfa43520.html}
}

@article{dalyPatternsPlagiarism2005,
  title = {Patterns of Plagiarism},
  author = {Daly, Charlie and Horgan, Jane},
  year = {2005},
  month = feb,
  journal = {ACM SIGCSE Bulletin},
  volume = {37},
  number = {1},
  pages = {383--387},
  issn = {0097-8418},
  doi = {10.1145/1047124.1047473},
  url = {https://dl.acm.org/doi/10.1145/1047124.1047473},
  urldate = {2024-02-09},
  abstract = {We used a new technique to analyse how students plagiarise programs in an introductory programming course. This involved placing a watermark on a student's program and monitoring programs for the watermark during assignment submission. We obtained and analysed extensive and objective data on student plagiarising behaviour. In contrast to the standard plagiarism detection approaches based on pair comparison, the watermark based approach allows us to distinguish between the supplier and the recipient of the code. This gives us additional insight into student behaviour. We found that the dishonest students did not perform significantly worse than the honest students in the exams. However, when dishonest students are further classified into supplier and recipient, it emerged that the recipient students performed significantly worse than the suppliers.},
  keywords = {automatic evaluation,introductory computer programming,plagiarism,watermarks},
  file = {/home/charlotte/sync/Zotero/storage/4HCXLJA3/Daly and Horgan - 2005 - Patterns of plagiarism.pdf;/home/charlotte/sync/Zotero/storage/BL28PSWT/daly2005.pdf.pdf}
}

@techreport{danielsonFinalReportAutomated1976,
  title = {Final {{Report}} on the {{Automated Computer Science Education System}}},
  author = {Danielson, R. L. and Others, And},
  year = {1976},
  month = jun,
  url = {https://eric.ed.gov/?id=ED125599},
  urldate = {2024-02-07},
  abstract = {At the University of Illinois at Urbana, a computer based curriculum called Automated Computer Science Education System (ACSES) has been developed to supplement instruction in introductory computer science courses or to assist individuals interested in acquiring a foundation in computer science through independent study. The system, which uses PLATO terminals, is presently in routine use in several courses at the University of Illinois, and it has been used at Wright Community College in Chicago. Recent changes in programing and technical innovations have increased its instructional effectiveness. The first section of this report describes the goals and design of ACSES. Later sections provide yearly reviews of progress made for the duration of a grant from the National Science  Foundation. (EMH)},
  langid = {english},
  keywords = {Annual Reports,Computer Assisted Instruction,Computer Science Education,Higher Education,Independent Study},
  annotation = {ERIC Number: ED125599},
  file = {/home/charlotte/sync/Zotero/storage/PSFFZRJP/Danielson and Others - 1976 - Final Report on the Automated Computer Science Edu.pdf}
}

@inproceedings{daudPredictingStudentPerformance2017,
  title = {Predicting {{Student Performance}} Using {{Advanced Learning Analytics}}},
  booktitle = {Proceedings of the 26th {{International Conference}} on {{World Wide Web Companion}}},
  author = {Daud, Ali and Aljohani, Naif Radi and Abbasi, Rabeeh Ayaz and Lytras, Miltiadis D. and Abbas, Farhat and Alowibdi, Jalal S.},
  year = {2017},
  month = apr,
  series = {{{WWW}} '17 {{Companion}}},
  pages = {415--421},
  publisher = {{International World Wide Web Conferences Steering Committee}},
  address = {{Republic and Canton of Geneva, CHE}},
  doi = {10.1145/3041021.3054164},
  url = {https://dl.acm.org/doi/10.1145/3041021.3054164},
  urldate = {2024-02-14},
  abstract = {Educational Data Mining (EDM) and Learning Analytics (LA) research have emerged as interesting areas of research, which are unfolding useful knowledge from educational databases for many purposes such as predicting students' success. The ability to predict a student's performance can be beneficial for actions in modern educational systems. Existing methods have used features which are mostly related to academic performance, family income and family assets; while features belonging to family expenditures and students' personal information are usually ignored. In this paper, an effort is made to investigate aforementioned feature sets by collecting the scholarship holding students' data from different universities of Pakistan. Learning analytics, discriminative and generative classification models are applied to predict whether a student will be able to complete his degree or not. Experimental results show that proposed method significantly outperforms existing methods due to exploitation of family expenditures and students' personal information feature sets. Outcomes of this EDM/LA research can serve as policy improvement method in higher education.},
  isbn = {978-1-4503-4914-7},
  keywords = {educational data mining (edm),family expenditures,learning analytics (la),student performance prediction,students personal information},
  file = {/home/charlotte/sync/Zotero/storage/J3NBDBIQ/Daud et al. - 2017 - Predicting Student Performance using Advanced Lear.pdf;/home/charlotte/sync/Zotero/storage/VED4SMRC/daud2017.pdf.pdf}
}

@article{dawsonAssessmentRubricsClearer2017,
  title = {Assessment Rubrics: Towards Clearer and More Replicable Design, Research and Practice},
  shorttitle = {Assessment Rubrics},
  author = {Dawson, Phillip},
  year = {2017},
  month = apr,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {42},
  number = {3},
  pages = {347--360},
  publisher = {{Routledge}},
  issn = {0260-2938},
  doi = {10.1080/02602938.2015.1111294},
  url = {https://doi.org/10.1080/02602938.2015.1111294},
  urldate = {2022-08-16},
  abstract = {`Rubric' is a term with a variety of meanings. As the use of rubrics has increased both in research and practice, the term has come to represent divergent practices. These range from secret scoring sheets held by teachers to holistic student-developed articulations of quality. Rubrics are evaluated, mandated, embraced and resisted based on often imprecise and inconsistent understandings of the term. This paper provides a synthesis of the diversity of rubrics, and a framework for researchers and practitioners to be clearer about what they mean when they say `rubric'. Fourteen design elements or decision points are identified that make one rubric different from another. This framework subsumes previous attempts to categorise rubrics, and should provide more precision to rubric discussions and debate, as well as supporting more replicable research and practice.},
  keywords = {assessment design,replicable research,research synthesis,rubric design,rubrics}
}

@phdthesis{dawyndt2004knowledge,
  title = {Knowledge Accumulation of Microbial Data Aiming at a Dynamic Taxonomic Framework},
  author = {Dawyndt, Peter},
  year = {2004},
  school = {Ghent University},
  file = {/home/charlotte/sync/Zotero/storage/SWALKR7I/Dawyndt - 2004 - Knowledge accumulation of microbial data aiming at.pdf}
}

@article{debuseEducatorsPerceptionsAutomated2008,
  title = {Educators' Perceptions of Automated Feedback Systems},
  author = {Debuse, Justin C. W. and Lawley, Meredith and Shibl, Rania},
  year = {2008},
  month = aug,
  journal = {Australasian Journal of Educational Technology},
  volume = {24},
  number = {4},
  issn = {1449-5554},
  doi = {10.14742/ajet.1198},
  url = {https://ajet.org.au/index.php/AJET/article/view/1198},
  urldate = {2024-02-05},
  abstract = {Assessment of student learning is a core function of educators. Ideally students should be provided with timely, constructive feedback to facilitate learning. However, provision of high quality feedback becomes more complex as class sizes increase, modes of study expand and academic workloads increase. ICT solutions are being developed to facilitate quality feedback, whilst not impacting adversely upon staff workloads. Hence the research question of this study is 'How do academic staff perceive the usefulness of an automated feedback system in terms of impact on workloads and quality of feedback?' This study used an automated feedback generator (AFG) across multiple tutors and assessment items within an MBA course delivered in a variety of modes. All academics marking in the course completed a survey based on an adaptation of the unified theory of acceptance and use of technology (UTAUT) model. Results indicated that while the workload impact was generally positive with savings in both cost and time, improvements and modifications to the system could further reduce workloads. Furthermore, results indicated that AFG improves quality in terms of timeliness, greater consistency between markers and an increase in the amount of feedback provided.},
  copyright = {Copyright (c)},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/2LQ5RKYB/Debuse et al. - 2008 - Educators' perceptions of automated feedback syste.pdf}
}

@article{demmeApproximateGraphClustering2012,
  title = {Approximate Graph Clustering for Program Characterization},
  author = {Demme, John and Sethumadhavan, Simha},
  year = {2012},
  month = jan,
  journal = {ACM Transactions on Architecture and Code Optimization},
  volume = {8},
  number = {4},
  pages = {21:1--21:21},
  issn = {1544-3566},
  doi = {10.1145/2086696.2086700},
  url = {https://dl.acm.org/doi/10.1145/2086696.2086700},
  urldate = {2023-11-23},
  abstract = {An important aspect of system optimization research is the discovery of program traits or behaviors. In this paper, we present an automated method of program characterization which is able to examine and cluster program graphs, i.e., dynamic data graphs or control flow graphs. Our novel approximate graph clustering technology allows users to find groups of program fragments which contain similar code idioms or patterns in data reuse, control flow, and context. Patterns of this nature have several potential applications including development of new static or dynamic optimizations to be implemented in software or in hardware. For the SPEC CPU 2006 suite of benchmarks, our results show that approximate graph clustering is effective at grouping behaviorally similar functions. Graph based clustering also produces clusters that are more homogeneous than previously proposed non-graph based clustering methods. Further qualitative analysis of the clustered functions shows that our approach is also able to identify some frequent unexploited program behaviors. These results suggest that our approximate graph clustering methods could be very useful for program characterization.},
  file = {/home/charlotte/sync/Zotero/storage/6WUFLLW5/Demme and Sethumadhavan - 2012 - Approximate graph clustering for program character.pdf}
}

@mastersthesis{deridderPapyrosSchrijvenUitvoeren2022,
  title = {{Papyros: schrijven, uitvoeren en testen van Python-code in de browser}},
  author = {De Ridder, Winnie and Van Petegem, Charlotte and Dawyndt, Peter and Mesuere, Bart},
  year = {2022},
  url = {http://lib.ugent.be/catalog/rug01:003059976},
  langid = {dutch},
  school = {Ghent University},
  file = {/home/charlotte/sync/Zotero/storage/HG3PDTXX/De Ridder et al. - 2022 - Papyros schrijven, uitvoeren en testen van Python.pdf}
}

@inproceedings{dianaInstructorDashboardRealtime2017,
  title = {An Instructor Dashboard for Real-Time Analytics in Interactive Programming Assignments},
  booktitle = {Proceedings of the {{Seventh International Learning Analytics}} \& {{Knowledge Conference}}},
  author = {Diana, Nicholas and Eagle, Michael and Stamper, John and Grover, Shuchi and Bienkowski, Marie and Basu, Satabdi},
  year = {2017},
  month = mar,
  series = {{{LAK}} '17},
  pages = {272--279},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3027385.3027441},
  url = {https://doi.org/10.1145/3027385.3027441},
  urldate = {2022-11-25},
  abstract = {Many introductory programming environments generate a large amount of log data, but making insights from these data accessible to instructors remains a challenge. This research demonstrates that student outcomes can be accurately predicted from student program states at various time points throughout the course, and integrates the resulting predictive models into an instructor dashboard. The effectiveness of the dashboard is evaluated by measuring how well the dashboard analytics correctly suggest that the instructor help students classified as most in need. Finally, we describe a method of matching low-performing students with high-performing peer tutors, and show that the inclusion of peer tutors not only increases the amount of help given, but the consistency of help availability as well.},
  isbn = {978-1-4503-4870-6},
  keywords = {dashboards,introductory programming,learning analytics,machine learning,peer tutors},
  file = {/home/charlotte/sync/Zotero/storage/Y4KAGAF2/Diana et al. - 2017 - An instructor dashboard for real-time analytics in.pdf}
}

@article{dijkstraCrueltyReallyTeaching1989,
  title = {On the Cruelty of Really Teaching Computing Science},
  author = {Dijkstra, Edsger W.},
  year = {1989},
  journal = {Communications of the ACM},
  volume = {32},
  number = {12},
  pages = {1398--1404},
  file = {/home/charlotte/sync/Zotero/storage/PC67MJGK/Dijkstra - 1989 - On the cruelty of really teaching computing scienc.pdf}
}

@article{dominguezEffectsAddingNonCompulsory2019,
  title = {The {{Effects}} of {{Adding Non-Compulsory Exercises}} to an {{Online Learning Tool}} on {{Student Performance}} and {{Code Copying}}},
  author = {Dom{\'i}nguez, C{\'e}sar and Jaime, Arturo and Heras, J{\'o}nathan and {Garc{\'i}a-Izquierdo}, Francisco J.},
  year = {2019},
  month = jan,
  journal = {ACM Transactions on Computing Education},
  volume = {19},
  number = {3},
  pages = {16:1--16:22},
  doi = {10.1145/3264507},
  url = {https://doi.org/10.1145/3264507},
  urldate = {2021-04-30},
  abstract = {This study analyzes the impact of adding a review exercises module to an online tool used in a software engineering degree program. The objective of the module is to promote students' self-learning effort to improve their performance. We also intend to determine if this new feature has any effect on the amount of code copies detected in lab sessions when using the same online tool. Two groups of students were compared quantitatively: the first group used the tool exclusively during lab sessions, whereas the second group had the option of employing the tool's new module to enhance their study. The tool allows us to collect interesting data related to the focus of this research: supplementary work completed voluntarily by students and the percentage of students copying others' code during compulsory lab sessions. The results show that the students in the second group achieved better academic results and copied less in lab sessions. In the second group, the students who invested more effort in doing revision exercises and copied less in lab sessions obtained better results; and, interestingly, the effort invested in completing review exercises did not seem to compensate for the learning effort avoided by copying others' exercises during lab sessions. The results show the advantages of a tool used with a dual orientation: compulsory and voluntary. Mandatory usage in lab sessions establishes some milestones that, eventually, act as an incentive fostering learning, while voluntary use reinforces students' perception of the tool's usefulness in terms of learning.},
  keywords = {academic performance,code copying,non-compulsory exercises,Online learning tool},
  file = {/home/charlotte/sync/Zotero/storage/3K2BNVJM/Domínguez et al. - 2019 - The Effects of Adding Non-Compulsory Exercises to .pdf}
}

@book{dooleySoftwareDevelopmentProfessional2011,
  title = {Software {{Development}} and {{Professional Practice}}},
  author = {Dooley, John},
  year = {2011},
  publisher = {{Apress}},
  address = {{Berkeley, CA}},
  doi = {10.1007/978-1-4302-3802-7},
  url = {http://link.springer.com/10.1007/978-1-4302-3802-7},
  urldate = {2022-08-16},
  isbn = {978-1-4302-3801-0 978-1-4302-3802-7},
  langid = {english}
}

@article{douceAutomaticTestbasedAssessment2005,
  title = {Automatic Test-Based Assessment of Programming: {{A}} Review},
  shorttitle = {Automatic Test-Based Assessment of Programming},
  author = {Douce, Christopher and Livingstone, David and Orwell, James},
  year = {2005},
  month = sep,
  journal = {Journal on Educational Resources in Computing},
  volume = {5},
  number = {3},
  pages = {4--es},
  issn = {1531-4278},
  doi = {10.1145/1163405.1163409},
  url = {https://doi.org/10.1145/1163405.1163409},
  urldate = {2022-08-16},
  abstract = {Systems that automatically assess student programming assignments have been designed and used for over forty years. Systems that objectively test and mark student programming work were developed simultaneously with programming assessment in the computer science curriculum. This article reviews a number of influential automatic assessment systems, including descriptions of the earliest systems, and presents some of the most recent developments. The final sections explore a number of directions automated assessment systems may take, presenting current developments alongside a number of important emerging e-learning specifications.},
  keywords = {computer-based training,Education,learning,programming assessment},
  file = {/home/charlotte/sync/Zotero/storage/EHFLBUCZ/Douce et al. - 2005 - Automatic test-based assessment of programming A .pdf}
}

@article{downesModelsSustainableOpen2007,
  title = {Models for {{Sustainable Open Educational Resources}}},
  author = {Downes, Stephen},
  year = {2007},
  month = jan,
  journal = {Interdisciplinary Journal of E-Learning and Learning Objects},
  volume = {3},
  number = {1},
  pages = {29--44},
  publisher = {{Informing Science Institute}},
  issn = {1552-2237},
  url = {https://www.learntechlib.org/p/44796/},
  urldate = {2022-10-03},
  abstract = {This paper depicts the sustainability of Open Educational Resources (OERs) in terms of the three models: funding, technical, and content. Discussion and recommendations are focused on the sustainability of OERs and the requirement that we think of OERs as only part of a larger picture -- one that includes volunteers and incentives, community and partnerships, co-production and sharing, distributed management and control.},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/H3X3P7FN/Downes - 2007 - Models for Sustainable Open Educational Resources.pdf;/home/charlotte/sync/Zotero/storage/EBCULPC9/44796.html}
}

@article{dunicanMakingAnalogyAlternative2002,
  title = {Making the Analogy: {{Alternative}} Delivery Techniques for First Year Programming Courses},
  shorttitle = {Making the Analogy},
  author = {Dunican, Enda},
  year = {2002},
  file = {/home/charlotte/sync/Zotero/storage/ESRSXNZD/Dunican - 2002 - Making the analogy Alternative delivery technique.pdf}
}

@article{duttSystematicReviewEducational2017,
  title = {A {{Systematic Review}} on {{Educational Data Mining}}},
  author = {Dutt, Ashish and Ismail, Maizatul Akmar and Herawan, Tutut},
  year = {2017},
  journal = {IEEE Access},
  volume = {5},
  pages = {15991--16005},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2017.2654247},
  abstract = {Presently, educational institutions compile and store huge volumes of data, such as student enrolment and attendance records, as well as their examination results. Mining such data yields stimulating information that serves its handlers well. Rapid growth in educational data points to the fact that distilling massive amounts of data requires a more sophisticated set of algorithms. This issue led to the emergence of the field of educational data mining (EDM). Traditional data mining algorithms cannot be directly applied to educational problems, as they may have a specific objective and function. This implies that a preprocessing algorithm has to be enforced first and only then some specific data mining methods can be applied to the problems. One such preprocessing algorithm in EDM is clustering. Many studies on EDM have focused on the application of various data mining algorithms to educational attributes. Therefore, this paper provides over three decades long (1983-2016) systematic literature review on clustering algorithm and its applicability and usability in the context of EDM. Future insights are outlined based on the literature reviewed, and avenues for further research are identified.},
  keywords = {Big data,Classification algorithms,Clustering algorithms,clustering methods,Clustering methods,Data mining,educational technology,Partitioning algorithms,systematic review,Systematics},
  file = {/home/charlotte/sync/Zotero/storage/CU7556ZS/Dutt et al. - 2017 - A Systematic Review on Educational Data Mining.pdf;/home/charlotte/sync/Zotero/storage/87M7RKHE/7820050.html}
}

@article{edwardsExperiencesUsingTestdriven2007,
  title = {Experiences Using Test-Driven Development with an Automated Grader},
  author = {Edwards, Stephen H. and {P{\'e}rez-Qui{\~n}ones}, Manuel A.},
  year = {2007},
  month = jan,
  journal = {Journal of Computing Sciences in Colleges},
  volume = {22},
  number = {3},
  pages = {44--50},
  issn = {1937-4771},
  abstract = {Including software testing practices in programming assignments has moved from a novel idea to accepted practice in recent years. Further, testing frameworks have spurred renewed interest in new approaches to automated grading, with some systems specifically aiming to give feedback on software testing skills. As more educators consider incorporating testing techniques in their own courses, lessons learned from using testing in the classroom as well as from using automated grading systems become more valuable. This paper summarizes experiences in using software testing in CS1- and CS2-level courses over the past three years. Among these experiences, this paper focuses on student perceptions of automated grading tools and how they might be addressed, approaches to designing project specifications, and strategies for providing meaningful feedback to students that can help improve their performance and reduce their frustration.},
  file = {/home/charlotte/sync/Zotero/storage/RYA3T7IP/Edwards and Pérez-Quiñones - 2007 - Experiences using test-driven development with an .pdf}
}

@inproceedings{edwardsSeparationSyntaxProblem2018,
  title = {Separation of Syntax and Problem Solving in {{Introductory Computer Programming}}},
  booktitle = {2018 {{IEEE Frontiers}} in {{Education Conference}} ({{FIE}})},
  author = {Edwards, John M. and Fulton, Erika K. and Holmes, Jonathan D. and Valentin, Joseph L. and Beard, David V. and Parker, Kevin R.},
  year = {2018},
  month = oct,
  pages = {1--5},
  issn = {2377-634X},
  doi = {10.1109/FIE.2018.8658852},
  abstract = {In this research work in progress paper, we discuss the possible benefits of separating syntax practice from problem-solving learning in an Introductory Computer Programming course. We propose a curriculum and associated development tool called Phanon that teach the rudiments of programming language through exercises done online outside of class. Having students complete exercises before class frees up classroom time and instructor face time for the higher-order learning tasks of problem decomposition and solving. We report results from a pilot study that are consistent with our hypothesis that these techniques result in improved student outcomes and attitudes and we discuss a future follow-up study.},
  keywords = {computer science,education,Education,Problem-solving,programming,Programming profession,Syntactics,Time measurement},
  file = {/home/charlotte/sync/Zotero/storage/TDG5PQJJ/Edwards et al. - 2018 - Separation of syntax and problem solving in Introd.pdf;/home/charlotte/sync/Zotero/storage/M56ABAC9/8658852.html}
}

@inproceedings{edwardsUsingSoftwareTesting2004,
  title = {Using Software Testing to Move Students from Trial-and-Error to Reflection-in-Action},
  booktitle = {Proceedings of the 35th {{SIGCSE}} Technical Symposium on {{Computer}} Science Education},
  author = {Edwards, Stephen H.},
  year = {2004},
  month = mar,
  series = {{{SIGCSE}} '04},
  pages = {26--30},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/971300.971312},
  url = {https://doi.org/10.1145/971300.971312},
  urldate = {2022-03-03},
  abstract = {Introductory computer science students rely on a trial and error approach to fixing errors and debugging for too long. Moving to a reflection in action strategy can help students become more successful. Traditional programming assignments are usually assessed in a way that ignores the skills needed for reflection in action, but software testing promotes the hypothesis-forming and experimental validation that are central to this mode of learning. By changing the way assignments are assessed--where students are responsible for demonstrating correctness through testing, and then assessed on how well they achieve this goal--it is possible to reinforce desired skills. Automated feedback can also play a valuable role in encouraging students while also showing them where they can improve.},
  isbn = {978-1-58113-798-9},
  keywords = {automated grading,CS1,extreme programming,pedagogy,test-driven development},
  file = {/home/charlotte/sync/Zotero/storage/TM3AG8YJ/Edwards - 2004 - Using software testing to move students from trial.pdf}
}

@inproceedings{edwardsWebCATAutomaticallyGrading2008,
  title = {Web-{{CAT}}: Automatically Grading Programming Assignments},
  shorttitle = {Web-{{CAT}}},
  booktitle = {Proceedings of the 13th Annual Conference on {{Innovation}} and Technology in Computer Science Education},
  author = {Edwards, Stephen H. and {Perez-Quinones}, Manuel A.},
  year = {2008},
  month = jun,
  series = {{{ITiCSE}} '08},
  pages = {328},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1384271.1384371},
  url = {https://dl.acm.org/doi/10.1145/1384271.1384371},
  urldate = {2023-08-21},
  abstract = {This demonstration introduces participants to using Web-CAT, an open-source automated grading system. Web-CAT is customizable and extensible, allowing it to support a wide variety of programming languages and assessment strategies. Web-CAT is most well-known as the system that "grades students on how well they test their own code," with experimental evidence that it offers greater learning benefits than more traditional output-comparison grading. Participants will learn how to set up courses, prepare reference tests, set up assignments, and allow graders to manually grade for design.},
  isbn = {978-1-60558-078-4},
  keywords = {assessment,automated grading,evaluation,feedback,manual grading,marking,programming assignment},
  file = {/home/charlotte/sync/Zotero/storage/9VQMRN4M/Edwards and Perez-Quinones - 2008 - Web-CAT automatically grading programming assignm.pdf}
}

@inproceedings{edwardsWebCATWebbasedCenter2006,
  title = {Web-{{CAT}} : The {{Web-based Center}} for {{Automated Testing}}},
  shorttitle = {Web-{{CAT}}},
  author = {Edwards, S.},
  year = {2006},
  url = {https://www.semanticscholar.org/paper/Web-CAT-%3A-the-Web-based-Center-for-Automated-Edwards/9bad816ad294dfdf13599a7e3ac11e72d77af7fc},
  urldate = {2024-02-20},
  abstract = {The Web-CAT software system for evaluating student programming assignments has had substantial impact both within Virginia Tech and in other universities. Web-CAT, the Web-based Center for Automated Testing, is a tool that provides rapid, directed comments on student work, encourages students to write software tests for their own work, and empowers students with the responsibility of demonstrating the correctness and validity of their own programs. Web-CAT has allowed Dr. Edwards to transform the way programming assignments are given and assessed in our freshman and sophomore CS programming courses. While students have always focused on ``writing code,'' Web-CAT has given instructors a tool that encourages students to step back and reflect on their own work and what they are trying to achieve. Web-CAT does not grade student programs for correctness---instead, the student is responsible for demonstrating correctness by writing and running test cases. Each test case is a minihypothesis about how the student believes his or her program should work, and students continually write, refine, and experimentally validate these hypotheses as they develop solutions. Web-CAT then grades students on how well they test their own programs, that is, how rigorous and convincing is their own demonstration of the correctness of their own work. As a result, students learn more and produce higher-quality code. Students who use Web-CAT produce an average of 28\% fewer program bugs, are more likely to turn their work in on time, and receive higher scores. Further, students see clear benefits to using Web-CAT, since it increases their confidence in the correctness of their own work, helps them incrementally develop solutions, and reduces some of the most frustrating factors that cause students to fail to complete working solutions. The lessons learned from these development efforts have been disseminated through journal articles, conference papers, demonstrations, poster presentations, workshop papers, and four tutorials at national conferences.}
}

@article{elbadrawyPredictingStudentPerformance2016,
  title = {Predicting {{Student Performance Using Personalized Analytics}}},
  author = {Elbadrawy, Asmaa and Polyzou, Agoritsa and Ren, Zhiyun and Sweeney, Mackenzie and Karypis, George and Rangwala, Huzefa},
  year = {2016},
  month = apr,
  journal = {Computer},
  volume = {49},
  number = {4},
  pages = {61--69},
  issn = {1558-0814},
  doi = {10.1109/MC.2016.119},
  abstract = {To help solve the ongoing problem of student retention, new expected performance-prediction techniques are needed to facilitate degree planning and determine who might be at risk of failing or dropping a class. Personalized multiregression and matrix factorization approaches based on recommender systems, initially developed for e-commerce applications, accurately forecast students' grades in future courses as well as on in-class assessments.},
  keywords = {big data,Big data,computing in education,data analysis,data mining,Data models,Data retention,Education,learning-management systems,LMSs,massive open online courses,matrix factorization,MOOCs,multilinear regression,Predictive models,recommender systems,Recommender systems,Servers},
  file = {/home/charlotte/sync/Zotero/storage/L63BQ9D6/Elbadrawy et al. - 2016 - Predicting Student Performance Using Personalized .pdf;/home/charlotte/sync/Zotero/storage/2K9HRDGJ/7452320.html}
}

@inproceedings{engelbart1968research,
  title = {A Research Center for Augmenting Human Intellect},
  booktitle = {Proceedings of the {{December}} 9-11, 1968, Fall Joint Computer Conference, Part {{I}}},
  author = {Engelbart, Douglas C and English, William K},
  year = {1968},
  pages = {395--410},
  file = {/home/charlotte/sync/Zotero/storage/W5GNPHGI/Engelbart and English - 1968 - A research center for augmenting human intellect.pdf}
}

@article{epsteinImmediateFeedbackAcademic2001,
  title = {Immediate {{Feedback}} during {{Academic Testing}}},
  author = {Epstein, Michael L. and Epstein, Beth B. and Brosvic, Gary M.},
  year = {2001},
  month = jun,
  journal = {Psychological Reports},
  volume = {88},
  number = {3},
  pages = {889--894},
  publisher = {{SAGE Publications Inc}},
  issn = {0033-2941},
  doi = {10.2466/pr0.2001.88.3.889},
  url = {https://doi.org/10.2466/pr0.2001.88.3.889},
  urldate = {2022-02-24},
  abstract = {Performance on two multiple-choice testing procedures was examined during unit tests and a final examination. The Immediate Feedback Assessment Technique provided immediate response feedback in an answer-until-correct style of responding. The testing format which served as a point of comparison was the Scantron form. One format was completed by students in introductory psychology courses during unit tests whereas all students used the Scantron form on the final examination. Students tested with Immediate Feedback forms on the unit tests correctly answered more of the final examination questions which were repeated from earlier unit tests than did students tested with Scantron forms. Also, students tested with Immediate Feedback forms correctly answered more final examination questions previously answered incorrectly on the unit tests than did students tested previously with Scantron forms.},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/BRNBWF32/Epstein et al. - 2001 - Immediate Feedback during Academic Testing.pdf}
}

@article{ernstDynamicallyDiscoveringLikely2001,
  title = {Dynamically Discovering Likely Program Invariants to Support Program Evolution},
  author = {Ernst, M.D. and Cockrell, J. and Griswold, W.G. and Notkin, D.},
  year = {2001},
  month = feb,
  journal = {IEEE Transactions on Software Engineering},
  volume = {27},
  number = {2},
  pages = {99--123},
  issn = {1939-3520},
  doi = {10.1109/32.908957},
  abstract = {Explicitly stated program invariants can help programmers by identifying program properties that must be preserved when modifying code. In practice, however, these invariants are usually implicit. An alternative to expecting programmers to fully annotate code with invariants is to automatically infer likely invariants from the program itself. This research focuses on dynamic techniques for discovering invariants from execution traces. This article reports three results. First, it describes techniques for dynamically discovering invariants, along with an implementation, named Daikon, that embodies these techniques. Second, it reports on the application of Daikon to two sets of target programs. In programs from Gries's work (1981) on program derivation, the system rediscovered predefined invariants. In a C program lacking explicit invariants, the system discovered invariants that assisted a software evolution task. These experiments demonstrate that, at least for small programs, invariant inference is both accurate and useful. Third, it analyzes scalability issues, such as invariant detection runtime and accuracy, as functions of test suites and program points instrumented.},
  keywords = {Application software,Computer Society,Detectors,Formal specifications,Instruments,Pattern analysis,Programming profession,Runtime,Scalability,Testing},
  file = {/home/charlotte/sync/Zotero/storage/M76XJUUV/Ernst et al. - 2001 - Dynamically discovering likely program invariants .pdf;/home/charlotte/sync/Zotero/storage/ZNQ82TZZ/908957.html}
}

@article{farrellAssertionsProtocolOASIS2002,
  title = {Assertions and {{Protocol}} for the {{OASIS Security Assertion Markup Language}} ({{SAML}})},
  author = {Farrell, Stephen and Reid, Irving and Orchard, David and Sankar, Krishna and Moses, Tim and Edwards, Entrust Nigel and Pato, Joe and Knouse, Charles and Cantor, Oblix Scott and Platt, Darren},
  year = {2002},
  journal = {Organization for the Advancement of Structured Information Standards (OASIS) Standard (November 2002), http://www. oasis-open. org/committees/download. php/1371/oasis-sstc-saml-core-1.0. pdf},
  file = {/home/charlotte/sync/Zotero/storage/US6RPQBH/Farrell et al. - 2002 - Assertions and Protocol for the OASIS Security Ass.pdf}
}

@inproceedings{feldmanAnsweringAmRight2019,
  title = {Towards Answering ``{{Am I}} on the Right Track?'' Automatically Using Program Synthesis},
  shorttitle = {Towards Answering ``{{Am I}} on the Right Track?},
  booktitle = {Proceedings of the 2019 {{ACM SIGPLAN Symposium}} on {{SPLASH-E}}},
  author = {Feldman, Molly Q and Wang, Yiting and Byrd, William E. and Guimbreti{\`e}re, Fran{\c c}ois and Andersen, Erik},
  year = {2019},
  month = oct,
  series = {{{SPLASH-E}} 2019},
  pages = {13--24},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3358711.3361626},
  url = {https://dl.acm.org/doi/10.1145/3358711.3361626},
  urldate = {2024-01-22},
  abstract = {Students learning to program often need help completing assignments and understanding why their code does not work as they expect it to. One common place where they seek such help is at teaching assistant office hours. We found that teaching assistants in introductory programming (CS1) courses frequently answer some variant of the question ``Am I on the Right Track?''. The goal of this work is to develop an automated tool that provides similar feedback for students in real-time from within an IDE as they are writing their program. Existing automated tools lack the generality that we seek, often assuming a single approach to a problem, using hand-coded error models, or applying sample fixes from other students. In this paper, we explore the use of program synthesis to provide less constrained automated answers to ``Am I on the Right Track'' (AIORT) questions. We describe an observational study of TA-student interactions that supports targeting AIORT questions, as well as the development of and design considerations behind a prototype integrated development environment (IDE). The IDE uses an existing program synthesis engine to determine if a student is on the right track and we present pilot user studies of its use.},
  isbn = {978-1-4503-6989-3},
  keywords = {Computer science education,program synthesis,user interfaces},
  file = {/home/charlotte/sync/Zotero/storage/7QWDMXTP/feldman2019.pdf.pdf;/home/charlotte/sync/Zotero/storage/AZFIKMYP/Feldman et al. - 2019 - Towards answering “Am I on the right track” autom.pdf}
}

@article{fergusonInconsistentMaximumLikelihood1982,
  title = {An {{Inconsistent Maximum Likelihood Estimate}}},
  author = {Ferguson, Thomas S.},
  year = {1982},
  month = dec,
  journal = {Journal of the American Statistical Association},
  volume = {77},
  number = {380},
  pages = {831--834},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.1982.10477894},
  url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1982.10477894},
  urldate = {2021-02-19},
  abstract = {An example is given of a family of distributions on [--- 1, 1] with a continuous one-dimensional parameterization that joins the triangular distribution (when {$\Theta$} = 0) to the uniform (when {$\Theta$} = 1), for which the maximum likelihood estimates exist and converge strongly to {$\Theta$} = 1 as the sample size tends to infinity, whatever be the true value of the parameter. A modification that satisfies Cram{\'e}r's conditions is also given.},
  keywords = {Asymptotic efficiency,Inconsistency,Maximum likelihood estimates,Mixtures},
  file = {/home/charlotte/sync/Zotero/storage/QEWUSYDZ/01621459.1982.html}
}

@article{fergusonLearningAnalyticsDrivers2012,
  title = {Learning Analytics: Drivers, Developments and Challenges},
  shorttitle = {Learning Analytics},
  author = {Ferguson, Rebecca},
  year = {2012},
  journal = {International Journal of Technology Enhanced Learning},
  volume = {4},
  number = {5/6},
  pages = {304--317},
  issn = {1753-5263},
  url = {http://www.inderscience.com/info/ingeneral/forthcoming.php?jcode=ijtel},
  urldate = {2022-08-16},
  abstract = {Learning analytics is a significant area of technology-enhanced learning that has emerged during the last decade. This review of the field begins with an examination of the technological, educational and political factors that have driven the development of analytics in educational settings. It goes on to chart the emergence of learning analytics, including their origins in the 20th century, the development of data-driven analytics, the rise of learning-focused perspectives and the influence of national economic concerns. It next focuses on the relationships between learning analytics, educational data mining and academic analytics. Finally, it examines developing areas of learning analytics research, and identifies a series of future challenges.},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/D5IYWZI3/Ferguson - 2012 - Learning analytics drivers, developments and chal.pdf;/home/charlotte/sync/Zotero/storage/UT6YF5KM/36374.html}
}

@inproceedings{fincherWhatAreWe1999,
  title = {What Are We Doing When We Teach Programming?},
  booktitle = {{{FIE}}'99 {{Frontiers}} in {{Education}}. 29th {{Annual Frontiers}} in {{Education Conference}}. {{Designing}} the {{Future}} of {{Science}} and {{Engineering Education}}. {{Conference Proceedings}} ({{IEEE Cat}}. {{No}}.{{99CH37011}}},
  author = {Fincher, S.},
  year = {1999},
  month = nov,
  volume = {1},
  pages = {12A4/1-12A4/5 vol.1},
  issn = {0190-5848},
  doi = {10.1109/FIE.1999.839268},
  abstract = {The academic discipline of computer science uniquely prepares students for future study by teaching the fundamental construct of its practice-programming- before anything else. The disciplinary argument seems to run that if a student is not versed in the practicalities, then they cannot appreciate the underlying concepts of the discipline. This may be true. However an analogous simulation would be if it were thought necessary for architecture students to be taught bricklaying before they could appreciate the fundamentals of building design. This argument is clearly flawed when compared to endeavours such as the study of English Literature, which makes no claim to teach the practice of producing work before the study of the products of others work. It is possible that this is an argument of disciplinary maturity-that all disciplines have passed through a similar phase. This paper examines the emergent approaches being defined, all of which address the central concern of the teaching of programming and its relationship to the learning of computer science. It examines: the "syntax-free" approach of Richard Bornat and Russel Shackelford, the "problem-solving" approach of David Barnes (et al.), the "literacy" approach of Peter Juliff and Owen Astrachan and the "computation-as-interaction" approach of Lynn Andrea Stein. These approaches are discussed both in their own terms, and also placed in a preliminary taxonomic framework for the teaching of programming.},
  keywords = {Computer science,Education,Laboratories,Vehicles},
  file = {/home/charlotte/sync/Zotero/storage/HT6KLTBM/Fincher - 1999 - What are we doing when we teach programming.pdf;/home/charlotte/sync/Zotero/storage/359UNGNZ/839268.html}
}

@inproceedings{fonsecaWebbasedPlatformMethodology2023,
  title = {A Web-Based Platform and a Methodology to Teach Programming Languages in Electrical Engineering Education -- Evolution and Student Feedback},
  booktitle = {2023 32nd {{Annual Conference}} of the {{European Association}} for {{Education}} in {{Electrical}} and {{Information Engineering}} ({{EAEEIE}})},
  author = {Fonseca, In{\'a}cio and Martins, Nuno Cid and Lopes, Fernando},
  year = {2023},
  month = jun,
  pages = {1--3},
  issn = {2472-7687},
  doi = {10.23919/EAEEIE55804.2023.10181316},
  url = {https://ieeexplore.ieee.org/abstract/document/10181316},
  urldate = {2023-10-02},
  abstract = {The teaching of diverse programming topics and languages is a fundamental component of electrical engineering education. However, it is a complex task facing many challenges such as the need to accommodate students with very different programming backgrounds and with very different levels of motivation for the programming field -- these are classical difficulties with electrical engineering candidates.A web-based collaborative tool and a methodology to support student interaction and assistance in classroom teaching of programming languages in electrical engineering courses were presented in [1]. The main technological choices and functionalities, as well as examples of implemented courses, were described. The tool was developed aiming to be flexible, scalable and with high evolution potential.In this paper, we present the evolution of the basis tool through technology improvements, a set of new functionalities and added programming languages. The main technology upgrades include the full integration of the Visual Studio Code for the Web editor, a new web interface we called iWeb-TD and the expansion of the multi-user capabilities. In terms of functionalities, in addition to PHP and Octave, it is now possible to teach C/C++, Python, Java, and ipynb. A new major component is the integration of active debugging with step execution for all supported languages. This is a fundamental aspect that allows students with weak programming skills to evolve in a structured form. The tool can also allow the teacher to develop and test pedagogical elements in Python or Octave and publish them for student access in read-only mode using the Jupyter-Notebook technology.The paper includes example pedagogical elements for two electrical engineering courses taught using the enhanced platform, including the compilation of associated student feedback.},
  file = {/home/charlotte/sync/Zotero/storage/WPW7AYUK/Fonseca et al. - 2023 - A web-based platform and a methodology to teach pr.pdf;/home/charlotte/sync/Zotero/storage/SIFC9TWB/10181316.html}
}

@article{forisekSecurityProgrammingContest2006,
  title = {Security of Programming Contest Systems},
  author = {Fori{\v s}ek, Michal},
  year = {2006},
  journal = {Information Technologies at School},
  pages = {553--563},
  publisher = {{2nd International Conference on Informatics in Secondary Schools: Evolution {\dots}}}
}

@article{forisekSuitabilityProgrammingTasks2006,
  title = {On the {{Suitability}} of {{Programming Tasks}} for {{Automated Evaluation}}},
  author = {Forisek, Michal},
  year = {2006},
  month = apr,
  journal = {Informatics in Education},
  volume = {5},
  number = {1},
  pages = {63--76},
  publisher = {{Vilnius University Institute of Data Science and Digital Technologies}},
  issn = {1648-5831, 2335-8971},
  doi = {10.15388/infedu.2006.05},
  url = {https://www.infedu.vu.lt/journal/INFEDU/article/570},
  urldate = {2022-08-16},
  abstract = {For many programming tasks we would be glad to have some kind of automatic evaluation process. As an example, most of the programming contests use an automatic evaluation of the contestants' submissions. While this approach is clearly highly efficient, it also has some drawbacks. Often it is the case that the test inputs are not able to ``break'' all flawed submissions. In this article we show that the situation is not pleasant at all - for some programming tasks it is impossible to design good test inputs. Moreover, we discuss some ways how to recognize such tasks, and discuss other possibilities for doing the evaluation. The discussion is focused on programming contests, but the results can be applied for any programming tasks, e.g., assignments in school.},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/UBH6XC83/Forisek - 2006 - On the Suitability of Programming Tasks for Automa.pdf;/home/charlotte/sync/Zotero/storage/3RU4ZGIG/info.html}
}

@article{forsbergPerceivedFairnessBackground2009,
  title = {Perceived {{Fairness}} of a {{Background Information Form}} and a {{Job Knowledge Test}}},
  author = {Forsberg, Anna M. and Shultz, Kenneth S.},
  year = {2009},
  month = mar,
  journal = {Public Personnel Management},
  volume = {38},
  number = {1},
  pages = {33--46},
  publisher = {{SAGE Publications Inc}},
  issn = {0091-0260},
  doi = {10.1177/009102600903800103},
  url = {https://doi.org/10.1177/009102600903800103},
  urldate = {2021-04-30},
  abstract = {Applicants for the jobs of engineering aide and plumber with a large public employer were asked to provide their assessments of the perceived fairness of two different HR selection devices---a background information form and a written job knowledge test. Significant differences were found in the applicants' perceptions of the fairness of the two selection devices. In addition, the differences found depended on the classification of the job for which individuals were applying. Specifically, engineering aide applicants saw the background information inventory as more just, while plumber applicants preferred the written exam. Implications of the results for HR selection are discussed.},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/4IGJ3LIJ/Forsberg and Shultz - 2009 - Perceived Fairness of a Background Information For.pdf}
}

@article{forsytheAutomaticGradingPrograms1965,
  title = {Automatic Grading Programs},
  author = {Forsythe, George E. and Wirth, Niklaus},
  year = {1965},
  month = may,
  journal = {Communications of the ACM},
  volume = {8},
  number = {5},
  pages = {275--278},
  issn = {0001-0782},
  doi = {10.1145/364914.364937},
  url = {https://dl.acm.org/doi/10.1145/364914.364937},
  urldate = {2024-02-06},
  file = {/home/charlotte/sync/Zotero/storage/4WT3CXI4/Forsythe and Wirth - 1965 - Automatic grading programs.pdf;/home/charlotte/sync/Zotero/storage/6E4CRJY3/forsythe1965.pdf.pdf}
}

@article{gibbsConditionsWhichAssessment2005,
  title = {Conditions {{Under Which Assessment Supports Students}}' {{Learning}}},
  author = {Gibbs, Graham and Simpson, Claire},
  year = {2005},
  journal = {Learning and Teaching in Higher Education},
  number = {1},
  pages = {3--31},
  publisher = {{University of Gloucestershire}},
  issn = {1742-240X},
  url = {https://eprints.glos.ac.uk/3609/},
  urldate = {2022-02-21},
  abstract = {Much evaluation of teaching focuses on what teachers do in class. This article focuses on the evaluation of assessment arrangements and the way they affect student learning out of class. It is assumed that assessment has an overwhelming influence on what, how and how much students study. The article proposes a set of `conditions under which assessment supports learning' and justifies these with reference to theory, empirical evidence and practical experience. These conditions are offered as a framework for teachers to review the effectiveness of their own assessment practice.},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/C73HNGSD/Gibbs and Simpson - 2005 - Conditions Under Which Assessment Supports Student.pdf;/home/charlotte/sync/Zotero/storage/MXJULSHV/3609.html}
}

@article{gielenImprovingEffectivenessPeer2010,
  title = {Improving the Effectiveness of Peer Feedback for Learning},
  author = {Gielen, Sarah and Peeters, Elien and Dochy, Filip and Onghena, Patrick and Struyven, Katrien},
  year = {2010},
  month = aug,
  journal = {Learning and Instruction},
  series = {Unravelling {{Peer Assessment}}},
  volume = {20},
  number = {4},
  pages = {304--315},
  issn = {0959-4752},
  doi = {10.1016/j.learninstruc.2009.08.007},
  url = {https://www.sciencedirect.com/science/article/pii/S0959475209000759},
  urldate = {2021-09-15},
  abstract = {The present study examined the effectiveness of (a) peer feedback for learning, more specifically of certain characteristics of the content and style of the provided feedback, and (b) a particular instructional intervention to support the use of the feedback. A quasi-experimental repeated measures design was adopted. Writing assignments of 43 students of Grade 7 in secondary education showed that receiving `justified' comments in feedback improves performance, but this effect diminishes for students with better pretest performance. Justification was superior to the accuracy of comments. The instructional intervention of asking assessees to reflect upon feedback after peer assessment did not increase learning gains significantly.},
  langid = {english},
  keywords = {Feedback accuracy,Peer assessment,Peer feedback,Revision,Writing},
  file = {/home/charlotte/sync/Zotero/storage/ZV6YGHVX/Gielen et al. - 2010 - Improving the effectiveness of peer feedback for l.pdf;/home/charlotte/sync/Zotero/storage/IXWTQUEY/S0959475209000759.html}
}

@article{gielenPeerAssessmentWiki2012,
  title = {Peer {{Assessment}} in a {{Wiki}}: {{Product Improvement}}, {{Students}}' {{Learning And Perception Regarding Peer Feedback}}},
  shorttitle = {Peer {{Assessment}} in a {{Wiki}}},
  author = {Gielen, Mario and De Wever, Bram},
  year = {2012},
  month = dec,
  journal = {Procedia - Social and Behavioral Sciences},
  series = {International {{Conference}} on {{Education}} \& {{Educational Psychology}} ({{ICEEPSY}} 2012)},
  volume = {69},
  pages = {585--594},
  issn = {1877-0428},
  doi = {10.1016/j.sbspro.2012.11.450},
  url = {https://www.sciencedirect.com/science/article/pii/S1877042812054365},
  urldate = {2021-09-15},
  abstract = {The present study examines the added value of peer assessment in a computer-supported collaborative learning environment (CSCL) in higher education by focusing on (1) the learning effect, (2) wiki product improvement and (3) students' perception of peer feedback in a CSCL-environment. The present study involved two conditions: structured peer feedback (S-PFB) and non-structured (control). The results do not indicate a significant learning effect between pretest and posttest or between the conditions. However, for both conditions the peer feedback process improved significantly the quality of the wiki product from draft to final version, although no significant differences between the control and the experimental group (S-PFB) were found. Furthermore, the S-PFB group adopted a more critical attitude when providing and receiving peer feedback. The S-PFB group also perceived the received peer feedback as being more profound and detailed.},
  langid = {english},
  keywords = {Computer-supported collaborative learning (CSCL),Peer assessment,Peer feedback,Structuring peer feedback,Wiki},
  file = {/home/charlotte/sync/Zotero/storage/A2VG7MMD/Gielen and De Wever - 2012 - Peer Assessment in a Wiki Product Improvement, St.pdf;/home/charlotte/sync/Zotero/storage/M8XVAWP9/S1877042812054365.html}
}

@inproceedings{giraffaTeachingObjectOrientedProgramming2014,
  title = {Teaching {{Object-Oriented Programming}} in {{First-Year Undergraduate Courses Supported By Virtual Classrooms}}},
  booktitle = {The 2nd {{International Workshop}} on {{Learning Technology}} for {{Education}} in {{Cloud}}},
  author = {Giraffa, Lucia M. M. and Moraes, Marcia Cristina and Uden, Lorna},
  editor = {Uden, Lorna and Tao, Yu-Hui and Yang, Hsin-Chang and Ting, I-Hsien},
  year = {2014},
  series = {Springer {{Proceedings}} in {{Complexity}}},
  pages = {15--26},
  publisher = {{Springer Netherlands}},
  address = {{Dordrecht}},
  doi = {10.1007/978-94-007-7308-0_2},
  abstract = {Students struggle to learn computer programming. In recent years, there has been a dramatic drop in the number of students enrolling in IT and computer science courses. There is high dropout rate among first year students undertaking computer science courses. Because introductory programming courses traditionally have a high failure rate, this has been a barrier for students and staff in computer science faculties. Programming is acknowledged by many to be an inherently complex, intellectual activity with students struggling through their first programming subjects and lecturers are struggling to teach it. This problem is no different at School of Computer Science at PUCRS in Brazil. The department has for many years trying to improve the teaching of programming courses to the students. This paper describes the use of a classroom in the MOODLE environment to teach Java programming to first year students.},
  isbn = {978-94-007-7308-0},
  langid = {english},
  keywords = {Algorithms,Teaching methodologies evaluation,Teaching programming},
  file = {/home/charlotte/sync/Zotero/storage/QWJTTHIV/Giraffa et al. - 2014 - Teaching Object-Oriented Programming in First-Year.pdf}
}

@article{glassFewerStudentsAre2022,
  title = {Fewer Students Are Benefiting from Doing Their Homework: An Eleven-Year Study},
  shorttitle = {Fewer Students Are Benefiting from Doing Their Homework},
  author = {Glass, Arnold L. and Kang, Mengxue},
  year = {2022},
  month = feb,
  journal = {Educational Psychology},
  volume = {42},
  number = {2},
  pages = {185--199},
  publisher = {{Routledge}},
  issn = {0144-3410},
  doi = {10.1080/01443410.2020.1802645},
  url = {https://doi.org/10.1080/01443410.2020.1802645},
  urldate = {2022-08-16},
  abstract = {Performance on homework questions was compared with performance on related exam questions querying the same fact or principle, was used to assess the effect of answering online homework questions on subsequent exam performance. A distinctive pattern of performance was found for some students in which superior performance on online homework questions resulted in poorer exam performance. When assessed over an eleven-year period, for 2433 students in 12 different college lecture courses, the percent of students who did not benefit from correctly answering homework questions increased from 14\% in 2008 to 55\% in 2017. During the most recent two years of the study, when students were asked how they did their homework, students who benefitted from homework reported generating their own answers and students who reported copying the answers from another source did not benefit from homework.},
  keywords = {Generation effect,long-term memory,testing effect}
}

@article{gooldFactorsAffectingPerformance2000,
  title = {Factors Affecting Performance in First-Year Computing},
  author = {Goold, Annagret and Rimmer, Russell},
  year = {2000},
  month = jun,
  journal = {ACM SIGCSE Bulletin},
  volume = {32},
  number = {2},
  pages = {39--43},
  issn = {0097-8418},
  doi = {10.1145/355354.355369},
  url = {https://doi.org/10.1145/355354.355369},
  urldate = {2022-02-17},
  abstract = {Performances are analysed over successive semesters for a cohort of first-year students doing computer programming. Attainment is related to performance in other studies. However, many factors have roles. Learning style and problem-solving skills are important in information technology in Semester I. Gender and secondary school outcomes matter in introductory programming, also in Semester I. Dislike of programming influences outcomes in introductory programming and in Data Structures and Algorithms in Semester II. For a number of indicators, influence fluctuates over time and across area of study.},
  file = {/home/charlotte/sync/Zotero/storage/C5V99SA8/Goold and Rimmer - 2000 - Factors affecting performance in first-year comput.pdf}
}

@article{gordonUndergraduateTeachingAssistants2013,
  title = {Undergraduate {{Teaching Assistants}}: {{A Learner-Centered Model}} for {{Enhancing Student Engagement}} in the {{First-Year Experience}}},
  shorttitle = {Undergraduate {{Teaching Assistants}}},
  author = {Gordon, Jessica and Henry, Peter and Dempster, Michaux},
  year = {2013},
  journal = {International Journal of Teaching and Learning in Higher Education},
  volume = {25},
  number = {1},
  pages = {103--109},
  publisher = {{International Society for Exploring Teaching and Learning}},
  issn = {1812-9129},
  url = {https://eric.ed.gov/?id=EJ1016536},
  urldate = {2022-10-03},
  abstract = {In this paper, we provide an in-depth view of the Undergraduate Teaching Assistant (UTA) program  at Virginia Commonwealth University as a potential model for other large research universities who might wish to implement similar learner-centered initiatives in their first-year experience courses. Unlike graduate teaching assistants, whose primary objective in the classroom is to assist the professor, the UTAs assist the students by facilitating student engagement, offering peer-to-peer assistance, and modeling successful academic practices. The UTA program, founded in 2008, is integrated through all levels of VCU's University College. This paper explores the benefits offered to all stakeholders: faculty, students, and undergraduate teaching assistants.},
  langid = {english},
  keywords = {College Faculty,College Freshmen,Correlation,Course Descriptions,Experiential Learning,Interdisciplinary Approach,Leadership Training,Learner Engagement,Mentors,Peer Relationship,Research Universities,Student Role,Teaching Assistants,Undergraduate Students},
  file = {/home/charlotte/sync/Zotero/storage/6XLM87XC/Gordon et al. - 2013 - Undergraduate Teaching Assistants A Learner-Cente.pdf;/home/charlotte/sync/Zotero/storage/5G69JJB4/eric.ed.gov.html}
}

@book{grahamFoundationsSoftwareTesting2021,
  title = {Foundations of {{Software Testing ISTQB Certification}}, 4th Edition},
  author = {Graham, Dorothy and Black, Rex and van Veenendaal, Erik},
  year = {2021},
  month = jun,
  publisher = {{Cengage Learning}},
  abstract = {Now in its fourth edition, Foundations of Software Testing: ISTQB Certification is the essential guide to software testing and to the ISTQB Foundation qualification. Completely updated to comprehensively reflect the most recent changes to the 2018 ISTQB Foundation Syllabus, the book adopts a practical, hands-on approach, covering the fundamental topics that every system and software tester should know. The authors are themselves developers of the ISTQB syllabus and are highly respected international authorities and teachers within the field of software testing. About ISTQB ISTQB is a multinational body overseeing the development of international qualifications in software testing. It offers an internationally recognized qualification that ensures there is an international, common understanding of software and system testing issues.},
  googlebooks = {mOwxEAAAQBAJ},
  isbn = {978-0-357-88415-7},
  langid = {english},
  keywords = {Computers / Software Development & Engineering / General}
}

@article{grgic-hlacaCaseProcessFairness2018,
  title = {The {{Case}} for {{Process Fairness}} in {{Learning}}: {{Feature Selection}} for {{Fair Decision Making}}},
  author = {{Grgi{\'c}-Hla{\v c}a}, Nina and Zafar, Muhammad Bilal and Gummadi, Krishna P and Weller, Adrian},
  year = {2018},
  pages = {11},
  abstract = {Machine learning methods are increasingly being used to inform, or sometimes even directly to make, important decisions about humans. A number of recent works have focussed on the fairness of the outcomes of such decisions, particularly on avoiding decisions that affect users of different sensitive groups (e.g., race, gender) disparately. In this paper, we propose to consider the fairness of the process of decision making. Process fairness can be measured by estimating the degree to which people consider various features to be fair to use when making an important legal decision. We examine the task of predicting whether or not a prisoner is likely to commit a crime again once released by analyzing the dataset considered by ProPublica relating to the COMPAS system. We introduce new measures of people's discomfort with using various features, show how these measures can be estimated, and consider the effect of removing the uncomfortable features on prediction accuracy and on outcome fairness. Our empirical analysis suggests that process fairness may be achieved with little cost to outcome fairness, but that some loss of accuracy is unavoidable.},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/5LLYV7RM/Grgic-Hlacˇa et al. - The Case for Process Fairness in Learning Feature.pdf}
}

@inproceedings{guoOnlinePythonTutor2013,
  title = {Online Python Tutor: Embeddable Web-Based Program Visualization for Cs Education},
  shorttitle = {Online Python Tutor},
  booktitle = {Proceeding of the 44th {{ACM}} Technical Symposium on {{Computer}} Science Education},
  author = {Guo, Philip J.},
  year = {2013},
  month = mar,
  series = {{{SIGCSE}} '13},
  pages = {579--584},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2445196.2445368},
  url = {https://doi.org/10.1145/2445196.2445368},
  urldate = {2022-08-16},
  abstract = {This paper presents Online Python Tutor, a web-based program visualization tool for Python, which is becoming a popular language for teaching introductory CS courses. Using this tool, teachers and students can write Python programs directly in the web browser (without installing any plugins), step forwards and backwards through execution to view the run-time state of data structures, and share their program visualizations on the web. In the past three years, over 200,000 people have used Online Python Tutor to visualize their programs. In addition, instructors in a dozen universities such as UC Berkeley, MIT, the University of Washington, and the University of Waterloo have used it in their CS1 courses. Finally, Online Python Tutor visualizations have been embedded within three web-based digital Python textbook projects, which collectively attract around 16,000 viewers per month and are being used in at least 25 universities. Online Python Tutor is free and open source software, available at pythontutor.com.},
  isbn = {978-1-4503-1868-6},
  keywords = {CS1,program visualization,python},
  file = {/home/charlotte/sync/Zotero/storage/6ITEX6FW/Guo - 2013 - Online python tutor embeddable web-based program .pdf}
}

@inproceedings{hamerStudentsProjectsSource2021,
  title = {Students {{Projects}}' {{Source Code Changes Impact}} on {{Software Quality Through Static Analysis}}},
  booktitle = {Quality of {{Information}} and {{Communications Technology}}},
  author = {Hamer, Sivana and {Quesada-L{\'o}pez}, Christian and Jenkins, Marcelo},
  editor = {Paiva, Ana C. R. and Cavalli, Ana Rosa and Ventura Martins, Paula and {P{\'e}rez-Castillo}, Ricardo},
  year = {2021},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {553--564},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-85347-1_39},
  abstract = {Monitoring and examining source code and quality metrics is an essential task in software development projects. Still, it is challenging to evaluate for educational projects due to the time and effort required by instructors, and constant change during the software project evolution. In this paper, we used an automated approach to analyze source code and quality metrics' evolution and impact in software engineering projects using static code analysis on each software change (commits and merges). We examined five undergraduate software engineering projects' changed modules, compilability, and source code and quality metrics (size, complexity, duplication, maintainability, and security). In total, we assessed 12,103 changes from 103 students contributing to the projects. Our approach allowed us to identify students' project trends in the impact of the source code changes, providing insights into behaviors such as technology knowledge deficiencies, issues in continuous integration practices, and software quality degradation. We believe that the early, constant feedback on student software engineering project quality can help instructors improve their courses and students enhance their development practices. Tracking of source code evolution could be done via static analysis and instructors could use the analysis results for teaching.},
  isbn = {978-3-030-85347-1},
  langid = {english},
  keywords = {Change analysis,Mining software repositories,Project based learning,Quality metrics,Software engineering education},
  file = {/home/charlotte/sync/Zotero/storage/ZB8IV633/Hamer et al. - 2021 - Students Projects’ Source Code Changes Impact on S.pdf}
}

@article{hanksPairProgrammingEducation2011,
  title = {Pair Programming in Education: A Literature Review},
  shorttitle = {Pair Programming in Education},
  author = {Hanks, Brian and Fitzgerald, Sue and McCauley, Ren{\'e}e and Murphy, Laurie and Zander, Carol},
  year = {2011},
  month = jun,
  journal = {Computer Science Education},
  volume = {21},
  number = {2},
  pages = {135--173},
  publisher = {{Routledge}},
  issn = {0899-3408},
  doi = {10.1080/08993408.2011.579808},
  url = {https://doi.org/10.1080/08993408.2011.579808},
  urldate = {2022-08-16},
  abstract = {This article provides a review of educational research literature focused on pair programming in the undergraduate computer science curriculum. Research suggests that the benefits of pair programming include increased success rates in introductory courses, increased retention in the major, higher quality software, higher student confidence in solutions, and improvement in learning outcomes. Moreover, there is some evidence that women, in particular, benefit from pair programming. The literature also provides evidence that the transition from paired to solo programming is easy for students. The greatest challenges for paired students appear to concern scheduling and partner compatibility. This review also considers practical issues such as assigning partners, teaching students to work in pairs, and assessing individual contributions, and concludes with a discussion of open research questions.},
  keywords = {collaborative learning,pair programming}
}

@article{hannebauerDoesSyntaxHighlighting2018,
  title = {Does Syntax Highlighting Help Programming Novices?},
  author = {Hannebauer, Christoph and Hesenius, Marc and Gruhn, Volker},
  year = {2018},
  month = oct,
  journal = {Empirical Software Engineering},
  volume = {23},
  number = {5},
  pages = {2795--2828},
  issn = {1573-7616},
  doi = {10.1007/s10664-017-9579-0},
  url = {https://doi.org/10.1007/s10664-017-9579-0},
  urldate = {2023-11-16},
  abstract = {Program comprehension is an important skill for programmers -- extending and debugging existing source code is part of the daily routine. Syntax highlighting is one of the most common tools used to support developers in understanding algorithms. However, most research in this area originates from a time when programmers used a completely different tool chain. We examined the influence of syntax highlighting on novices' ability to comprehend source code. Additional analyses cover the influence of task type and programming experience on the code comprehension ability itself and its relation to syntax highlighting. We conducted a controlled experiment with 390 undergraduate students in an introductory Java programming course. We measured the correctness with which they solved small coding tasks. Each test subject received some tasks with syntax highlighting and some without. The data provided no evidence that syntax highlighting improves novices' ability to comprehend source code. There are very few similar experiments and it is unclear as of yet which factors impact the effectiveness of syntax highlighting. One major limitation may be the types of tasks chosen for this experiment. The results suggest that syntax highlighting squanders a feedback channel from the IDE to the programmer that can be used more effectively.},
  langid = {english},
  keywords = {Code colouring,IDE interface,Program comprehension,Source code typography,Syntax highlighting},
  file = {/home/charlotte/sync/Zotero/storage/IWUEEJV7/Hannebauer et al. - 2018 - Does syntax highlighting help programming novices.pdf}
}

@techreport{hardtOAuthAuthorizationFramework2012,
  type = {Request for {{Comments}}},
  title = {The {{OAuth}} 2.0 {{Authorization Framework}}},
  author = {Hardt, Dick},
  year = {2012},
  month = oct,
  number = {RFC 6749},
  institution = {{Internet Engineering Task Force}},
  doi = {10.17487/RFC6749},
  url = {https://datatracker.ietf.org/doc/rfc6749},
  urldate = {2022-08-16},
  abstract = {The OAuth 2.0 authorization framework enables a third-party application to obtain limited access to an HTTP service, either on behalf of a resource owner by orchestrating an approval interaction between the resource owner and the HTTP service, or by allowing the third-party application to obtain access on its own behalf. This specification replaces and obsoletes the OAuth 1.0 protocol described in RFC 5849. [STANDARDS-TRACK]},
  file = {/home/charlotte/sync/Zotero/storage/WAFXIJ6P/Hardt - 2012 - The OAuth 2.0 Authorization Framework.pdf}
}

@article{hattiePowerFeedback2007,
  title = {The {{Power}} of {{Feedback}}},
  author = {Hattie, John and Timperley, Helen},
  year = {2007},
  month = mar,
  journal = {Review of Educational Research},
  volume = {77},
  number = {1},
  pages = {81--112},
  publisher = {{American Educational Research Association}},
  issn = {0034-6543},
  doi = {10.3102/003465430298487},
  url = {https://doi.org/10.3102/003465430298487},
  urldate = {2022-02-21},
  abstract = {Feedback is one of the most powerful influences on learning and achievement, but this impact can be either positive or negative. Its power is frequently mentioned in articles about learning and teaching, but surprisingly few recent studies have systematically investigated its meaning. This article provides a conceptual analysis of feedback and reviews the evidence related to its impact on learning and achievement. This evidence shows that although feedback is among the major influences, the type of feedback and the way it is given can be differentially effective. A model of feedback is then proposed that identifies the particular properties and circumstances that make it effective, and some typically thorny issues are discussed, including the timing of feedback and the effects of positive and negative feedback. Finally, this analysis is used to suggest ways in which feedback can be used to enhance its effectiveness in classrooms.},
  langid = {english},
  keywords = {assessment,feedback,student and teacher learning},
  file = {/home/charlotte/sync/Zotero/storage/3V7WRXCU/Hattie and Timperley - 2007 - The Power of Feedback.pdf}
}

@inproceedings{haynes-magyarCodespecComputerProgramming2022,
  title = {Codespec: {{A Computer Programming Practice Environment}}},
  shorttitle = {Codespec},
  booktitle = {Proceedings of the 2022 {{ACM Conference}} on {{International Computing Education Research}} - {{Volume}} 2},
  author = {{Haynes-Magyar}, Carl Christopher and {Haynes-Magyar}, Nathaniel James},
  year = {2022},
  month = aug,
  series = {{{ICER}} '22},
  volume = {2},
  pages = {32--34},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3501709.3544278},
  url = {https://dl.acm.org/doi/10.1145/3501709.3544278},
  urldate = {2024-02-09},
  isbn = {978-1-4503-9195-5},
  keywords = {Adaptive Learning Systems,Computer Programming Practice,Scaffolding},
  file = {/home/charlotte/sync/Zotero/storage/DU5TNBA9/Haynes-Magyar and Haynes-Magyar - 2022 - Codespec A Computer Programming Practice Environm.pdf}
}

@article{hernandez-de-menendezLearningAnalyticsState2022,
  title = {Learning Analytics: State of the Art},
  shorttitle = {Learning Analytics},
  author = {{Hern{\'a}ndez-de-Men{\'e}ndez}, Marcela and {Morales-Menendez}, Ruben and Escobar, Carlos A. and Ram{\'i}rez Mendoza, Ricardo A.},
  year = {2022},
  month = sep,
  journal = {International Journal on Interactive Design and Manufacturing (IJIDeM)},
  volume = {16},
  number = {3},
  pages = {1209--1230},
  issn = {1955-2505},
  doi = {10.1007/s12008-022-00930-0},
  url = {https://doi.org/10.1007/s12008-022-00930-0},
  urldate = {2023-10-04},
  abstract = {Learning Analytics is a field that measures, analyses, and reports data about students and their contexts to understand/improve learning and the place in which it occurs. Educational institutions have different motivations to use Learning Analytics. Some want to improve students' outcomes or optimize their educational technology and reduce the dropout rate and others. This concept is presented with practical experiences that have been acquired and validated by 16 institutions. Besides, an analysis of the results, challenges, and expectations was performed. It was found that the majority of initiatives use Learning Analytics to improve retention of students; few are focused merely on improving the teaching/learning process or academic issues. The organizations invest their resources in acquiring Learning Analytics software; however, most universities develop their technology. The technology helps organizations be preventive and not reactive as various models determine students at risk of failing. This information allows them to make suitable interventions, which increases the success of the initiative. CoViD19 pandemic is also put in context in this research; Learning Analytics could be a great approach to help the educational community adapt effectively to the new forms of educational delivery. Based on an exhaustive bibliographic review, various educational projects and experiences were analyzed, presenting an overview detailing applications, results, and potentialities and opportunities, hoping that this article will be a useful reference for researchers and faculty to exploit Learning Analytics education.},
  langid = {english},
  keywords = {Educational innovation,Educational practices,Higher education,Learning analytics},
  file = {/home/charlotte/sync/Zotero/storage/CRBJ9RWK/Hernández-de-Menéndez et al. - 2022 - Learning analytics state of the art.pdf}
}

@article{hextAutomaticGradingScheme1969,
  title = {An Automatic Grading Scheme for Simple Programming Exercises},
  author = {Hext, J. B. and Winings, J. W.},
  year = {1969},
  month = may,
  journal = {Communications of the ACM},
  volume = {12},
  number = {5},
  pages = {272--275},
  issn = {0001-0782},
  doi = {10.1145/362946.362981},
  url = {https://dl.acm.org/doi/10.1145/362946.362981},
  urldate = {2024-02-06},
  abstract = {A discussion is given of alterations that were made to a typical university operating system to record the results of programming exercises in three different languages, includeing assembly language. In this computer-controlled grading scheme provision is made for testing with programmer-supplied data and for final runs with system-supplied data. Exercises run under the scheme may be mixed with other programs, and no special recognition of exercises by the operators is necessary.},
  keywords = {automatic grading program,programming exercises},
  file = {/home/charlotte/sync/Zotero/storage/542L4HBY/hext1969.pdf.pdf;/home/charlotte/sync/Zotero/storage/MCQ2FCYW/Hext and Winings - 1969 - An automatic grading scheme for simple programming.pdf}
}

@article{higginsCourseMarkerCBASystem2003,
  title = {The {{CourseMarker CBA System}}: {{Improvements}} over {{Ceilidh}}},
  shorttitle = {The {{CourseMarker CBA System}}},
  author = {Higgins, Colin and Hegazy, Tarek and Symeonidis, Pavlos and Tsintsifas, Athanasios},
  year = {2003},
  month = sep,
  journal = {Education and Information Technologies},
  volume = {8},
  number = {3},
  pages = {287--304},
  issn = {1573-7608},
  doi = {10.1023/A:1026364126982},
  url = {https://doi.org/10.1023/A:1026364126982},
  urldate = {2024-02-09},
  abstract = {This document reports on the results of re-designing and re-implementing the Ceilidh courseware system. It highlights the limitations identified in the thirteen years of Ceilidh's use at the University of Nottingham. It also illustrates how most of these limitations have been resolved by re-designing Ceilidh's architecture and improving various aspects of the marking and administrating processes. The new system, entitled CourseMarker, offers enhanced functionality by adding useful features that have long been needed by Ceilidh's community. The paper concludes with an evaluation of the changes and a brief report on the experience of CourseMarker's use over the last three years. Finally, recent developments and future directions are discussed.},
  langid = {english},
  keywords = {automatic assessment of programming coursework,free response Computer Based Assessment (CBA)},
  file = {/home/charlotte/sync/Zotero/storage/SAQXI48J/Higgins et al. - 2003 - The CourseMarker CBA System Improvements over Cei.pdf;/home/charlotte/sync/Zotero/storage/YRYDZSMT/higgins2003.pdf.pdf}
}

@mastersthesis{holeProgrammingIntroductoryPhysics2020,
  title = {Programming in {{Introductory Physics}}: An {{Online Learning Platform}} to {{Support Teachers}}},
  shorttitle = {Programming in {{Introductory Physics}}},
  author = {Hole, Niklas Molnes},
  year = {2020},
  url = {https://ntnuopen.ntnu.no/ntnu-xmlui/handle/11250/2777908},
  urldate = {2023-10-02},
  abstract = {Den norske regjeringen har bestemt at fra 2021 vil programmering v{\ae}re lagt til fysikk planen ved norske videreg{\aa}ende skoler (USS). L{\ae}rere har v{\ae}rt i stand til {\aa} delta p{\aa} ProFag (https://www.mn.uio.no/kurt/livslang-lering/profag) og andre tiltak for {\aa} l{\ae}re {\aa} bruke programmering i sine respektive kurs. Dermed kan utvikling av verkt{\o}y for {\aa} hjelpe i denne overgangen v{\ae}re avgj{\o}rende for {\aa} lykkes i avanserte kurs som fysikk. Imidlertid mangler der verkt{\o}y spesielt for {\aa} introdusere programmering i helt grunnleggende fysikk kurs. I tillegg har de tilgjengelige verkt{\o}yene som introduserer programmering generelt, mangler i funksjonalitet for {\aa} lage tilpassede oppgaver. For {\aa} hjelpe til med {\aa} l{\o}se disse problemene ble det gjennomf{\o}rt en Design Science Research (DSR) prosess. Ved {\aa} designe et verkt{\o}y, en online l{\ae}ringsplattform (OLP), som kunne introdusere programmering i et introduksjonskurs i fysikk, var det mulig {\aa} identifisere hvilke elementer som var viktige i et slikt verkt{\o}y. Det ble ogs{\aa} designet designet inn en funksjon for {\aa} la brukeren lage egne programmeringsoppgaver. Dette gjorde det mulig {\aa} finne ut hvordan et brukergrensesnitt (UI) kan tilpasses fysikkl{\ae}rere. For {\aa} f{\aa} et godt svar p{\aa} begge disse problemene, ble designet, elaborert og evaluert p{\aa} tre forskjellige m{\aa}lgrupper: universitetsstudenter (pilot), eksperter som jobber med dette feltet (expert), og fysikkl{\ae}rere uten noe tidligere kompetanse p{\aa} dette feltet (main). Totalt 18 elementer ble funnet {\aa} v{\ae}re avgj{\o}rende i utformingen av et verkt{\o}y som pr{\o}ver {\aa} introdusere programmering i et grunnleggende fysikk kurs. Det ble ogs{\aa} avdekket at ved {\aa} opprettet et brukergrensesnitt for {\aa} lage programmeringsoppgaver som passer til slik grunnleggende fysikk, var det viktig {\aa} ha muligheten til {\aa} skjule distraherende kode og for {\aa} kunne teste oppgaven i et realistisk milj{\o} mens man former oppgaven. I tillegg var det viktig at man laget brukergrensesnittet slik at utformingen av oppgaver tilsvarer m{\aa}ten oppgave-skaperne vanligvis lager oppgaver. For gruppen av fysikkl{\ae}rere var det mest interessant {\aa} bruke forh{\aa}ndsoppgaver enn {\aa} lage dem selv. Imidlertid var de interessert i {\aa} endre eksisterende oppgaver. Bortsett fra det som ble funnet ut i fra evalueringen, har OLPen som ble utviklet her ogs{\aa} som m{\aa}l {\aa} inspirere til forskningsarbeid og utvikling av verkt{\o}y som eksplisitt er laget for {\aa} introdusere programmering i spesifikke emner. OLP-artefakten som ble designet og utviklet i l{\o}pet av arbeid med denne oppgaven er tilgjengelig som en online demo (https://master-thesis-artifact.now.sh/) og som kildekode (https://github.com/niklasmh/master-thesis-artifact)},
  langid = {english},
  school = {NTNU},
  annotation = {Accepted: 2021-09-15T16:19:35Z},
  file = {/home/charlotte/sync/Zotero/storage/GRJMYXGD/Hole - 2020 - Programming in Introductory Physics an Online Lea.pdf}
}

@article{hollingsworthAutomaticGradersProgramming1960,
  title = {Automatic Graders for Programming Classes},
  author = {Hollingsworth, Jack},
  year = {1960},
  month = oct,
  journal = {Communications of the ACM},
  volume = {3},
  number = {10},
  pages = {528--529},
  issn = {0001-0782},
  doi = {10.1145/367415.367422},
  url = {https://doi.org/10.1145/367415.367422},
  urldate = {2022-08-16},
  abstract = {Fifteen months ago the first version of an ``automatic grader'' was tried with a group of twenty students taking a formal course in programming. The first group of twenty programs took only five minutes on the computer (an IBM 650). With such a satisfactory beginning, the grader was then used for the entire course with this group of students and have been used at Rensselaer ever since. For all exercises, the average time spent on the computer has run from half a minute to a minute for each student. In general only an eighth as much computer time is required when the grader is used as is required when each student is expected to run his own program, probably less than a third as much staff time, and considerably less student time. The grader easily justifies itself on economic grounds. It accomplishes more than savings in time and money; it makes possible the teaching of programming to large numbers of students. This spring we had 80 students taking a full semester course in programming; over 120 are expected next spring. We could not accommodate such numbers without the use of the grader. Even though the grader makes the teaching of programming to large numbers of students possible and economically feasible, a most serious question remains, how well did the students learn? After fifteen months, our experience leads us to believe that students learn programming not only as well but probably better than they did under the method we did use---laboratory groups of four or five students. They are not as skilled in machine operation, however, since they get only a brief introduction to it late in the course. After learning programming, very little time is needed for each student to become at least an adequate machine operator. Students seem to like the grader and are not reluctant to suggest improvements!},
  file = {/home/charlotte/sync/Zotero/storage/JS69Q9SX/Hollingsworth - 1960 - Automatic graders for programming classes.pdf}
}

@inproceedings{hughesCeilidhCollaborativeWriting1998,
  title = {Ceilidh: Collaborative Writing on the {{Web}}},
  shorttitle = {Ceilidh},
  booktitle = {Proceedings of the 1998 {{ACM}} Symposium on {{Applied Computing}}},
  author = {Hughes, Richard J. and Shewmake, Jake and Okelberry, Christopher R.},
  year = {1998},
  month = feb,
  series = {{{SAC}} '98},
  pages = {732--736},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/330560.331081},
  url = {https://dl.acm.org/doi/10.1145/330560.331081},
  urldate = {2024-02-09},
  isbn = {978-0-89791-969-2},
  keywords = {Ceilidh,classroom,collaboration,composition,writing},
  file = {/home/charlotte/sync/Zotero/storage/7MSWHKF3/hughes1998.pdf.pdf;/home/charlotte/sync/Zotero/storage/I6GESF6J/Hughes et al. - 1998 - Ceilidh collaborative writing on the Web.pdf}
}

@article{hungAutomaticProgrammingAssessment1993,
  title = {Automatic Programming Assessment},
  author = {Hung, Sheung-Lun and Kwok, Iam-For and Chan, Raymond},
  year = {1993},
  month = mar,
  journal = {Computers \& Education},
  volume = {20},
  number = {2},
  pages = {183--190},
  issn = {0360-1315},
  doi = {10.1016/0360-1315(93)90086-X},
  url = {https://www.sciencedirect.com/science/article/pii/036013159390086X},
  urldate = {2024-02-07},
  abstract = {Software metrics have been used extensively to provide quantitative measures of software characteristics. This paper aims at evaluating the relevance of using software metrics as means of assessing students' performance in programming. The study focusses on the use of four basic software metrics which are combined to form a single assessment score. The four metrics are respectively those which measure programming skill, complexity, programming style and programming efficiency. Measurements suggested that the lines of code metric is a good candidate for measuring programming skill. McCabe's cyclomatic complexity metrics have been adopted for measuring program complexity. Program execution times are used as the measuring yardsticks for programming efficiency. To facilitate automatic assessment, a program analyzer has been constructed which can provide measures of all the relevant software metrics together with the appropriate assessment scores. The tool was tested with sample assignments of Pascal programs and good distribution of marks has been obtained.},
  file = {/home/charlotte/sync/Zotero/storage/TI5Q63PJ/hung1993.pdf.pdf;/home/charlotte/sync/Zotero/storage/37JRXCS4/036013159390086X.html}
}

@article{huntFastAlgorithmComputing1977,
  title = {A Fast Algorithm for Computing Longest Common Subsequences},
  author = {Hunt, James W. and Szymanski, Thomas G.},
  year = {1977},
  month = may,
  journal = {Communications of the ACM},
  volume = {20},
  number = {5},
  pages = {350--353},
  issn = {0001-0782},
  doi = {10.1145/359581.359603},
  url = {https://doi.org/10.1145/359581.359603},
  urldate = {2022-08-23},
  abstract = {Previously published algorithms for finding the longest common subsequence of two sequences of length n have had a best-case running time of O(n2). An algorithm for this problem is presented which has a running time of O((r + n) log n), where r is the total number of ordered pairs of positions at which the two sequences match. Thus in the worst case the algorithm has a running time of O(n2 log n). However, for those applications where most positions of one sequence match relatively few positions in the other sequence, a running time of O(n log n) can be expected.},
  keywords = {efficient algorithms,longest common subsequence},
  file = {/home/charlotte/sync/Zotero/storage/FJPYJKMJ/Hunt and Szymanski - 1977 - A fast algorithm for computing longest common subs.pdf}
}

@book{huntPragmaticProgrammer1999,
  title = {The Pragmatic Programmer},
  author = {Hunt, Andrew},
  year = {1999},
  publisher = {{Pearson Education India}}
}

@article{huUsingPOGILHelp2013,
  title = {Using {{POGIL}} to Help Students Learn to Program},
  author = {Hu, Helen H. and Shepherd, Tricia D.},
  year = {2013},
  month = aug,
  journal = {ACM Transactions on Computing Education},
  volume = {13},
  number = {3},
  pages = {13:1--13:23},
  doi = {10.1145/2499947.2499950},
  url = {https://doi.org/10.1145/2499947.2499950},
  urldate = {2021-09-30},
  abstract = {POGIL has been successfully implemented in a scientific computing course to teach science students how to program in Python. Following POGIL guidelines, the authors have developed guided inquiry activities that lead student teams to discover and understand programming concepts. With each iteration of the scientific computing course, the authors have refined the activities and learned how to better adapt POGIL for the computer science classroom. This article details how POGIL activities differ from both traditional computer science labs and other active-learning pedagogies. Background is provided on POGIL's effectiveness. The article then includes a full description of how POGIL activities were used in the scientific computing course, as well as an example POGIL activity on recursion. Discussion is provided on how to facilitate and develop POGIL activities. Quotes from student evaluations and an assessment on how well students learned to program are provided.},
  keywords = {active learning,inquiry-based learning,POGIL,process skills,process-oriented guided inquiry learning},
  file = {/home/charlotte/sync/Zotero/storage/ZUEUNNWT/Hu and Shepherd - 2013 - Using POGIL to help students learn to program.pdf}
}

@article{hylenOpenEducationalResources2021,
  title = {Open Educational Resources: {{Opportunities}} and Challenges},
  author = {Hyl{\'e}n, Jan},
  year = {2021},
  publisher = {{OECD}}
}

@inproceedings{ihantolaReviewRecentSystems2010,
  title = {Review of Recent Systems for Automatic Assessment of Programming Assignments},
  booktitle = {Proceedings of the 10th {{Koli Calling International Conference}} on {{Computing Education Research}}},
  author = {Ihantola, Petri and Ahoniemi, Tuukka and Karavirta, Ville and Sepp{\"a}l{\"a}, Otto},
  year = {2010},
  month = oct,
  series = {Koli {{Calling}} '10},
  pages = {86--93},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1930464.1930480},
  url = {https://doi.org/10.1145/1930464.1930480},
  urldate = {2022-08-16},
  abstract = {This paper presents a systematic literature review of the recent (2006--2010) development of automatic assessment tools for programming exercises. We discuss the major features that the tools support and the different approaches they are using both from the pedagogical and the technical point of view. Examples of these features are ways for the teacher to define tests, resubmission policies, security issues, and so forth. We have also identified a list of novel features, like assessing web software, that are likely to get more research attention in the future. As a conclusion, we state that too many new systems are developed, but also acknowledge the current reasons for the phenomenon. As one solution we encourage opening up the existing systems and joining efforts on developing those further. Selected systems from our survey are briefly described in Appendix A.},
  isbn = {978-1-4503-0520-4},
  file = {/home/charlotte/sync/Zotero/storage/YDXWS4RA/Ihantola et al. - 2010 - Review of recent systems for automatic assessment .pdf}
}

@article{insaAutomaticAssessmentJava2018,
  title = {Automatic Assessment of {{Java}} Code},
  author = {Insa, David and Silva, Josep},
  year = {2018},
  month = sep,
  journal = {Computer Languages, Systems \& Structures},
  volume = {53},
  pages = {59--72},
  issn = {1477-8424},
  doi = {10.1016/j.cl.2018.01.004},
  url = {https://www.sciencedirect.com/science/article/pii/S1477842417301045},
  urldate = {2023-10-05},
  abstract = {Assessment is an integral part of education often used to evaluate students, but also to provide them with feedback. It is essential to ensure that assessment is fair, objective, and equally applied to all students. This holds, for instance, in multiple-choice tests, but, unfortunately, it is not ensured in the assessment of source code, which is still a manual and error-prone task. In this paper, we present JavAssess , a Java library with an API composed of around 200 methods to automatically inspect, test, mark, and correct Java code. It can be used to produce both black-box (based on output comparison) and white-box (based on the internal properties of the code) assessment tools. This means that it allows for marking the code even if it is only partially correct. We describe the library, how to use it, and we provide a complete example to automatically mark and correct a student's code. We also report the use of this system in a real university context to compare manual and automatic assessment in university courses. The study reports the average error in the marks produced by teachers when assessing source code manually, and it shows that the system automatically assesses around 50\% of the work.},
  keywords = {Assessment,Java},
  file = {/home/charlotte/sync/Zotero/storage/IW5SWITR/Insa and Silva - 2018 - Automatic assessment of Java code.pdf;/home/charlotte/sync/Zotero/storage/VY7F759E/S1477842417301045.html}
}

@article{isaacson1989automating,
  title = {Automating the Execution of Student Programs},
  author = {Isaacson, Peter C and Scott, Terry A},
  year = {1989},
  journal = {ACM SIGCSE Bulletin},
  volume = {21},
  number = {2},
  pages = {15--22},
  publisher = {{ACM New York, NY, USA}},
  file = {/home/charlotte/sync/Zotero/storage/XVVKJK4A/Isaacson and Scott - 1989 - Automating the execution of student programs.pdf}
}

@article{isong2001developing,
  title = {Developing an Automated Program Checker},
  author = {Isong, Julia},
  year = {2001},
  journal = {Journal of Computing Sciences in Colleges},
  volume = {16},
  number = {3},
  pages = {218--224},
  publisher = {{Citeseer}},
  file = {/home/charlotte/sync/Zotero/storage/VWJUIVMV/Isong - 2001 - Developing an automated program checkers.pdf}
}

@inproceedings{jacksonGradingStudentPrograms1997,
  title = {Grading Student Programs Using {{ASSYST}}},
  booktitle = {Proceedings of the Twenty-Eighth {{SIGCSE}} Technical Symposium on {{Computer}} Science Education},
  author = {Jackson, David and Usher, Michelle},
  year = {1997},
  month = mar,
  series = {{{SIGCSE}} '97},
  pages = {335--339},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/268084.268210},
  url = {https://doi.org/10.1145/268084.268210},
  urldate = {2022-08-16},
  abstract = {The task of grading solutions to student programming exercises is laborious and error-prone. We have developed a software tool called ASSYST that is designed to relieve a tutor of much of the burden of assessing such programs. ASSYST offers a graphical interface that can be used to direct all aspects of the grading process, and it considers a wide range of criteria in its automatic assessment. Experience with the system has been encouraging.},
  isbn = {978-0-89791-889-3},
  file = {/home/charlotte/sync/Zotero/storage/XLGYGGA8/Jackson and Usher - 1997 - Grading student programs using ASSYST.pdf}
}

@article{jacksonSemiautomatedApproachOnline2000,
  title = {A Semi-Automated Approach to Online Assessment},
  author = {Jackson, David},
  year = {2000},
  month = jul,
  journal = {ACM SIGCSE Bulletin},
  volume = {32},
  number = {3},
  pages = {164--167},
  issn = {0097-8418},
  doi = {10.1145/353519.343160},
  url = {https://doi.org/10.1145/353519.343160},
  urldate = {2022-09-09},
  abstract = {Desirable though fully automated assessment of student programming assignments is, it is an area that is beset by difficulties. While it is not contested that some aspects of assessment can be performed much more efficiently and accurately by computer, there are many others that still require human involvement. We have therefore designed a system that combines the strengths of the two approaches, the assessment software calling upon the skills of the human tutor where necessary to make sensible judgements. The technique has been used successfully on a systems programming course for several years, and student feedback has been supportive.},
  file = {/home/charlotte/sync/Zotero/storage/ERKK7ECV/Jackson - 2000 - A semi-automated approach to online assessment.pdf}
}

@inproceedings{janzenTestdrivenLearningEarly2008,
  title = {Test-Driven Learning in Early Programming Courses},
  booktitle = {Proceedings of the 39th {{SIGCSE}} Technical Symposium on {{Computer}} Science Education},
  author = {Janzen, David and Saiedian, Hossein},
  year = {2008},
  month = mar,
  series = {{{SIGCSE}} '08},
  pages = {532--536},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1352135.1352315},
  url = {https://doi.org/10.1145/1352135.1352315},
  urldate = {2022-03-03},
  abstract = {Coercing new programmers to adopt disciplined development practices such as thorough unit testing is a challenging endeavor. Test-driven development (TDD) has been proposed as a solution to improve both software design and testing. Test-driven learning (TDL) has been proposed as a pedagogical approach for teaching TDD without imposing significant additional instruction time. This research evaluates the effects of students using a test-first (TDD) versus test-last approach in early programming courses, and considers the use of TDL on a limited basis in CS1 and CS2. Software testing, programmer productivity, programmer performance, and programmer opinions are compared between test-first and test-last programming groups. Results from this research indicate that a test-first approach can increase student testing and programmer performance, but that early programmers are very reluctant to adopt a test-first approach, even after having positive experiences using TDD. Further, this research demonstrates that TDL can be applied in CS1/2, but suggests that a more pervasive implementation of TDL may be necessary to motivate and establish disciplined testing practice among early programmers.},
  isbn = {978-1-59593-799-5},
  keywords = {cs1,pedagogy,test-driven development,test-driven learning},
  file = {/home/charlotte/sync/Zotero/storage/XYCHY72D/Janzen and Saiedian - 2008 - Test-driven learning in early programming courses.pdf}
}

@inproceedings{jenkinsDifficultyLearningProgram2002,
  title = {On the Difficulty of Learning to Program},
  booktitle = {Proceedings of the 3rd {{Annual Conference}} of the {{LTSN Centre}} for {{Information}} and {{Computer Sciences}}},
  author = {Jenkins, Tony},
  year = {2002},
  volume = {4},
  pages = {53--58},
  publisher = {{Citeseer}},
  file = {/home/charlotte/sync/Zotero/storage/NEG8W3MU/Jenkins - 2002 - On the difficulty of learning to program.pdf}
}

@article{jesionkowskaActiveLearningAugmented2020,
  title = {Active {{Learning Augmented Reality}} for {{STEAM Education}}---{{A Case Study}}},
  author = {Jesionkowska, Joanna and Wild, Fridolin and Deval, Yann},
  year = {2020},
  month = aug,
  journal = {Education Sciences},
  volume = {10},
  number = {8},
  pages = {198},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/educsci10080198},
  url = {https://www.mdpi.com/2227-7102/10/8/198},
  urldate = {2021-10-01},
  abstract = {Immersive technologies are rapidly transforming the field of education. Amongst them, Augmented Reality (AR) has shown promise as a resource, particularly for education in Science, Technology, Engineering, Arts, and Mathematics (STEAM). There are, however, few teachers deploying this new medium in the classroom directly, and, consequently, only a few, elect students benefit from the AR-enriched offers. Curricula are already overloaded, and schools generally lack developmental resources, thus leaving no room for experimentation. This situation is further aggravated by the too few educational applications available with sufficient learning content. In this article, we investigate the method of Active Learning for the teaching of STEAM subjects, using a format where students are tasked with building an AR application as part of their learning. We evaluate the applicability of the Active Learning for STEAM subjects with a qualitative, case study approach, applying the workshop format as an extracurricular activity in our work with students from a range of secondary schools in Oxford. We discuss how the format works, so it can be embedded into regular curricula, not just as an extracurricular activity, also providing an overview on the involved teaching units and rationale. All teams in our preview audience of the case study succeeded in building working applications, several of impressive complexity. Students found that the lessons were enjoyable and AR technology can enhance their learning experience. The Active Learning method served as a catalyst for students\&rsquo; skills development, with the case study providing evidence of learning to code, working with a physics simulation engine, ray-tracing, and geometry, learning how to manage teams and interact with other students/instructors, and engineering a working prototype of a game. We consequentially argue that combining the STEM subjects and the arts, using the proposed Active Learning format, is able to provide a more holistic and engaging education.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {active learning,augmented reality,education,STEAM,STEM},
  file = {/home/charlotte/sync/Zotero/storage/TSQPYJVY/Jesionkowska et al. - 2020 - Active Learning Augmented Reality for STEAM Educat.pdf;/home/charlotte/sync/Zotero/storage/ELTL6PBV/198.html}
}

@inproceedings{jessen2010overview,
  title = {An Overview of {{ESI}} Storage \& Retrieval},
  booktitle = {Sedona Conf. {{J}}.},
  author = {Jessen, John H},
  year = {2010},
  volume = {11},
  pages = {237},
  publisher = {{HeinOnline}}
}

@article{jiangExploringEffectsSPOCbased2023,
  title = {Exploring the Effects of {{SPOC-based}} Blended Learning on Students' Learning Performance at Higher Vocational Education},
  author = {Jiang, Wuxue and Zhan, Ying and Sun, Daner and Sun, Jin and Tian, Peiyao},
  year = {2023},
  journal = {Interactive Learning Environments},
  volume = {0},
  number = {0},
  pages = {1--18},
  publisher = {{Routledge}},
  issn = {1049-4820},
  doi = {10.1080/10494820.2023.2294774},
  url = {https://doi.org/10.1080/10494820.2023.2294774},
  urldate = {2024-01-05},
  abstract = {Higher vocational education has been on a trajectory of rapid development. However, the challenge of fostering effective learning in students persists. In response to this, a study was undertaken to explore the impact of an optimized model of SPOC-based blended learning (SPOC-BL) on student presence, learning satisfaction, learning motivation, and academic performance in C language programming course. This quasi-experimental study spanned a period of three months and involved 92 students from two classes in a higher vocational school. Quantitative research methods were employed to analyze students' academic performance and their interrelationship among student presence, learning satisfaction, learning motivation in SPOC-BL approach. Analysis of Covariance, paired samples t-tests, and multiple regression analysis were conducted to analyze students' performance on achievement tests and student surveys. The results showed substantial improvements in student presence, learning motivation, learning satisfaction, and academic achievement as direct outcomes of the innovative instructional approach. The findings illuminated significant effects for all factors, with student presence exerting the most significant influence, followed closely by learning motivation, and with learning satisfaction playing a smaller yet still meaningful role. The study will inform the design and implementation of blended learning in higher vocational education.},
  keywords = {academic achievement,Blended learning,higher vocational school,learning motivation,learning satisfaction,SPOC-BL,student presence},
  file = {/home/charlotte/sync/Zotero/storage/5SJYAAFA/Jiang et al. - 2023 - Exploring the effects of SPOC-based blended learni.pdf}
}

@article{jones2001grading,
  title = {Grading Student Programs- a Software Testing Approach},
  author = {Jones, Edward L},
  year = {2001},
  journal = {Journal of Computing Sciences in Colleges},
  volume = {16},
  number = {2},
  pages = {185--192},
  publisher = {{Citeseer}},
  file = {/home/charlotte/sync/Zotero/storage/XWEESBAS/Jones - 2001 - Grading student programs- a software testing appro.pdf}
}

@article{joyBossOnlineSubmission2005,
  title = {The Boss Online Submission and Assessment System},
  author = {Joy, Mike and Griffiths, Nathan and Boyatt, Russell},
  year = {2005},
  month = sep,
  journal = {Journal on Educational Resources in Computing},
  volume = {5},
  number = {3},
  pages = {2--es},
  issn = {1531-4278},
  doi = {10.1145/1163405.1163407},
  url = {https://dl.acm.org/doi/10.1145/1163405.1163407},
  urldate = {2024-02-09},
  abstract = {Computer programming lends itself to automated assessment. With appropriate software tools, program correctness can be measured, along with an indication of quality according to a set of metrics. Furthermore, the regularity of program code allows plagiarism detection to be an integral part of the tools that support assessment. In this paper, we describe a submission and assessment system, called BOSS, that supports coursework assessment through collecting submissions, performing automatic tests for correctness and quality, checking for plagiarism, and providing an interface for marking and delivering feedback. We describe how automated assessment is incorporated into BOSS such that it supports, rather than constrains, assessment. The pedagogic and administrative issues that are affected by the assessment process are also discussed.},
  keywords = {automated assessment,Online submission,programming languages},
  file = {/home/charlotte/sync/Zotero/storage/6MUNQDNW/Joy et al. - 2005 - The boss online submission and assessment system.pdf;/home/charlotte/sync/Zotero/storage/EQA2HWED/joy2005.pdf.pdf}
}

@article{kailaRedesigningObjectOrientedProgramming2016,
  title = {Redesigning an {{Object-Oriented Programming Course}}},
  author = {Kaila, Erkki and Kurvinen, Einari and Lokkila, Erno and Laakso, Mikko-Jussi},
  year = {2016},
  month = aug,
  journal = {ACM Transactions on Computing Education},
  volume = {16},
  number = {4},
  pages = {18:1--18:21},
  doi = {10.1145/2906362},
  url = {https://doi.org/10.1145/2906362},
  urldate = {2021-09-30},
  abstract = {Educational technology offers several potential benefits for programming education. Still, to facilitate the technology properly, integration into a course must be carefully designed. In this article, we present a redesign of an object-oriented university-level programming course. In the redesign, a collaborative education tool was utilized to enhance active learning, facilitate communication between students and teachers, and remodel the evaluation procedure by utilizing automatically assessed tasks. The redesign was based on the best practices found in our own earlier research and that of the research community, with a focus on facilitating active learning methods and student collaboration. The redesign was evaluated by comparing two instances of the redesigned course against two instances using the old methodology. The drop-out rate decreased statistically significantly in the redesigned course instances. Moreover, there was a trend toward higher grade averages in the redesigned instances. Based on the results, we can conclude that the utilization of educational technology has a highly positive effect on student performance. Still, making major changes to course methodology does not come without certain difficulties. Hence, we also present our experiences and suggestions for the course redesign to help other educators and researchers perform similar design changes.},
  keywords = {course methodology,course redesign,Object-oriented programming,programming education},
  file = {/home/charlotte/sync/Zotero/storage/I6R5ZUQ8/Kaila et al. - 2016 - Redesigning an Object-Oriented Programming Course.pdf}
}

@article{karabenickRelationshipAcademicHelp1991,
  title = {Relationship of Academic Help Seeking to the Use of Learning Strategies and Other Instrumental Achievement Behavior in College Students},
  author = {Karabenick, Stuart A. and Knapp, John R.},
  year = {1991},
  journal = {Journal of Educational Psychology},
  volume = {83},
  number = {2},
  pages = {221--230},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-2176},
  doi = {10.1037/0022-0663.83.2.221},
  abstract = {Correlates of help seeking among college students were examined. In the 1st study (N{\enspace}={\enspace}612), college students' help-seeking tendencies, given the prospect of poor performance, were (a) directly related to their rated likelihood of engaging in instrumental achievement activities, (b) directly related to persistent global self-esteem, and (c) inversely related to students' perceptions that seeking help is threatening. In Study 2 (N{\enspace}={\enspace}541), help seeking was directly related to the use of cognitive, metacognitive, and resource management learning strategies. Study 3 (N{\enspace}={\enspace}386) replicated the results of Study 2 and also found that correlations between help seeking and learning strategy use were unchanged when controlling for individual differences in the perceived threat to self-esteem posed by help seeking. Evidence from all 3 studies is consistent with viewing help seeking in an academic context as an achievement-related rather than as a dependent behavior. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Educational Counseling,Help Seeking Behavior,Individual Differences,Learning Strategies,Self-Esteem,Threat},
  file = {/home/charlotte/sync/Zotero/storage/CR2SZPLV/1991-28915-001.html}
}

@inproceedings{kelleherAlice2ProgrammingSyntax2002,
  title = {Alice2: Programming without Syntax Errors},
  booktitle = {User {{Interface Software}} and {{Technology}}},
  author = {Kelleher, Caitlin and Cosgrove, Dennis and Culyba, David and Forlines, Clifton and Pratt, Jason and Pausch, Randy},
  year = {2002},
  volume = {2},
  pages = {35--36},
  publisher = {{Citeseer}}
}

@article{keuningSystematicLiteratureReview2018,
  title = {A {{Systematic Literature Review}} of {{Automated Feedback Generation}} for {{Programming Exercises}}},
  author = {Keuning, Hieke and Jeuring, Johan and Heeren, Bastiaan},
  year = {2018},
  month = sep,
  journal = {ACM Transactions on Computing Education},
  volume = {19},
  number = {1},
  pages = {3:1--3:43},
  doi = {10.1145/3231711},
  url = {https://doi.org/10.1145/3231711},
  urldate = {2022-10-03},
  abstract = {Formative feedback, aimed at helping students to improve their work, is an important factor in learning. Many tools that offer programming exercises provide automated feedback on student solutions. We have performed a systematic literature review to find out what kind of feedback is provided, which techniques are used to generate the feedback, how adaptable the feedback is, and how these tools are evaluated. We have designed a labelling to classify the tools, and use Narciss' feedback content categories to classify feedback messages. We report on the results of coding a total of 101 tools. We have found that feedback mostly focuses on identifying mistakes and less on fixing problems and taking a next step. Furthermore, teachers cannot easily adapt tools to their own needs. However, the diversity of feedback types has increased over the past decades and new techniques are being applied to generate feedback that is increasingly helpful for students.},
  keywords = {automated feedback,learning programming,programming tools,Systematic literature review},
  file = {/home/charlotte/sync/Zotero/storage/TDEACJRZ/Keuning et al. - 2018 - A Systematic Literature Review of Automated Feedba.pdf}
}

@article{khalifaWebbasedLearningEffects2002,
  title = {Web-Based Learning: Effects on Learning Process and Outcome},
  shorttitle = {Web-Based Learning},
  author = {Khalifa, M. and Lam, R.},
  year = {2002},
  month = nov,
  journal = {IEEE Transactions on Education},
  volume = {45},
  number = {4},
  pages = {350--356},
  issn = {1557-9638},
  doi = {10.1109/TE.2002.804395},
  abstract = {Educators have witnessed lately a proliferation of Web-based learning applications. These Web-learning environments have made learning much more convenient by stretching the spatial and temporal barriers. Their effectiveness, however, remains to be examined. In this research, the authors study the relative effectiveness of two different types of Web-learning environments: distributed passive learning (DPL) versus distributed interactive learning (DEL) environments. In the DPL environment, the Web is only used to deliver linear learning material, such as Word files and PowerPoint slides. In the DIL environment, however, the learning material is in hypertext format, providing the learner with more exploration and interactivity capabilities. The results of an empirical study show that the DIL environment is superior to the DPL environment in terms of both the learning process and the learning outcome.},
  keywords = {Computer aided instruction,Engineering education,Internet},
  file = {/home/charlotte/sync/Zotero/storage/7JRDKDS6/Khalifa and Lam - 2002 - Web-based learning effects on learning process an.pdf;/home/charlotte/sync/Zotero/storage/NVP8AJWZ/1049596.html}
}

@inproceedings{kimFaCoYCodetocodeSearch2018,
  title = {{{FaCoY}}: A Code-to-Code Search Engine},
  shorttitle = {{{FaCoY}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Software Engineering}}},
  author = {Kim, Kisub and Kim, Dongsun and Bissyand{\'e}, Tegawend{\'e} F. and Choi, Eunjong and Li, Li and Klein, Jacques and Traon, Yves Le},
  year = {2018},
  month = may,
  series = {{{ICSE}} '18},
  pages = {946--957},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3180155.3180187},
  url = {https://dl.acm.org/doi/10.1145/3180155.3180187},
  urldate = {2023-11-23},
  abstract = {Code search is an unavoidable activity in software development. Various approaches and techniques have been explored in the literature to support code search tasks. Most of these approaches focus on serving user queries provided as natural language free-form input. However, there exists a wide range of use-case scenarios where a code-to-code approach would be most beneficial. For example, research directions in code transplantation, code diversity, patch recommendation can leverage a code-to-code search engine to find essential ingredients for their techniques. In this paper, we propose FaCoY, a novel approach for statically finding code fragments which may be semantically similar to user input code. FaCoY implements a query alternation strategy: instead of directly matching code query tokens with code in the search space, FaCoY first attempts to identify other tokens which may also be relevant in implementing the functional behavior of the input code. With various experiments, we show that (1) FaCoY is more effective than online code-to-code search engines; (2) FaCoY can detect more semantic code clones (i.e., Type-4) in BigCloneBench than the state-of-the-art; (3) FaCoY, while static, can detect code fragments which are indeed similar with respect to runtime execution behavior; and (4) FaCoY can be useful in code/patch recommendation.},
  isbn = {978-1-4503-5638-1},
  file = {/home/charlotte/sync/Zotero/storage/ZKJSFYC8/Kim et al. - 2018 - FaCoY a code-to-code search engine.pdf}
}

@incollection{kleinbaumIntroductionLogisticRegression1994,
  title = {Introduction to {{Logistic Regression}}},
  booktitle = {Logistic {{Regression}}: {{A Self-Learning Text}}},
  author = {Kleinbaum, David G.},
  editor = {Kleinbaum, David G.},
  year = {1994},
  series = {Statistics in the {{Health}} Sciences},
  pages = {1--38},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4757-4108-7_1},
  url = {https://doi.org/10.1007/978-1-4757-4108-7_1},
  urldate = {2021-02-19},
  abstract = {This introduction to logistic regression describes the reasons for the popularity of the logistic model, the model form, how the model may be applied, and several of its key features, particularly how an odds ratio can be derived and computed for this model.},
  isbn = {978-1-4757-4108-7},
  langid = {english},
  keywords = {Estimate Odds Ratio,Logistic Model,Logistic Regression,Logit Transformation,Risk Ratio}
}

@inproceedings{kosowskiApplicationOnlineJudge2008,
  title = {Application of an {{Online Judge}} \& {{Contester System}} in {{Academic Tuition}}},
  booktitle = {Advances in {{Web Based Learning}} -- {{ICWL}} 2007},
  author = {Kosowski, Adrian and Ma{\l}afiejski, Micha{\l} and Noi{\'n}ski, Tomasz},
  editor = {Leung, Howard and Li, Frederick and Lau, Rynson and Li, Qing},
  year = {2008},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {343--354},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-78139-4_31},
  abstract = {The paper contains a description of the SPOJ online judge and contester system, used for E-Learning of programming, which has been successfully applied in the tuition of students at the Gda{\'n}sk University of Technology. We study the implementation of the system with security demands and present our experiences connected with the use of such systems in academic courses at an undergraduate and graduate level in the last four years.},
  isbn = {978-3-540-78139-4},
  langid = {english},
  keywords = {Contest Organizer,Master Node,Pass Threshold,Programming Assignment,Security Demand},
  file = {/home/charlotte/sync/Zotero/storage/9Q4KRSFA/application-of-an-online-judge--contester-system-in-academic-tui.pdf.pdf}
}

@article{kovacicPredictingStudentSuccess2012,
  title = {Predicting Student Success by Mining Enrolment Data.},
  author = {Kovacic, Z.},
  year = {2012},
  url = {https://repository.openpolytechnic.ac.nz/handle/11072/1486},
  urldate = {2021-02-19},
  abstract = {This paper explores the socio-demographic variables (age, gender, ethnicity, education, work status, and disability) and study environment (course programme and course block), that may influence persistence or dropout of the distance education students at the Open Polytechnic. It examines to what extent these factors, i.e. enrolment data help us in preidentifying successful and unsuccessful students. The data stored in the Open Polytechnic student management system from 2006 to 2009, covering over 450 students who enrolled to Information Systems course was used to perform a quantitative analysis of study outcome. Based on a data mining techniques (such as feature selection and classification trees) and logistic regression the most important factors for student success and a profile of the typical successful and unsuccessful students are identified. The empirical results show the following: (i) the most important factors separating successful from unsuccessful students are: ethnicity, course programme and course block; (ii) among classification tree growing methods Classification and Regression Tree (CART) was the most successful in growing the tree with an overall percentage of correct classification of 60.5\%; (iii) both the risk estimated by the cross-validation and the gain diagram suggests that all trees, based only on enrolment data, are not quite good in separating successful from unsuccessful students, and (iv) the same conclusion was reached using the logistic regression. The implications of these results for academic and administrative staff are discussed.},
  langid = {english},
  annotation = {Accepted: 2013-04-10T01:20:26Z},
  file = {/home/charlotte/sync/Zotero/storage/7RPMXNW8/Kovacic - 2012 - Predicting student success by mining enrolment dat.pdf;/home/charlotte/sync/Zotero/storage/HAP6SWMI/1486.html}
}

@inproceedings{kruscheArTEMiSAutomaticAssessment2018,
  title = {{{ArTEMiS}}: {{An Automatic Assessment Management System}} for {{Interactive Learning}}},
  shorttitle = {{{ArTEMiS}}},
  booktitle = {Proceedings of the 49th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  author = {Krusche, Stephan and Seitz, Andreas},
  year = {2018},
  month = feb,
  series = {{{SIGCSE}} '18},
  pages = {284--289},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3159450.3159602},
  url = {https://dl.acm.org/doi/10.1145/3159450.3159602},
  urldate = {2023-08-21},
  abstract = {The increasing number of students in computer science courses leads to high efforts in manual assessment of exercises. Existing assessment systems are not designed for exercises with immediate feedback in large classes. In this paper, we present an AuTomated assEssment Management System for interactive learning. ArTEMiS assesses solutions to programming exercises automatically and provides instant feedback so that students can iteratively solve the exercise. It is open source and highly scalable based on version control, regression testing and continuous integration. ArTEMiS offers an online code editor with interactive exercise instructions, is programming language independent and applicable to a variety of computer science courses. By using it, students gain experiences in version control, dependency management and continuous integration. We used ArTEMiS in 3 university and 1 online courses and report about our experiences. We figured out that ArTEMiS is suitable for beginners, helps students to realize their progress and to gradually improve their solutions. It reduces the effort of instructors and enhances the learning experience of students.},
  isbn = {978-1-4503-5103-4},
  keywords = {automated assessment,continuous integration,in-class exercises,instant feedback,interactive exercise instructions,online courses,online editor,programming exercises,version control},
  file = {/home/charlotte/sync/Zotero/storage/9XZTFL7M/Krusche and Seitz - 2018 - ArTEMiS An Automatic Assessment Management System.pdf}
}

@inproceedings{lahiriDifferentialAssertionChecking2013,
  title = {Differential Assertion Checking},
  booktitle = {Proceedings of the 2013 9th {{Joint Meeting}} on {{Foundations}} of {{Software Engineering}}},
  author = {Lahiri, Shuvendu K. and McMillan, Kenneth L. and Sharma, Rahul and Hawblitzel, Chris},
  year = {2013},
  month = aug,
  series = {{{ESEC}}/{{FSE}} 2013},
  pages = {345--355},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2491411.2491452},
  url = {https://doi.org/10.1145/2491411.2491452},
  urldate = {2022-06-30},
  abstract = {Previous version of a program can be a powerful enabler for program analysis by defining new relative specifications and making the results of current program analysis more relevant. In this paper, we describe the approach of differential assertion checking (DAC) for comparing different versions of a program with respect to a set of assertions. DAC provides a natural way to write relative specifications over two programs. We introduce a novel modular approach to DAC by reducing it to safety checking of a composed program, which can be accomplished by standard program verifiers. In particular, we leverage automatic invariant generation to synthesize relative specifications for pairs of loops and procedures. We provide a preliminary evaluation of a prototype implementation within the SymDiff tool along two directions (a) soundly verifying bug fixes in the presence of loops and (b) providing a knob for suppressing alarms when checking a new version of a program.},
  isbn = {978-1-4503-2237-9},
  keywords = {differential analysis,regressions,verification},
  file = {/home/charlotte/sync/Zotero/storage/3VUU4ZTK/Lahiri et al. - 2013 - Differential assertion checking.pdf}
}

@book{laplanteWhatEveryEngineer2007,
  title = {What Every Engineer Should Know about Software Engineering},
  author = {Laplante, Philip A},
  year = {2007},
  publisher = {{CRC Press}}
}

@article{lebudaTellMeYour2013,
  title = {Tell {{Me Your Name}} and {{I}}'ll {{Tell You How Creative Your Work Is}}: {{Author}}'s {{Name}} and {{Gender}} as {{Factors Influencing Assessment}} of {{Products}}' {{Creativity}} in {{Four Different Domains}}},
  shorttitle = {Tell {{Me Your Name}} and {{I}}'ll {{Tell You How Creative Your Work Is}}},
  author = {Lebuda, Izabela and Karwowski, Maciej},
  year = {2013},
  month = jan,
  journal = {Creativity Research Journal},
  volume = {25},
  number = {1},
  pages = {137--142},
  publisher = {{Routledge}},
  issn = {1040-0419},
  doi = {10.1080/10400419.2013.752297},
  url = {https://doi.org/10.1080/10400419.2013.752297},
  urldate = {2022-08-16},
  abstract = {The main goal of this study was to examine the effects of authors' name and gender on judges' assessment of product creativity in 4 different domains (art, science, music, and poetry). A total of 119 participants divided into 5 groups assessed products signed with a fictional author's name (unique vs. typical, male vs. female) or in an anonymous condition. It was observed that depending on the domain, the uniqueness of the author's name and her or his gender was associated with the assessment of creativity of the product. A poem and painting signed with an unusual name and a piece of music whose authorship was attributed to a man with a unique name were assessed as especially creative. In case of scientific theory, works attributed to men were assessed as significantly more creative than those of women. The results are discussed in light of the attributional approach to creativity.}
}

@article{leeSupportingStudentsGeneration2023,
  title = {Supporting Students' Generation of Feedback in Large-Scale Online Course with Artificial Intelligence-Enabled Evaluation},
  author = {Lee, Alwyn Vwen Yen},
  year = {2023},
  month = jun,
  journal = {Studies in Educational Evaluation},
  volume = {77},
  pages = {101250},
  issn = {0191-491X},
  doi = {10.1016/j.stueduc.2023.101250},
  url = {https://www.sciencedirect.com/science/article/pii/S0191491X23000160},
  urldate = {2024-01-10},
  abstract = {Educators in large-scale online courses tend to lack the necessary resources to generate and provide adequate feedback for all students, especially when students' learning outcomes are evaluated through student writing. As a result, students welcome peer feedback and sometimes generate self-feedback to widen their perspectives and obtain feedback, but often lack the support to do so. This study, as part of a larger project, sought to address this prevalent problem in large-scale courses by allowing students to write essays as an expression of their opinions and response to others, conduct peer and self-evaluation, using provided rubric and Artificial Intelligence (AI)-enabled evaluation to aid the giving and receiving of feedback. A total of 605 undergraduate students were part of a large-scale online course and contributed over 2500 short essays during a semester. The research design uses a mixed-methods approach, consisting qualitative measures used during essay coding, and quantitative methods from the application of machine learning algorithms. With limited instructors and resources, students first use instructor-developed rubric to conduct peer and self-assessment, while instructors qualitatively code a subset of essays that are used as inputs for training a machine learning model, which is subsequently used to provide automated scores and an accuracy rate for the remaining essays. With AI-enabled evaluation, the provision of feedback can become a sustainable process with students receiving and using meaningful feedback for their work, entailing shared responsibility from teachers and students, and becoming more effective.},
  keywords = {Artificial intelligence,Formative assessment,Machine learning,Online course,Peer and self-feedback},
  file = {/home/charlotte/sync/Zotero/storage/4V95XI77/Lee - 2023 - Supporting students’ generation of feedback in lar.pdf;/home/charlotte/sync/Zotero/storage/WGZCH6HT/S0191491X23000160.html}
}

@article{leibaOAuthWebAuthorization2012,
  title = {{{OAuth Web Authorization Protocol}}},
  author = {Leiba, Barry},
  year = {2012},
  month = jan,
  journal = {IEEE Internet Computing},
  volume = {16},
  number = {1},
  pages = {74--77},
  issn = {1941-0131},
  doi = {10.1109/MIC.2012.11},
  abstract = {Allowing one Web service to act on our behalf with another has become increasingly important as social Internet services such as blogs, photo sharing, and social networks have become widely popular. OAuth, a new protocol for establishing identity management standards across services, provides an alternative to sharing our usernames and passwords, and exposing ourselves to attacks on our online data and identities.},
  keywords = {access control,Authentication,authorization,Authorization,Browsers,Electronic mail,Facebook,identity management,Internet,Protocols,Servers,Social network services,social networking,Web services},
  file = {/home/charlotte/sync/Zotero/storage/5Y5CMDU8/Leiba - 2012 - OAuth Web Authorization Protocol.pdf;/home/charlotte/sync/Zotero/storage/66JL2EPQ/6123701.html}
}

@article{liaoRobustMachineLearning2019,
  title = {A {{Robust Machine Learning Technique}} to {{Predict Low-performing Students}}},
  author = {Liao, Soohyun Nam and Zingaro, Daniel and Thai, Kevin and Alvarado, Christine and Griswold, William G. and Porter, Leo},
  year = {2019},
  month = jan,
  journal = {ACM Transactions on Computing Education},
  volume = {19},
  number = {3},
  pages = {18:1--18:19},
  doi = {10.1145/3277569},
  url = {https://doi.org/10.1145/3277569},
  urldate = {2021-09-16},
  abstract = {As enrollments and class sizes in postsecondary institutions have increased, instructors have sought automated and lightweight means to identify students who are at risk of performing poorly in a course. This identification must be performed early enough in the term to allow instructors to assist those students before they fall irreparably behind. This study describes a modeling methodology that predicts student final exam scores in the third week of the term by using the clicker data that is automatically collected for instructors when they employ the Peer Instruction pedagogy. The modeling technique uses a support vector machine binary classifier, trained on one term of a course, to predict outcomes in the subsequent term. We applied this modeling technique to five different courses across the computer science curriculum, taught by three different instructors at two different institutions. Our modeling approach includes a set of strengths not seen wholesale in prior work, while maintaining competitive levels of accuracy with that work. These strengths include using a lightweight source of student data, affording early detection of struggling students, and predicting outcomes across terms in a natural setting (different final exams, minor changes to course content), across multiple courses in a curriculum, and across multiple institutions.},
  keywords = {at-risk students,clicker data,cross-term,machine learning,multi-institution,Peer instruction,prediction},
  file = {/home/charlotte/sync/Zotero/storage/V7D5GFFW/Liao et al. - 2019 - A Robust Machine Learning Technique to Predict Low.pdf}
}

@inproceedings{lienard2023extracting,
  title = {Extracting Unit Tests from Patterns Mined in Student Code to Provide Improved Feedback in Autograders},
  booktitle = {Seminar Series on Advanced Techniques \& Tools for Software Evolution ({{SATToSE}})},
  author = {Lienard, Julien and Mens, Kim and Nijssen, Siegfried},
  year = {2023},
  file = {/home/charlotte/sync/Zotero/storage/V2ECFWXV/Lienard et al. - 2023 - Extracting unit tests from patterns mined in stude.pdf}
}

@article{livierisPredictingSecondarySchool2019,
  title = {Predicting {{Secondary School Students}}' {{Performance Utilizing}} a {{Semi-supervised Learning Approach}}},
  author = {Livieris, Ioannis E. and Drakopoulou, Konstantina and Tampakas, Vassilis T. and Mikropoulos, Tassos A. and Pintelas, Panagiotis},
  year = {2019},
  month = apr,
  journal = {Journal of Educational Computing Research},
  volume = {57},
  number = {2},
  pages = {448--470},
  publisher = {{SAGE Publications Inc}},
  issn = {0735-6331},
  doi = {10.1177/0735633117752614},
  url = {https://doi.org/10.1177/0735633117752614},
  urldate = {2021-09-16},
  abstract = {Educational data mining constitutes a recent research field which gained popularity over the last decade because of its ability to monitor students' academic performance and predict future progression. Numerous machine learning techniques and especially supervised learning algorithms have been applied to develop accurate models to predict student's characteristics which induce their behavior and performance. In this work, we examine and evaluate the effectiveness of two wrapper methods for semisupervised learning algorithms for predicting the students' performance in the final examinations. Our preliminary numerical experiments indicate that the advantage of semisupervised methods is that the classification accuracy can be significantly improved by utilizing a few labeled and many unlabeled data for developing reliable prediction models.},
  langid = {english},
  keywords = {educational data mining,self-training,semisupervised methods,student's evaluation system,Yet Another Two Stage Idea},
  file = {/home/charlotte/sync/Zotero/storage/MN2ZWDUT/Livieris et al. - 2019 - Predicting Secondary School Students' Performance .pdf}
}

@book{looiArtificialIntelligenceEducation2005,
  title = {Artificial {{Intelligence}} in {{Education}}: {{Supporting Learning Through Intelligent}} and {{Socially Informed Technology}}},
  shorttitle = {Artificial {{Intelligence}} in {{Education}}},
  author = {Looi, C.-K. and McCalla, G. and Bredeweg, B.},
  year = {2005},
  month = jul,
  publisher = {{IOS Press}},
  abstract = {The field of Artificial Intelligence in Education has continued to broaden and now includes research and researchers from many areas of technology and social science. This study opens opportunities for the cross-fertilization of information and ideas from researchers in the many fields that make up this interdisciplinary research area, including artificial intelligence, other areas of computer science, cognitive science, education, learning sciences, educational technology, psychology, philosophy, sociology, anthropology, linguistics, and the many domain-specific areas for which Artificial Intelligence in Education systems have been designed and built. An explicit goal is to appeal to those researchers who share the perspective that true progress in learning technology requires both deep insight into technology and also deep insight into learners, learning, and the context of learning. The theme reflects this basic duality.},
  googlebooks = {OALvAgAAQBAJ},
  isbn = {978-1-60750-120-6},
  langid = {english},
  keywords = {Computers / Artificial Intelligence / General},
  file = {/home/charlotte/sync/Zotero/storage/LNF56FUN/Looi et al. - 2005 - Artificial Intelligence in Education Supporting L.pdf}
}

@article{luanAromaCodeRecommendation2019,
  title = {Aroma: Code Recommendation via Structural Code Search},
  shorttitle = {Aroma},
  author = {Luan, Sifei and Yang, Di and Barnaby, Celeste and Sen, Koushik and Chandra, Satish},
  year = {2019},
  month = oct,
  journal = {Proceedings of the ACM on Programming Languages},
  volume = {3},
  number = {OOPSLA},
  pages = {152:1--152:28},
  doi = {10.1145/3360578},
  url = {https://dl.acm.org/doi/10.1145/3360578},
  urldate = {2023-11-23},
  abstract = {Programmers often write code that has similarity to existing code written somewhere. A tool that could help programmers to search such similar code would be immensely useful. Such a tool could help programmers to extend partially written code snippets to completely implement necessary functionality, help to discover extensions to the partial code which are commonly included by other programmers, help to cross-check against similar code written by other programmers, or help to add extra code which would fix common mistakes and errors. We propose Aroma, a tool and technique for code recommendation via structural code search. Aroma indexes a huge code corpus including thousands of open-source projects, takes a partial code snippet as input, searches the corpus for method bodies containing the partial code snippet, and clusters and intersects the results of the search to recommend a small set of succinct code snippets which both contain the query snippet and appear as part of several methods in the corpus. We evaluated Aroma on 2000 randomly selected queries created from the corpus, as well as 64 queries derived from code snippets obtained from Stack Overflow, a popular website for discussing code. We implemented Aroma for 4 different languages, and developed an IDE plugin for Aroma. Furthermore, we conducted a study where we asked 12 programmers to complete programming tasks using Aroma, and collected their feedback. Our results indicate that Aroma is capable of retrieving and recommending relevant code snippets efficiently.},
  keywords = {clone detection,clustering,code recommendation,feature-based code representation,structural code search},
  file = {/home/charlotte/sync/Zotero/storage/HFS4J8WW/Luan et al. - 2019 - Aroma code recommendation via structural code sea.pdf}
}

@misc{luCodeXGLUEMachineLearning2021,
  title = {{{CodeXGLUE}}: {{A Machine Learning Benchmark Dataset}} for {{Code Understanding}} and {{Generation}}},
  shorttitle = {{{CodeXGLUE}}},
  author = {Lu, Shuai and Guo, Daya and Ren, Shuo and Huang, Junjie and Svyatkovskiy, Alexey and Blanco, Ambrosio and Clement, Colin and Drain, Dawn and Jiang, Daxin and Tang, Duyu and Li, Ge and Zhou, Lidong and Shou, Linjun and Zhou, Long and Tufano, Michele and Gong, Ming and Zhou, Ming and Duan, Nan and Sundaresan, Neel and Deng, Shao Kun and Fu, Shengyu and Liu, Shujie},
  year = {2021},
  month = mar,
  number = {arXiv:2102.04664},
  eprint = {2102.04664},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2102.04664},
  url = {http://arxiv.org/abs/2102.04664},
  urldate = {2023-11-23},
  abstract = {Benchmark datasets have a significant impact on accelerating research in programming language tasks. In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning research for program understanding and generation. CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison. CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform. The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Software Engineering},
  file = {/home/charlotte/sync/Zotero/storage/PCHYC68D/Lu et al. - 2021 - CodeXGLUE A Machine Learning Benchmark Dataset fo.pdf;/home/charlotte/sync/Zotero/storage/L5U8STUS/2102.html}
}

@inproceedings{luxton-reillyAutomatedAssessmentExperiences2023,
  title = {Automated {{Assessment}}: {{Experiences From}} the {{Trenches}}},
  shorttitle = {Automated {{Assessment}}},
  booktitle = {Proceedings of the 25th {{Australasian Computing Education Conference}}},
  author = {{Luxton-Reilly}, Andrew and Tempero, Ewan and Arachchilage, Nalin and Chang, Angela and Denny, Paul and Fowler, Allan and Giacaman, Nasser and Kontorovich, Igor and Lottridge, Danielle and Manoharan, Sathiamoorthy and Sindhwani, Shyamli and Singh, Paramvir and Speidel, Ulrich and Stephen, Sudeep and Terragni, Valerio and Whalley, Jacqueline and Wuensche, Burkhard and Ye, Xinfeng},
  year = {2023},
  month = jan,
  series = {{{ACE}} '23},
  pages = {1--10},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3576123.3576124},
  url = {https://dl.acm.org/doi/10.1145/3576123.3576124},
  urldate = {2023-12-02},
  abstract = {Automated assessment is commonly used across the spectrum of computing courses offered by Tertiary institutions. Such assessment is frequently intended to address the scalability of feedback that is essential for learning, and assessment for accreditation purposes. Although many reviews of automated assessment have been reported, the voices of teachers are not present. In this paper we present a variety of cases that illustrate some of the varied motivations and experiences of teaching using automated assessment.},
  isbn = {978-1-4503-9941-8},
  keywords = {automated assessment,computing education,feedback,teaching},
  file = {/home/charlotte/sync/Zotero/storage/MR42KB5K/Luxton-Reilly et al. - 2023 - Automated Assessment Experiences From the Trenche.pdf}
}

@inproceedings{luxton-reillyIntroductoryProgrammingSystematic2018,
  title = {Introductory Programming: A Systematic Literature Review},
  shorttitle = {Introductory Programming},
  booktitle = {Proceedings {{Companion}} of the 23rd {{Annual ACM Conference}} on {{Innovation}} and {{Technology}} in {{Computer Science Education}}},
  author = {{Luxton-Reilly}, Andrew and Simon and Albluwi, Ibrahim and Becker, Brett A. and Giannakos, Michail and Kumar, Amruth N. and Ott, Linda and Paterson, James and Scott, Michael James and Sheard, Judy and Szabo, Claudia},
  year = {2018},
  month = jul,
  series = {{{ITiCSE}} 2018 {{Companion}}},
  pages = {55--106},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3293881.3295779},
  url = {https://doi.org/10.1145/3293881.3295779},
  urldate = {2022-02-25},
  abstract = {As computing becomes a mainstream discipline embedded in the school curriculum and acts as an enabler for an increasing range of academic disciplines in higher education, the literature on introductory programming is growing. Although there have been several reviews that focus on specific aspects of introductory programming, there has been no broad overview of the literature exploring recent trends across the breadth of introductory programming. This paper is the report of an ITiCSE working group that conducted a systematic review in order to gain an overview of the introductory programming literature. Partitioning the literature into papers addressing the student, teaching, the curriculum, and assessment, we explore trends, highlight advances in knowledge over the past 15 years, and indicate possible directions for future research.},
  isbn = {978-1-4503-6223-8},
  keywords = {CS1,introductory programming,ITiCSE working group,literature review,novice programming,overview,review,SLR,systematic literature review,systematic review},
  file = {/home/charlotte/sync/Zotero/storage/H7DE54N9/Luxton-Reilly et al. - 2018 - Introductory programming a systematic literature .pdf}
}

@article{maertensDolosLanguageagnosticPlagiarism2022,
  title = {Dolos: {{Language-agnostic}} Plagiarism Detection in Source Code},
  shorttitle = {Dolos},
  author = {Maertens, Rien and Van Petegem, Charlotte and Strijbol, Niko and Baeyens, Toon and Jacobs, Arne Carla and Dawyndt, Peter and Mesuere, Bart},
  year = {2022},
  journal = {Journal of Computer Assisted Learning},
  issn = {1365-2729},
  doi = {10.1111/jcal.12662},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jcal.12662},
  urldate = {2022-03-25},
  abstract = {Background Learning to code is increasingly embedded in secondary and higher education curricula, where solving programming exercises plays an important role in the learning process and in formative and summative assessment. Unfortunately, students admit that copying code from each other is a common practice and teachers indicate they rarely use plagiarism detection tools. Objectives We want to lower the barrier for teachers to detect plagiarism by introducing a new source code plagiarism detection tool (Dolos) that is powered by state-of-the art similarity detection algorithms, offers interactive visualizations, and uses generic parser models to support a broad range of programming languages. Methods Dolos is compared with state-of-the-art plagiarism detection tools in a benchmark based on a standardized dataset. We describe our experience with integrating Dolos in a programming course with a strong focus on online learning and the impact of transitioning to remote assessment during the COVID-19 pandemic. Results and Conclusions Dolos outperforms other plagiarism detection tools in detecting potential cases of plagiarism and is a valuable tool for preventing and detecting plagiarism in online learning environments. It is available under the permissive MIT open-source license at https://dolos.ugent.be. Implications Dolos lowers barriers for teachers to discover, prove and prevent plagiarism in programming courses. This helps to enable a shift towards open and online learning and assessment environments, and opens up interesting avenues for more effective learning and better assessment.},
  langid = {english},
  keywords = {academic dishonesty,cheating,data visualization,online learning,plagiarism,programming language,remote assessment,source code},
  file = {/home/charlotte/sync/Zotero/storage/98H8W237/Maertens et al. - Dolos Language-agnostic plagiarism detection in s.pdf;/home/charlotte/sync/Zotero/storage/SM9PZIIZ/jcal.html}
}

@inproceedings{maertensDolosSeamlessSource2023,
  title = {Dolos 2.0: {{Towards Seamless Source Code Plagiarism Detection}} in {{Online Learning Environments}}},
  shorttitle = {Dolos 2.0},
  booktitle = {Proceedings of the 2023 {{Conference}} on {{Innovation}} and {{Technology}} in {{Computer Science Education V}}. 2},
  author = {Maertens, Rien and Dawyndt, Peter and Mesuere, Bart},
  year = {2023},
  month = jun,
  series = {{{ITiCSE}} 2023},
  pages = {632},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3587103.3594166},
  url = {https://dl.acm.org/doi/10.1145/3587103.3594166},
  urldate = {2023-11-16},
  abstract = {With the increasing demand for programming skills comes a trend towards more online programming courses and assessments. While this allows educators to teach larger groups of students, it also opens the door to dishonest student behaviour, such as copying code from other students. When teachers use assignments where all students write code for the same problem, source code similarity tools can help to combat plagiarism. Unfortunately, teachers often do not use these tools to prevent such behaviour. In response to this challenge, we have developed a new source code plagiarism detection tool named Dolos. Dolos is open-source, supports a wide range of programming languages, and is designed to be user-friendly. It enables teachers to detect, prove and prevent plagiarism in programming courses by using fast algorithms and powerful visualisations. We present further enhancements to Dolos and discuss how it can be integrated into modern computing education courses to meet the challenges of online learning and assessment. By lowering the barriers for teachers to detect, prove and prevent plagiarism in programming courses, Dolos can help protect academic integrity and ensure that students earn their grades honestly.},
  isbn = {9798400701399},
  keywords = {plagiarism detection,programming education,similarity detection},
  file = {/home/charlotte/sync/Zotero/storage/35UGGC92/Maertens et al. - 2023 - Dolos 2.0 Towards Seamless Source Code Plagiarism.pdf}
}

@article{mahLearningAnalyticsDigital2016,
  title = {Learning {{Analytics}} and {{Digital Badges}}: {{Potential Impact}} on {{Student Retention}} in {{Higher Education}}},
  shorttitle = {Learning {{Analytics}} and {{Digital Badges}}},
  author = {Mah, Dana-Kristin},
  year = {2016},
  month = oct,
  journal = {Technology, Knowledge and Learning},
  volume = {21},
  number = {3},
  pages = {285--305},
  issn = {2211-1670},
  doi = {10.1007/s10758-016-9286-8},
  url = {https://doi.org/10.1007/s10758-016-9286-8},
  urldate = {2024-02-14},
  abstract = {Learning analytics and digital badges are emerging research fields in educational science. They both show promise for enhancing student retention in higher education, where withdrawals prior to degree completion remain at about 30~\% in Organisation for Economic Cooperation and Development member countries. This integrative review provides an overview of the theoretical literature as well as current practices and experience with learning analytics and digital badges in higher education with regard to their potential impact on student retention to enhance students' first-year experience. Learning analytics involves measuring and analyzing dynamic student data in order to gain insight into students' learning processes and optimize learning and teaching. One purpose of learning analytics is to construct predictive models to identify students who risk failing a course and thus are more likely to drop out of higher education. Personalized feedback provides students with information about academic support services, helping them to improve their skills and therefore be successful in higher education. Digital badges are symbols for certifying knowledge, skills, and competencies on web-based platforms. The intention is to encourage student persistence by motivating them, recognizing their generic skills, signaling their achievements, and capturing their learning paths. This article proposes a model that synthesizes learning analytics, digital badges, and generic skills such as academic competencies. The main idea is that generic skills can be represented as digital badges, which can be used for learning analytics algorithms to predict student success and to provide students with personalized feedback for improvement. Moreover, this model may serve as a platform for discussion and further research on learning analytics and digital badges to increase student retention in higher education.},
  langid = {english},
  keywords = {Academic competencies,Digital badges,Generic skills,Learning analytics,Student retention},
  file = {/home/charlotte/sync/Zotero/storage/2ATKA34V/mah2016.pdf.pdf;/home/charlotte/sync/Zotero/storage/SFY9BQJN/Mah - 2016 - Learning Analytics and Digital Badges Potential I.pdf}
}

@article{maloneyScratchProgrammingLanguage2010,
  title = {The {{Scratch Programming Language}} and {{Environment}}},
  author = {Maloney, John and Resnick, Mitchel and Rusk, Natalie and Silverman, Brian and Eastmond, Evelyn},
  year = {2010},
  month = nov,
  journal = {ACM Transactions on Computing Education},
  volume = {10},
  number = {4},
  pages = {16:1--16:15},
  doi = {10.1145/1868358.1868363},
  url = {https://dl.acm.org/doi/10.1145/1868358.1868363},
  urldate = {2024-02-21},
  abstract = {Scratch is a visual programming environment that allows users (primarily ages 8 to 16) to learn computer programming while working on personally meaningful projects such as animated stories and games. A key design goal of Scratch is to support self-directed learning through tinkering and collaboration with peers. This article explores how the Scratch programming language and environment support this goal.},
  keywords = {programming environment,programming language,Scratch,visual programming language},
  file = {/home/charlotte/sync/Zotero/storage/Q3J6XEQ2/Maloney et al. - 2010 - The Scratch Programming Language and Environment.pdf;/home/charlotte/sync/Zotero/storage/YGE92SII/maloney2010.pdf.pdf}
}

@article{malouffBiasGradingMetaanalysis2016,
  title = {Bias in Grading: {{A}} Meta-Analysis of Experimental Research Findings},
  shorttitle = {Bias in Grading},
  author = {Malouff, John M and Thorsteinsson, Einar B},
  year = {2016},
  month = nov,
  journal = {Australian Journal of Education},
  volume = {60},
  number = {3},
  pages = {245--256},
  publisher = {{SAGE Publications Ltd}},
  issn = {0004-9441},
  doi = {10.1177/0004944116664618},
  url = {https://doi.org/10.1177/0004944116664618},
  urldate = {2022-08-16},
  abstract = {This article provides a meta-analysis of experimental research findings on the existence of bias in subjective grading of student work such as essay writing. Twenty-three analyses, from 20 studies, with a total of 1935 graders, met the inclusion criteria for the meta-analysis. All studies involved graders being exposed to a specific type of information about a student other than the student's performance on a task. The hypothesized biasing characteristics included different race/ethnic backgrounds, education-related deficiencies, physical unattractiveness and poor quality of prior performance. The statistically significant overall between-groups effect size was g\,=\,0.36. Moderator analyses showed no significant difference in effect size related to whether the work graded was from a primary school student or a university student. No one type of biasing characteristic showed a significantly higher effect size than other types. The results suggest that bias can occur in subjective grading when graders are aware of irrelevant information about the students.},
  langid = {english},
  keywords = {assessment,bias,Ethnicity,experiment,grading,marking (scholastic),meta-analysis}
}

@article{malouffRiskHaloBias2013,
  title = {The {{Risk}} of a {{Halo Bias}} as a {{Reason}} to {{Keep Students Anonymous During Grading}}},
  author = {Malouff, John M. and Emmerton, Ashley J. and Schutte, Nicola S.},
  year = {2013},
  month = jul,
  journal = {Teaching of Psychology},
  volume = {40},
  number = {3},
  pages = {233--237},
  publisher = {{SAGE Publications Inc}},
  issn = {0098-6283},
  doi = {10.1177/0098628313487425},
  url = {https://doi.org/10.1177/0098628313487425},
  urldate = {2022-08-16},
  abstract = {Experts have advocated anonymous grading as a means of eliminating actual or perceived evaluator bias in subjective student assessment. The utility of anonymity in assessment rests on whether information derived from student identity can unduly influence evaluation. The halo effect provides a conceptual background for why a bias might occur. In the present study examining the halo effect, psychology faculty members and teaching assistants were randomly assigned to grade a student giving a poor oral presentation or the same student giving a good oral presentation. All graders then assessed an unrelated piece of written work by the student. As hypothesized, the graders assigned significantly higher scores to written work following the better oral presentation. The results provide strong evidence of a halo effect in that prior experience with a student biased the grading of written work completed by the student. The findings suggest the need to keep students anonymous when feasible in order to minimize the risk of unfair grading.},
  langid = {english},
  keywords = {grading biases,halo effect,performance appraisals},
  file = {/home/charlotte/sync/Zotero/storage/IBEJ99WF/Malouff et al. - 2013 - The Risk of a Halo Bias as a Reason to Keep Studen.pdf}
}

@inproceedings{maniBetterFeedbackEducational2014,
  title = {Better Feedback for Educational Online Judges},
  booktitle = {Proceedings of the 6th {{International Conference}} on {{Computer Supported Education}}, {{Volume}} 2: {{Barcelona}}, {{Spain}}, 1-3 {{April}}, 2014},
  author = {Mani, Anaga and Venkataramani, Divya and Petit Silvestre, Jordi and Roura Ferret, Salvador},
  year = {2014},
  pages = {176--183},
  publisher = {{SciTePress}},
  doi = {10.5220/0004842801760183},
  url = {https://upcommons.upc.edu/handle/2117/28174},
  urldate = {2022-08-16},
  copyright = {Open Access},
  isbn = {978-989-758-021-5},
  langid = {english},
  keywords = {Arees tematiques de la UPC::Ensenyament i aprenentatge::TIC's aplicades a l'educacio,Arees tematiques de la UPC::Informatica,Automatic assessment,Computer-assisted instruction,Data mining,Ensenyament assistit per ordinador,Mineria de dades,Online programming judges},
  annotation = {Accepted: 2015-06-04T08:47:03Z},
  file = {/home/charlotte/sync/Zotero/storage/U3W7F48R/Mani et al. - 2014 - Better feedback for educational online judges.pdf}
}

@inproceedings{marreroTestingFirstEmphasizing2005,
  title = {Testing First: Emphasizing Testing in Early Programming Courses},
  shorttitle = {Testing First},
  booktitle = {Proceedings of the 10th Annual {{SIGCSE}} Conference on {{Innovation}} and Technology in Computer Science Education},
  author = {Marrero, Will and Settle, Amber},
  year = {2005},
  month = jun,
  series = {{{ITiCSE}} '05},
  pages = {4--8},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1067445.1067451},
  url = {https://doi.org/10.1145/1067445.1067451},
  urldate = {2022-02-25},
  abstract = {The complexity of languages like Java and C++ can make introductory programming classes in these languages extremely challenging for many students. Part of the complexity comes from the large number of concepts and language features that students are expected to learn while having little time for adequate practice or examples. A second source of difficulty is the emphasis that object-oriented programming places on abstraction. We believe that by placing a larger emphasis on testing in programming assignments in these introductory courses, students have an opportunity for extra practice with the language, and this affords them a gentler transition into the abstract thinking needed for programming. In this paper we describe how we emphasized testing in introductory programming assignments by requiring that students design and implement tests before starting on the program itself. We also provide some preliminary results and student reactions.},
  isbn = {978-1-59593-024-8},
  keywords = {CS1,CS2,TDD,testing},
  file = {/home/charlotte/sync/Zotero/storage/N7DEPF4N/Marrero and Settle - 2005 - Testing first emphasizing testing in early progra.pdf}
}

@inproceedings{matzAnalyzingEfficacyECoach2021,
  title = {Analyzing the {{Efficacy}} of {{ECoach}} in {{Supporting Gateway Course Success Through Tailored Support}}},
  booktitle = {{{LAK21}}: 11th {{International Learning Analytics}} and {{Knowledge Conference}}},
  author = {Matz, Rebecca and Schulz, Kyle and Hanley, Elizabeth and Derry, Holly and Hayward, Benjamin and Koester, Benjamin and Hayward, Caitlin and McKay, Timothy},
  year = {2021},
  month = apr,
  series = {{{LAK21}}},
  pages = {216--225},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3448139.3448160},
  url = {https://doi.org/10.1145/3448139.3448160},
  urldate = {2022-09-15},
  abstract = {Large courses act as gateways for college students and often have poor outcomes, particularly in STEM fields where the pace of improvement has been glacial. Students encounter barriers to persistence like low grades, competitive cultures, and a lack of motivation and belonging. Tailored technology systems offer one promising path forward. In this observational study, we report on the use of one such system, called ECoach, that provides students resources based on their psychosocial profile, performance metrics, and pattern of ECoach usage. We investigated ECoach efficacy in five courses enrolling 3,599 students using a clustering method to group users by engagement level and subsequent regression analyses. We present results showing significant positive relationships with small effect sizes between ECoach engagement and final course grade as well as grade anomaly, a performance measure that takes into account prior course grades. The courses with the strongest relationship between ECoach engagement and performance offered nominal extra credit incentives yet show improved grades well above this ``investment'' from instructors. Such small incentives may act as a catalyst that spurs deeper engagement with the platform. The impact of specific ECoach features and areas for future study are discussed.},
  isbn = {978-1-4503-8935-8},
  keywords = {Academic achievement,educational technology,feedback,higher education,large enrollment courses,learning analytics,STEM,undergraduate education},
  file = {/home/charlotte/sync/Zotero/storage/4CTFPVTV/Matz et al. - 2021 - Analyzing the Efficacy of ECoach in Supporting Gat.pdf}
}

@article{mccabeComplexityMeasure1976,
  title = {A {{Complexity Measure}}},
  author = {McCabe, T.J.},
  year = {1976},
  month = dec,
  journal = {IEEE Transactions on Software Engineering},
  volume = {SE-2},
  number = {4},
  pages = {308--320},
  issn = {1939-3520},
  doi = {10.1109/TSE.1976.233837},
  abstract = {This paper describes a graph-theoretic complexity measure and illustrates how it can be used to manage and control program complexity. The paper first explains how the graph-theory concepts apply and gives an intuitive explanation of the graph concepts in programming terms. The control graphs of several actual Fortran programs are then presented to illustrate the correlation between intuitive complexity and the graph-theoretic complexity. Several properties of the graph-theoretic complexity are then proved which show, for example, that complexity is independent of physical size (adding or subtracting functional statements leaves complexity unchanged) and complexity depends only on the decision structure of a program.},
  keywords = {Basis,complexity measure,control flow,decomposition,Fluid flow measurement,graph theory,Graph theory,independence,linear,Linear programming,modularization,National security,programming,reduction,software,Software engineering,Software maintenance,Software measurement,Software systems,Software testing,System testing,testing},
  file = {/home/charlotte/sync/Zotero/storage/THCUMV8S/McCabe - 1976 - A Complexity Measure.pdf;/home/charlotte/sync/Zotero/storage/M4BGMB44/1702388.html}
}

@article{mccartneyWhyComputingStudents2016,
  title = {Why {{Computing Students Learn}} on {{Their Own}}: {{Motivation}} for {{Self-Directed Learning}} of {{Computing}}},
  shorttitle = {Why {{Computing Students Learn}} on {{Their Own}}},
  author = {McCartney, Robert and Boustedt, Jonas and Eckerdal, Anna and Sanders, Kate and Thomas, Lynda and Zander, Carol},
  year = {2016},
  month = jan,
  journal = {ACM Transactions on Computing Education},
  volume = {16},
  number = {1},
  pages = {2:1--2:18},
  doi = {10.1145/2747008},
  url = {https://doi.org/10.1145/2747008},
  urldate = {2021-09-30},
  abstract = {In this article, we address the question of why computing students choose to learn computing topics on their own. A better understanding of why some students choose to learn on their own may help us to motivate other students to develop this important skill. In addition, it may help in curriculum design; if we need to leave some topics out of our expanding curriculum, a good choice might be those topics that students readily learn on their own. Based on a thematic analysis of 17 semistructured interviews, we found that computing students' motivations for self-directed learning fall into four general themes: projects, social and peer interactions, joy of learning, and fear. Under these, we describe several more specific subthemes, illustrated in the words of the students. The project-related and social motivations are quite prominent. Although these motivations appear in the literature, they received greater emphasis from our interviewees. Perhaps most characteristic of computing is the motivation to learn to complete some project, both projects done for fun and projects required for school or work.},
  keywords = {informal learning,Motivation,self-directed learning},
  file = {/home/charlotte/sync/Zotero/storage/DZIEDPUU/McCartney et al. - 2016 - Why Computing Students Learn on Their Own Motivat.pdf}
}

@inproceedings{mccrackenMultinationalMultiinstitutionalStudy2001,
  title = {A Multi-National, Multi-Institutional Study of Assessment of Programming Skills of First-Year {{CS}} Students},
  booktitle = {Working Group Reports from {{ITiCSE}} on {{Innovation}} and Technology in Computer Science Education},
  author = {McCracken, Michael and Almstrum, Vicki and Diaz, Danny and Guzdial, Mark and Hagan, Dianne and Kolikant, Yifat Ben-David and Laxer, Cary and Thomas, Lynda and Utting, Ian and Wilusz, Tadeusz},
  year = {2001},
  month = dec,
  series = {{{ITiCSE-WGR}} '01},
  pages = {125--180},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/572133.572137},
  url = {https://doi.org/10.1145/572133.572137},
  urldate = {2022-02-24},
  abstract = {In computer science, an expected outcome of a student's education is programming skill. This working group investigated the programming competency students have as they complete their first one or two courses in computer science. In order to explore options for assessing students, the working group developed a trial assessment of whether students can program. The underlying goal of this work was to initiate dialog in the Computer Science community on how to develop these types of assessments. Several universities participated in our trial assessment and the disappointing results suggest that many students do not know how to program at the conclusion of their introductory courses. For a combined sample of 216 students from four universities, the average score was 22.89 out of 110 points on the general evaluation criteria developed for this study. From this trial assessment we developed a framework of expectations for first-year courses and suggestions for further work to develop more comprehensive assessments.},
  isbn = {978-1-4503-7359-3},
  file = {/home/charlotte/sync/Zotero/storage/SA2JIH5F/McCracken et al. - 2001 - A multi-national, multi-institutional study of ass.pdf}
}

@article{meansTechnologyEducationChange2010,
  title = {Technology and {{Education Change}}},
  author = {Means, Barbara},
  year = {2010},
  month = mar,
  journal = {Journal of Research on Technology in Education},
  volume = {42},
  number = {3},
  pages = {285--307},
  publisher = {{Routledge}},
  issn = {1539-1523},
  doi = {10.1080/15391523.2010.10782552},
  url = {https://doi.org/10.1080/15391523.2010.10782552},
  urldate = {2021-04-30},
  abstract = {This study examined technology implementation practices associated with student learning gains. Interviews and observations were conducted with staff at schools where teachers using reading or mathematics software with their students attained above-average achievement gains and at schools where software-using teachers had below-average gains. The findings highlight the importance of school practices in the areas of principal support and teacher collaboration around software use and of teacher practices concerning classroom management and use of software-generated student performance data. The issues of instructional coherence and competition for instructional time are highlighted as challenges to software implementation.},
  keywords = {implementation,software,Technology},
  file = {/home/charlotte/sync/Zotero/storage/33QIZ2Q7/Means - 2010 - Technology and Education Change.pdf;/home/charlotte/sync/Zotero/storage/YIZ4RLHU/15391523.2010.html}
}

@article{medeirosSystematicLiteratureReview2019,
  title = {A {{Systematic Literature Review}} on {{Teaching}} and {{Learning Introductory Programming}} in {{Higher Education}}},
  author = {Medeiros, Rodrigo Pessoa and Ramalho, Geber Lisboa and Falc{\~a}o, Taciana Pontual},
  year = {2019},
  month = may,
  journal = {IEEE Transactions on Education},
  volume = {62},
  number = {2},
  pages = {77--90},
  issn = {1557-9638},
  doi = {10.1109/TE.2018.2864133},
  abstract = {Contribution: This paper adds to the results of previous systematic literature reviews by addressing a more contemporary context of introductory programming. It proposes a categorization of introductory programming challenges, and highlights key issues for a research roadmap on introductory programming learning and teaching in higher education. Background: Despite the advances in methods and tools for teaching and learning introductory programming, dropout and failure rates are still high. Published surveys and reviews either cover papers only up to 2007, or focus on methods and tools for teaching introductory programming. Research Questions: 1) What previous skills and background knowledge are key for a novice student to learn programming? 2) What difficulties do novice students encounter in learning how to program? 3) What challenges do teachers encounter in teaching introductory programming? Methodology: Following a formal protocol, automatic and manual searches were performed for work from 2010 to 2016. Of 100 papers selected for data extraction, 89 were retained after quality assessment. Findings: The most frequently cited skills necessary for learning programming were related to problem solving and mathematical ability. Problem solving was also cited as a learning challenge, followed by motivation and engagement, and difficulties in learning the syntax of programming languages. The main teaching challenges concern the lack of appropriate methods and tools, as well as scaling and personalized teaching.},
  keywords = {Achievement,Bibliographies,Education,faculty development,higher education,introductory programming,Manuals,Programming profession,STEM,student experience,systematic review,Systematics,Tools},
  file = {/home/charlotte/sync/Zotero/storage/FM3325MY/Medeiros et al. - 2019 - A Systematic Literature Review on Teaching and Lea.pdf;/home/charlotte/sync/Zotero/storage/UUSKBDBE/8447543.html}
}

@article{mehrabiSurveyBiasFairness2019,
  title = {A {{Survey}} on {{Bias}} and {{Fairness}} in {{Machine Learning}}},
  author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  year = {2019},
  month = sep,
  journal = {arXiv:1908.09635 [cs]},
  eprint = {1908.09635},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1908.09635},
  urldate = {2021-04-30},
  abstract = {With the widespread use of AI systems and applications in our everyday lives, it is important to take fairness issues into consideration while designing and engineering these types of systems. Such systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that the decisions do not reflect discriminatory behavior toward certain groups or populations. We have recently seen work in machine learning, natural language processing, and deep learning that addresses such challenges in different subdomains. With the commercialization of these systems, researchers are becoming aware of the biases that these applications can contain and have attempted to address them. In this survey we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined in order to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and how they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/charlotte/sync/Zotero/storage/6JTUBGJI/Mehrabi et al. - 2019 - A Survey on Bias and Fairness in Machine Learning.pdf;/home/charlotte/sync/Zotero/storage/F76M7UNE/1908.html}
}

@inproceedings{menariniSemanticsassistedCodeReview2017,
  title = {Semantics-Assisted Code Review: {{An}} Efficient Tool Chain and a User Study},
  shorttitle = {Semantics-Assisted Code Review},
  booktitle = {2017 32nd {{IEEE}}/{{ACM International Conference}} on {{Automated Software Engineering}} ({{ASE}})},
  author = {Menarini, Massimiliano and Yan, Yan and Griswold, William G.},
  year = {2017},
  month = oct,
  pages = {554--565},
  doi = {10.1109/ASE.2017.8115666},
  abstract = {Code changes are often reviewed before they are deployed. Popular source control systems aid code review by presenting textual differences between old and new versions of the code, leaving developers with the difficult task of determining whether the differences actually produced the desired behavior. Fortunately, we can mine such information from code repositories. We propose aiding code review with inter-version semantic differential analysis. During review of a new commit, a developer is presented with summaries of both code differences and behavioral differences, which are expressed as diffs of likely invariants extracted by running the system's test cases. As a result, developers can more easily determine that the code changes produced the desired effect. We created an invariant-mining tool chain, Getty, to support our concept of semantically-assisted code review. To validate our approach, 1) we applied Getty to the commits of 6 popular open source projects, 2) we assessed the performance and cost of running Getty in different configurations, and 3) we performed a comparative user study with 18 developers. Our results demonstrate that semantically-assisted code review is feasible, effective, and that real programmers can leverage it to improve the quality of their reviews.},
  keywords = {code review,Computer bugs,dynamic impact analysis,likely invariants,mining software repository,Navigation,scalability,Semantics,Software,Software behavior,software testing,Testing,Tools},
  file = {/home/charlotte/sync/Zotero/storage/2YA7CAKT/Menarini et al. - 2017 - Semantics-assisted code review An efficient tool .pdf;/home/charlotte/sync/Zotero/storage/KI8EE4P4/8115666.html}
}

@inproceedings{mensGoodBadUgly2021,
  title = {The Good, the Bad, and the Ugly: Mining for Patterns in Student Source Code},
  shorttitle = {The Good, the Bad, and the Ugly},
  booktitle = {Proceedings of the 3rd {{International Workshop}} on {{Education}} through {{Advanced Software Engineering}} and {{Artificial Intelligence}}},
  author = {Mens, Kim and Nijssen, Siegfried and Pham, Hoang-Son},
  year = {2021},
  month = aug,
  series = {{{EASEAI}} 2021},
  pages = {1--8},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3472673.3473958},
  url = {https://doi.org/10.1145/3472673.3473958},
  urldate = {2022-07-06},
  abstract = {Research on source code mining has been explored to discover interesting structural regularities, API usage patterns, refactoring opportunities, bugs, crosscutting concerns, code clones and systematic changes. In this paper we present a pattern mining algorithm that uses frequent tree mining to mine for interesting good, bad or ugly coding idioms made by undergraduate students taking an introductory programming course. We do so by looking for patterns that distinguish positive examples, corresponding to the more correct answers to a question, from negative examples, corresponding to solutions that failed the question. We report promising initial results of this algorithm applied to the source code of over 500 students. Even though more work is needed to fine-tune and validate the algorithm further, we hope that it can lead to interesting insights that can eventually be integrated into an intelligent recommendation system to help students learn from their errors.},
  isbn = {978-1-4503-8624-1},
  keywords = {CS education,pattern mining,programming,source code mining},
  file = {/home/charlotte/sync/Zotero/storage/6UVXAKJ4/Mens et al. - 2021 - The good, the bad, and the ugly mining for patter.pdf}
}

@phdthesis{mesuere2016unipept,
  title = {Unipept: Computational Exploration of Metaproteome Data},
  author = {Mesuere, Bart},
  year = {2016},
  school = {Ghent University},
  file = {/home/charlotte/sync/Zotero/storage/KLCPQ4GF/Mesuere - 2016 - Unipept computational exploration of metaproteome.pdf}
}

@article{millerSystematicMistakeAnalysis1963,
  title = {Systematic Mistake Analysis of Digital Computer Programs},
  author = {Miller, Joan C. and Maloney, Clifford J.},
  year = {1963},
  journal = {Communications of the ACM},
  volume = {6},
  number = {2},
  pages = {58--63},
  publisher = {{ACM New York, NY, USA}},
  file = {/home/charlotte/sync/Zotero/storage/I225QATU/Miller and Maloney - 1963 - Systematic mistake analysis of digital computer pr.pdf}
}

@inproceedings{minaei-bidgoliPredictingStudentPerformance2003,
  title = {Predicting Student Performance: An Application of Data Mining Methods with an Educational {{Web-based}} System},
  shorttitle = {Predicting Student Performance},
  booktitle = {33rd {{Annual Frontiers}} in {{Education}}, 2003. {{FIE}} 2003.},
  author = {{Minaei-Bidgoli}, B. and Kashy, D. A. and Kortemeyer, G. and Punch, W. F.},
  year = {2003},
  month = nov,
  volume = {1},
  pages = {T2A-13},
  issn = {0190-5848},
  doi = {10.1109/FIE.2003.1263284},
  abstract = {Newly developed Web-based educational technologies offer researchers unique opportunities to study how students learn and what approaches to learning lead to success. Web-based systems routinely collect vast quantities of data on user patterns, and data mining methods can be applied to these databases. This paper presents an approach to classifying students in order to predict their final grade based on features extracted from logged data in an education Web-based system. We design, implement, and evaluate a series of pattern classifiers and compare their performance on an online course dataset. A combination of multiple classifiers leads to a significant improvement in classification performance. Furthermore, by learning an appropriate weighting of the features used via a genetic algorithm (GA), we further improve prediction accuracy. The GA is demonstrated to successfully improve the accuracy of combined classifier performance, about 10 to 12\% when comparing to non-GA classifier. This method may be of considerable usefulness in identifying students at risk early, especially in very large classes, and allow the instructor to provide appropriate advising in a timely manner.},
  keywords = {Accuracy,computer aided instruction,data mining,Data mining,Education,Educational institutions,Educational technology,Feature extraction,genetic algorithm,genetic algorithms,Genetic algorithms,Internet,pattern classification,Spatial databases,student performance,System testing,Web pages,Web-based educational technologies},
  file = {/home/charlotte/sync/Zotero/storage/BA342UGB/1263284.html}
}

@inproceedings{mishraProgrammingExerciseMarkup2023,
  title = {The {{Programming Exercise Markup Language}}: {{Towards Reducing}} the {{Effort Needed}} to {{Use Automated Grading Tools}}},
  shorttitle = {The {{Programming Exercise Markup Language}}},
  booktitle = {Proceedings of the 54th {{ACM Technical Symposium}} on {{Computer Science Education V}}. 1},
  author = {Mishra, Divyansh S. and Edwards, Stephen H.},
  year = {2023},
  month = mar,
  series = {{{SIGCSE}} 2023},
  pages = {395--401},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3545945.3569734},
  url = {https://dl.acm.org/doi/10.1145/3545945.3569734},
  urldate = {2024-01-05},
  abstract = {Automated programming assignment grading tools have become integral to CS courses at introductory as well as advanced levels. However such tools have their own custom approaches to setting up assignments and describing how solutions should be tested, requiring instructors to make a significant learning investment to begin using a new tool. In addition, differences between tools mean that initial investment must be repeated when switching tools or adding a new one. Worse still, tool-specific strategies further reduce the ability of educators to share and reuse their assignments. This paper describes an early experiences with PEML, the Programming Exercise Markup Language, which provides an easy to use, instructor friendly approach for writing programming assignments. Unlike tool-oriented data interchange formats, PEML is designed to provide a human friendly authoring format that has been developed to be intuitive, expressive and not be a technological or notational barrier to instructors. We describe the design and implementation of PEML, both as a programming library and also a public-access web microservice that provides full parsing and rendering capabilities for easy integration into any tools or scripting libraries. We also describe experiences using PEML to describe a full range of programming assignments, laboratory exercises, and small coding questions of varying complexity in demonstrating the practicality of the notation. The aim is to develop PEML as a community resource to reduce the barriers to entry for automated assignment tools while widening the scope of programming assignment sharing and reuse across courses and institutions.},
  isbn = {978-1-4503-9431-4},
  keywords = {automated grading,interchange format,markup language,notation,programming assignment,web service},
  file = {/home/charlotte/sync/Zotero/storage/K7SJQZZK/Mishra and Edwards - 2023 - The Programming Exercise Markup Language Towards .pdf}
}

@inproceedings{mitamuraSeriousGamesLearning2012,
  title = {Serious Games for Learning Programming Languages},
  booktitle = {2012 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  author = {Mitamura, Tamotsu and Suzuki, Yasuhiro and Oohori, Takahumi},
  year = {2012},
  month = oct,
  pages = {1812--1817},
  issn = {1062-922X},
  doi = {10.1109/ICSMC.2012.6378001},
  abstract = {In recent years, so-called serious games, where some kind of knowledge is gained through digital game play, have received significant attention and there has been an active movement toward games that effectively enrich the learning environment. Serious games are games that are developed according to the concept, ``It is possible through game play to obtain some kind of knowledge while having fun. Through these serious games, there has been an active movement toward fun learning using games in education at school and internal training at organizations. In contrast, at universities the level of learning programming differs significantly depending on the academic background of the student and there are issues with traditional programming education learning because the student does not feel enjoyment and is not interested in information engineering. As a countermeasure, teaching methods and teaching aids etc. have been cited as themes and learning through the utilization of serious games and game development has been proposed to tackle these themes. In this paper we propose and evaluate serious games for programming learning based on the concept ``Learning programming through gaming''.},
  keywords = {Educational institutions,Games,Java,Programming Languages,Programming profession,Serious Games},
  file = {/home/charlotte/sync/Zotero/storage/5FFVE8U4/Mitamura et al. - 2012 - Serious games for learning programming languages.pdf;/home/charlotte/sync/Zotero/storage/IPEK5HYI/6378001.html}
}

@book{molnarInterpretableMachineLearning2019,
  title = {Interpretable {{Machine Learning}}},
  author = {Molnar, Christoph},
  year = {2019},
  url = {https://christophm.github.io/interpretable-ml-book/},
  urldate = {2021-08-24},
  abstract = {Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable.},
  file = {/home/charlotte/sync/Zotero/storage/HV4YWAEG/interpretable-ml-book.html}
}

@inproceedings{munaiahAssistedDiscoverySoftware2018,
  title = {Assisted Discovery of Software Vulnerabilities},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Software Engineering}}: {{Companion Proceeedings}}},
  author = {Munaiah, Nuthan},
  year = {2018},
  month = may,
  series = {{{ICSE}} '18},
  pages = {464--467},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3183440.3183453},
  url = {https://doi.org/10.1145/3183440.3183453},
  urldate = {2022-06-30},
  abstract = {As more aspects of our daily lives rely on technology, the software that enables the technology must be secure. Developers rely on practices such as threat modeling, static and dynamic analyses, code review, and fuzz and penetration testing to engineer secure software. These practices, while effective at identifying vulnerabilities in software, are limited in their ability to describe the potential reasons for the existence of vulnerabilities. In order to overcome this limitation, researchers have proposed empirically validated metrics to identify factors that may have led to the introduction of vulnerabilities in the past. Developers must be made aware of these factors so that they can proactively consider the security implications of each line of code that they contribute. The goal of our research is to assist developers in engineering secure software by providing a technique that generates scientific, interpretable, and actionable feedback on security as the software evolves. In this paper, we provide an overview of our proposed approach to accomplish this research goal through a series of three research studies in which we (1) systematize the knowledge on vulnerability discovery metrics, (2) leverage the metrics to generate feedback on security, and (3) implement a framework for providing automatically generated feedback on security using code reviews as a medium.},
  isbn = {978-1-4503-5663-3},
  file = {/home/charlotte/sync/Zotero/storage/2BZQMI9Z/Munaiah - 2018 - Assisted discovery of software vulnerabilities.pdf}
}

@article{myersAnONDDifference1986,
  title = {{{AnO}}({{ND}}) Difference Algorithm and Its Variations},
  author = {Myers, Eugene W.},
  year = {1986},
  month = nov,
  journal = {Algorithmica},
  volume = {1},
  number = {1},
  pages = {251--266},
  issn = {1432-0541},
  doi = {10.1007/BF01840446},
  url = {https://doi.org/10.1007/BF01840446},
  urldate = {2022-08-16},
  abstract = {The problems of finding a longest common subsequence of two sequencesA andB and a shortest edit script for transformingA intoB have long been known to be dual problems. In this paper, they are shown to be equivalent to finding a shortest/longest path in an edit graph. Using this perspective, a simpleO(ND) time and space algorithm is developed whereN is the sum of the lengths ofA andB andD is the size of the minimum edit script forA andB. The algorithm performs well when differences are small (sequences are similar) and is consequently fast in typical applications. The algorithm is shown to haveO(N+D2) expected-time performance under a basic stochastic model. A refinement of the algorithm requires onlyO(N) space, and the use of suffix trees leads to anO(N logN+D2) time variation.},
  langid = {english},
  keywords = {Edit graph,File comparison,Longest common subsequence,Shortest edit script}
}

@article{nandiEvaluatingQualityInteraction2012,
  title = {Evaluating the Quality of Interaction in Asynchronous Discussion Forums in Fully Online Courses},
  author = {Nandi, Dip and Hamilton, Margaret and Harland, James},
  year = {2012},
  month = may,
  journal = {Distance Education},
  volume = {33},
  number = {1},
  pages = {5--30},
  publisher = {{Routledge}},
  issn = {0158-7919},
  doi = {10.1080/01587919.2012.667957},
  url = {https://doi.org/10.1080/01587919.2012.667957},
  urldate = {2022-08-16},
  abstract = {Fully online courses are becoming progressively more popular because of their ``anytime anywhere'' learning flexibility. One of the ways students interact with each other and with the instructors within fully online learning environments is via asynchronous discussion forums. However, student engagement in online discussion forums does not always take place automatically and there is a lack of clarity about the ideal role of the instructors in them. In this article, we report on our research on the quality of discussion in fully online courses through analysis of discussion forum activities. We have conducted our research on two large fully online subjects for computing students over two consecutive semesters and used a grounded theoretic approach for data analysis. Our results reveal what students and instructors consider as quality interaction in fully online courses. We also propose two frameworks based on our findings that can be used to ensure effective online interaction.},
  keywords = {asynchronous discussion forums,fully online course,quality framework}
}

@article{naurAutomaticGradingStudents1964,
  title = {Automatic Grading of Students' {{ALGOL}} Programming},
  author = {Naur, Peter},
  year = {1964},
  month = sep,
  journal = {BIT},
  volume = {4},
  number = {3},
  pages = {177--188},
  issn = {0006-3835},
  doi = {10.1007/BF01956028},
  url = {https://doi.org/10.1007/BF01956028},
  urldate = {2024-02-06},
  abstract = {The report describes an experiment on automatic grading of student algorithms, using an ALGOL compiler. The experiment is based on an evaluation of the efficiency and logical completeness of the algorithms, not on their formal correctness, which is supposed to be checked in advance by the individual student. The technique used is to embed the student algorithms within a larger grading program structure, which supplies test cases and performs checks and evaluation. The complete text of such a grading program is given. The experience gained through the experiment, and suggestions for further developments, are discussed.},
  keywords = {Complete Text,Computational Mathematic,Formal Correctness,Individual Student,Program Structure},
  file = {/home/charlotte/sync/Zotero/storage/7XRCLVIF/naur1964.pdf.pdf}
}

@inproceedings{navratOnlineProgrammingExercises2014,
  title = {Online Programming Exercises for Summative Assessment in University Courses},
  booktitle = {Proceedings of the 15th {{International Conference}} on {{Computer Systems}} and {{Technologies}}},
  author = {Navrat, Pavol and Tvarozek, Jozef},
  year = {2014},
  month = jun,
  series = {{{CompSysTech}} '14},
  pages = {341--348},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2659532.2659628},
  url = {https://doi.org/10.1145/2659532.2659628},
  urldate = {2021-02-22},
  abstract = {Although interactive e-learning environments are increasingly used in university courses, traditional types of examination still dominate the way how students are assessed for grades. In this paper, we examined how student data from online interactive learning environment for programming exercises can be used for summative assessment at the end of the course. Using data from three different university courses, we calibrated the two parameter logistic regression model, ranked students according to their ability of solving problems, and matched them to final grades. Results indicate we can predict grades within 0.57 to 1.02 level of accuracy, suggesting that careful use of interactive e-learning environments in university courses can substitute existing assessment methods, opening further possibilities for innovation in instructional process.},
  isbn = {978-1-4503-2753-4},
  keywords = {interactive e-learning,online learning environment,programming exercises,summative assessment,technology enhanced learning},
  file = {/home/charlotte/sync/Zotero/storage/ER9B2MRP/Navrat and Tvarozek - 2014 - Online programming exercises for summative assessm.pdf}
}

@article{neutenstomAssessmentCodeWhich2021,
  title = {Assessment of Code, Which Aspects Do Teachers Consider and How Are They Valued?},
  author = {NeutensTom and CoolsaetKris and {wyffelsFrancis}},
  year = {2021},
  month = aug,
  journal = {ACM Transactions on Computing Education (TOCE)},
  publisher = {{ACM}},
  doi = {10.1145/3517133},
  url = {https://dl.acm.org/doi/abs/10.1145/3517133},
  urldate = {2022-04-01},
  abstract = {In many countries, computer programming is becoming an integral part of the secondary school curriculum. However, many teachers, especially in the first years of Flemish secondary school, have limited experience with teaching programming. To improve their ...},
  langid = {english},
  annotation = {PUB27 New York, NY},
  file = {/home/charlotte/sync/Zotero/storage/UPCIS3VK/NeutensTom et al. - 2021 - Assessment of code, which aspects do teachers cons.pdf;/home/charlotte/sync/Zotero/storage/SAYY7V2P/3517133.html}
}

@article{newmanStudentsPerceptionsTeacher1993,
  title = {Students' {{Perceptions}} of the {{Teacher}} and {{Classmates}} in {{Relation}} to {{Reported Help Seeking}} in {{Math Class}}},
  author = {Newman, Richard S. and Schwager, Mahna T.},
  year = {1993},
  month = sep,
  journal = {The Elementary School Journal},
  volume = {94},
  number = {1},
  pages = {3--17},
  publisher = {{The University of Chicago Press}},
  issn = {0013-5984},
  doi = {10.1086/461747},
  url = {https://www.journals.uchicago.edu/doi/abs/10.1086/461747},
  urldate = {2022-08-16},
  abstract = {This study investigated students' perceptions of their teachers and classmates in relation to reported academic help seeking. 177 students at grades 3, 5, and 7 were interviewed individually using a structured questionnaire to assess who, why, and in what situations they asked for help when they had problems in math class. Results indicated that students generally preferred the teacher to classmates as helpers and saw the teacher, in comparison to classmates, as more likely to facilitate learning and less likely to think they were "dumb" for asking questions. Several grade-related differences emerged. Fifth and seventh graders' help-seeking intentions reflected more concern about social comparison than did third graders'. At seventh grade only, a concern that the teacher might think students were "dumb" for asking questions was negatively related to the self-reported likelihood of seeking help. Perceptions of teacher support varied with grade level. Although perception of a strong personal relationship with the teacher was associated with students' intentions to seek help at all grades, perception of teacher encouragement of questioning was related only at fifth and seventh grades.}
}

@article{nicolFormativeAssessmentSelf2006,
  title = {Formative Assessment and Self-regulated Learning: A Model and Seven Principles of Good Feedback Practice},
  shorttitle = {Formative Assessment and Self-regulated Learning},
  author = {Nicol, David J. and Macfarlane-Dick, Debra},
  year = {2006},
  month = apr,
  journal = {Studies in Higher Education},
  volume = {31},
  number = {2},
  pages = {199--218},
  publisher = {{Routledge}},
  issn = {0307-5079},
  doi = {10.1080/03075070600572090},
  url = {https://doi.org/10.1080/03075070600572090},
  urldate = {2022-02-21},
  abstract = {The research on formative assessment and feedback is reinterpreted to show how these processes can help students take control of their own learning, i.e. become self-regulated learners. This reformulation is used to identify seven principles of good feedback practice that support self-regulation. A key argument is that students are already assessing their own work and generating their own feedback, and that higher education should build on this ability. The research underpinning each feedback principle is presented, and some examples of easy-to-implement feedback strategies are briefly described. This shift in focus, whereby students are seen as having a proactive rather than a reactive role in generating and using feedback, has profound implications for the way in which teachers organise assessments and support learning.},
  file = {/home/charlotte/sync/Zotero/storage/KPAM4LT7/Nicol and Macfarlane‐Dick - 2006 - Formative assessment and self‐regulated learning .pdf;/home/charlotte/sync/Zotero/storage/P2LCKCBM/03075070600572090.html}
}

@article{nidhraBlackBoxWhite2012,
  title = {Black Box and White Box Testing Techniques-a Literature Review},
  author = {Nidhra, Srinivas and Dondeti, Jagruthi},
  year = {2012},
  journal = {International Journal of Embedded Systems and Applications (IJESA)},
  volume = {2},
  number = {2},
  pages = {29--50},
  file = {/home/charlotte/sync/Zotero/storage/I8LFXN35/Nidhra and Dondeti - 2012 - Black box and white box testing techniques-a liter.pdf}
}

@techreport{nievergeltACSESAutomatedComputer1976,
  title = {{{ACSES}}: {{The Automated Computer Science Education System}} at the {{University}} of {{Illinois}}},
  shorttitle = {{{ACSES}}},
  author = {Nievergelt, J. and Others, And},
  year = {1976},
  month = aug,
  url = {https://eric.ed.gov/?id=ED134229},
  urldate = {2024-02-07},
  abstract = {The Automated Computer Science Educational System (ACSES) has been developed at the University of Illinois for the purpose of providing improved education for the large number of students taking introductory computer science courses. The major components of this system are: a library of instructional lessons, an interactive programing system with excellent error diagnostics, an information retrieval system, an automated exam and quiz system, and several lessons which judge student programs. This report briefly describes each of these components, as well as some ideas on programing language design resulting from this experience, and presents an evaluation of the use of the system over the past three years. (Author)},
  langid = {english},
  keywords = {Artificial Intelligence,College Curriculum,Computer Assisted Instruction,Computer Science Education,Information Retrieval,Instructional Innovation,Instructional Systems,Online Systems,Programing Languages},
  annotation = {ERIC Number: ED134229},
  file = {/home/charlotte/sync/Zotero/storage/S56CZBGA/Nievergelt and Others - 1976 - ACSES The Automated Computer Science Education Sy.pdf}
}

@article{nirmalakhandanTeachingToolsPromote2007,
  title = {Teaching {{Tools}} to {{Promote Active Learning}}: {{Case Study}}},
  shorttitle = {Teaching {{Tools}} to {{Promote Active Learning}}},
  author = {Nirmalakhandan, N. and Ricketts, C. and McShannon, J. and Barrett, S.},
  year = {2007},
  month = jan,
  journal = {Journal of Professional Issues in Engineering Education and Practice},
  volume = {133},
  number = {1},
  pages = {31--37},
  publisher = {{American Society of Civil Engineers}},
  issn = {1052-3928},
  doi = {10.1061/(ASCE)1052-3928(2007)133:1(31)},
  url = {https://ascelibrary.org/doi/abs/10.1061/%28ASCE%291052-3928%282007%29133%3A1%2831%29},
  urldate = {2021-10-01},
  abstract = {In this case study, we present a teaching approach that promotes active learning in engineering classes. Students are provided with a combination of physical, mathematical, and computer simulation models that allow them to participate, act, react, and reflect, rather than just listen to lectures, as in traditional classes. We illustrate important aspects of our pedagogy with one of 12 modules that have been implemented in an undergraduate hydraulic engineering course. Student evaluations indicate that this approach is appealing to most students. Data are presented to show that this approach has contributed to improved student learning and achievement.},
  langid = {english},
  keywords = {Case reports,Computer models,Computer software,Engineering education,Mathematical models,Physical properties,Simulation models},
  file = {/home/charlotte/sync/Zotero/storage/SHENAY3T/Nirmalakhandan et al. - 2007 - Teaching Tools to Promote Active Learning Case St.pdf;/home/charlotte/sync/Zotero/storage/GHF6GZKB/(ASCE)1052-3928(2007)1331(31).html}
}

@article{nustRockerversePackagesApplications2020,
  title = {The {{Rockerverse}}: {{Packages}} and {{Applications}} for {{Containerisation}} with {{R}}},
  shorttitle = {The {{Rockerverse}}},
  author = {N{\"u}st, Daniel and Eddelbuettel, Dirk and Bennett, Dom and Cannoodt, Robrecht and Clark, Dav and Dar{\'o}czi, Gergely and Edmondson, Mark and Fay, Colin and Hughes, Ellis and Kjeldgaard, Lars and Lopp, Sean and Marwick, Ben and Nolis, Heather and Nolis, Jacqueline and Ooi, Hong and Ram, Karthik and Ross, Noam and Shepherd, Lori and S{\'o}lymos, P{\'e}ter and Swetnam, Tyson Lee and Turaga, Nitesh and Van Petegem, Charlotte and Williams, Jason and Willis, Craig and Xiao, Nan},
  year = {2020},
  journal = {The R Journal},
  volume = {12},
  number = {1},
  pages = {437--461},
  issn = {2073-4859},
  doi = {10.32614/RJ-2020-007},
  url = {https://journal.r-project.org/archive/2020/RJ-2020-007/index.html},
  urldate = {2021-02-26},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/ACQBCGCE/Nüst et al. - 2020 - The Rockerverse Packages and Applications for Con.pdf;/home/charlotte/sync/Zotero/storage/6JE8GK6V/index.html}
}

@book{oberkampfVerificationValidationScientific2010,
  title = {Verification and {{Validation}} in {{Scientific Computing}}},
  author = {Oberkampf, William L. and Roy, Christopher J.},
  year = {2010},
  month = oct,
  publisher = {{Cambridge University Press}},
  abstract = {Advances in scientific computing have made modelling and simulation an important part of the decision-making process in engineering, science, and public policy. This book provides a comprehensive and systematic development of the basic concepts, principles, and procedures for verification and validation of models and simulations. The emphasis is placed on models that are described by partial differential and integral equations and the simulations that result from their numerical solution. The methods described can be applied to a wide range of technical fields, from the physical sciences, engineering and technology and industry, through to environmental regulations and safety, product and plant safety, financial investing, and governmental regulations. This book will be genuinely welcomed by researchers, practitioners, and decision makers in a broad range of fields, who seek to improve the credibility and reliability of simulation results. It will also be appropriate either for university courses or for independent study.},
  googlebooks = {7d26zLEJ1FUC},
  isbn = {978-1-139-49176-1},
  langid = {english},
  keywords = {Computers / General,Mathematics / Differential Equations / General,Mathematics / Discrete Mathematics,Mathematics / Numerical Analysis}
}

@book{oecdOECDDigitalEducation2021,
  type = {Doi:{{https://doi.org/10.1787/589b283f-en}}},
  title = {{{OECD Digital Education Outlook}} 2021},
  author = {OECD},
  year = {2021},
  url = {https://www.oecd-ilibrary.org/content/publication/589b283f-en}
}

@misc{oreillyWhatWebDesign2007,
  type = {{{SSRN Scholarly Paper}}},
  title = {What Is {{Web}} 2.0: {{Design Patterns}} and {{Business Models}} for the {{Next Generation}} of {{Software}}},
  shorttitle = {What Is {{Web}} 2.0},
  author = {O'Reilly, Tim},
  year = {2007},
  month = aug,
  number = {1008839},
  address = {{Rochester, NY}},
  url = {https://papers.ssrn.com/abstract=1008839},
  urldate = {2024-02-08},
  abstract = {This paper was the first initiative to try to define Web 2.0 and understand its implications for the next generation of software, looking at both design patterns and business modes. Web 2.0 is the network as platform, spanning all connected devices; Web 2.0 applications are those that make the most of the intrinsic advantages of that platform: delivering software as a continually-updated service that gets better the more people use it, consuming and remixing data from multiple sources, including individual users, while providing their own data and services in a form that allows remixing by others, creating network effects through an architecture of participation, and going beyond the page metaphor of Web 1.0 to deliver rich user experiences.},
  langid = {english},
  keywords = {collective intelligence,data,long tail and beta,rich client,software as a service},
  file = {/home/charlotte/sync/Zotero/storage/KAZ6EHDA/O'Reilly - 2007 - What is Web 2.0 Design Patterns and Business Mode.pdf}
}

@article{osmanbegovicDataMiningApproach2012,
  title = {Data Mining Approach for Predicting Student Performance},
  author = {Osmanbegovic, Edin and Suljic, Mirza},
  year = {2012},
  journal = {Economic Review: Journal of Economics and Business},
  volume = {10},
  number = {1},
  pages = {3--12},
  publisher = {{Tuzla: University of Tuzla, Faculty of Economics}},
  file = {/home/charlotte/sync/Zotero/storage/HN484VJ9/Osmanbegovic and Suljic - 2012 - Data mining approach for predicting student perfor.pdf;/home/charlotte/sync/Zotero/storage/AGG6SJ86/193806.html}
}

@article{owenImpactFeedbackFormative2016,
  title = {The {{Impact}} of {{Feedback}} as {{Formative Assessment}} on {{Student Performance}}},
  author = {Owen, Leanne},
  year = {2016},
  journal = {International Journal of Teaching and Learning in Higher Education},
  volume = {28},
  number = {2},
  pages = {168--175},
  publisher = {{International Society for Exploring Teaching and Learning}},
  url = {https://eric.ed.gov/?id=EJ1111131},
  urldate = {2024-01-10},
  abstract = {This article provides an evaluation of the redesign of a research methods course intended to enhance students' learning for understanding and transfer. Drawing on principles of formative assessment from the existing academic literature, the instructor introduced a number of increasingly complex low-stakes assignments for students to complete prior to submitting their final project. Concrete, constructive feedback from either the instructor or peers or both was offered at each stage of the project so that students could have the opportunity to review their work and improve particular aspects prior to moving on to the next assignment. Student performance on each subsequent submission was assessed through the use of a scoring rubric. Although there was significant improvement from one draft of a given assignment (T1) to the next (T2), the instructor's decision not to require a preliminary draft of the final project ultimately yielded mixed results at the end of the course (T3); this serves to highlight the importance of providing multiple active learning opportunities for students by using a progressive scaffolding approach.},
  langid = {english},
  keywords = {Academic Achievement,Active Learning,Assignments,College Students,Feedback (Response),Formative Evaluation,Instructional Design,Methods Courses,Research Methodology,Scaffolding (Teaching Technique),Scoring Rubrics,Student Evaluation,Student Projects},
  annotation = {ERIC Number: EJ1111131},
  file = {/home/charlotte/sync/Zotero/storage/KKLMLPAK/Owen - 2016 - The Impact of Feedback as Formative Assessment on .pdf}
}

@article{paivaAutomatedAssessmentComputer2022,
  title = {Automated {{Assessment}} in {{Computer Science Education}}: {{A State-of-the-Art Review}}},
  shorttitle = {Automated {{Assessment}} in {{Computer Science Education}}},
  author = {Paiva, Jos{\'e} Carlos and Leal, Jos{\'e} Paulo and Figueira, {\'A}lvaro},
  year = {2022},
  month = jun,
  journal = {ACM Transactions on Computing Education},
  volume = {22},
  number = {3},
  pages = {34:1--34:40},
  doi = {10.1145/3513140},
  url = {https://doi.org/10.1145/3513140},
  urldate = {2022-08-16},
  abstract = {Practical programming competencies are critical to the success in computer science (CS) education and go-to-market of fresh graduates. Acquiring the required level of skills is a long journey of discovery, trial and error, and optimization seeking through a broad range of programming activities that learners must perform themselves. It is not reasonable to consider that teachers could evaluate all attempts that the average learner should develop multiplied by the number of students enrolled in a course, much less in a timely, deep, and fair fashion. Unsurprisingly, exploring the formal structure of programs to automate the assessment of certain features has long been a hot topic among CS education practitioners. Assessing a program is considerably more complex than asserting its functional correctness, as the proliferation of tools and techniques in the literature over the past decades indicates. Program efficiency, behavior, and readability, among many other features, assessed either statically or dynamically, are now also relevant for automatic evaluation. The outcome of an evaluation evolved from the primordial Boolean values to information about errors and tips on how to advance, possibly taking into account similar solutions. This work surveys the state of the art in the automated assessment of CS assignments, focusing on the supported types of exercises, security measures adopted, testing techniques used, type of feedback produced, and the information they offer the teacher to understand and optimize learning. A new era of automated assessment, capitalizing on static analysis techniques and containerization, has been identified. Furthermore, this review presents several other findings from the conducted review, discusses the current challenges of the field, and proposes some future research directions.},
  keywords = {Automated assessment,computer science,feedback,learning analytics,programming},
  file = {/home/charlotte/sync/Zotero/storage/J782VVIT/Paiva et al. - 2022 - Automated Assessment in Computer Science Education.pdf}
}

@article{paivaManagingGamifiedProgramming2022,
  title = {Managing {{Gamified Programming Courses}} with the {{FGPE Platform}}},
  author = {Paiva, Jos{\'e} Carlos and Queir{\'o}s, Ricardo and Leal, Jos{\'e} Paulo and Swacha, Jakub and Miernik, Filip},
  year = {2022},
  month = feb,
  journal = {Information},
  volume = {13},
  number = {2},
  pages = {45},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2078-2489},
  doi = {10.3390/info13020045},
  url = {https://www.mdpi.com/2078-2489/13/2/45},
  urldate = {2023-10-02},
  abstract = {E-learning tools are gaining increasing relevance as facilitators in the task of learning how to program. This is mainly a result of the pandemic situation and consequent lockdown in several countries, which forced distance learning. Instant and relevant feedback to students, particularly if coupled with gamification, plays a pivotal role in this process and has already been demonstrated as an effective solution in this regard. However, teachers still struggle with the lack of tools that can adequately support the creation and management of online gamified programming courses. Until now, there was no software platform that would be simultaneously open-source and general-purpose (i.e., not integrated with a specific course on a specific programming language) while featuring a meaningful selection of gamification components. Such a solution has been developed as a part of the Framework for Gamified Programming Education (FGPE) project. In this paper, we present its two front-end components: FGPE AuthorKit and FGPE PLE, explain how they can be used by teachers to prepare and manage gamified programming courses, and report the results of the usability evaluation by the teachers using the platform in their classes.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {automatic assessment,gamification,learning environment,programming exercises,programming learning,usability evaluation},
  file = {/home/charlotte/sync/Zotero/storage/SS4QTB5K/Paiva et al. - 2022 - Managing Gamified Programming Courses with the FGP.pdf}
}

@inproceedings{pariharAutomaticGradingFeedback2017,
  title = {Automatic {{Grading}} and {{Feedback}} Using {{Program Repair}} for {{Introductory Programming Courses}}},
  booktitle = {Proceedings of the 2017 {{ACM Conference}} on {{Innovation}} and {{Technology}} in {{Computer Science Education}}},
  author = {Parihar, Sagar and Dadachanji, Ziyaan and Singh, Praveen Kumar and Das, Rajdeep and Karkare, Amey and Bhattacharya, Arnab},
  year = {2017},
  month = jun,
  series = {{{ITiCSE}} '17},
  pages = {92--97},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3059009.3059026},
  url = {https://dl.acm.org/doi/10.1145/3059009.3059026},
  urldate = {2023-10-05},
  abstract = {We present GradeIT, a system that combines the dual objectives of automated grading and program repairing for introductory programming courses (CS1). Syntax errors pose a significant challenge for testcase-based grading as it is difficult to differentiate between a submission that is almost correct and has some minor syntax errors and another submission that is completely off-the-mark. GradeIT also uses program repair to help in grading submissions that do not compile. This enables running testcases on submissions containing minor syntax errors, thereby awarding partial marks for these submissions (which, without repair, do not compile successfully and, hence, do not pass any testcase). Our experiments on 15613 submissions show that GradeIT results are comparable to manual grading by teaching assistants (TAs), and do not suffer from unintentional variability that happens when multiple TAs grade the same assignment. The repairs performed by GradeIT enabled successful compilation of 56\% of the submissions having compilation errors, and resulted in an improvement in marks for 11\% of these submissions.},
  isbn = {978-1-4503-4704-4},
  keywords = {automated grading,cs1,programming assignments},
  file = {/home/charlotte/sync/Zotero/storage/DRRPWHV5/Parihar et al. - 2017 - Automatic Grading and Feedback using Program Repai.pdf}
}

@article{pattisProceduresEarlyApproach1993,
  title = {The ``Procedures Early'' Approach in {{CS}} 1: A Heresy},
  shorttitle = {The ``Procedures Early'' Approach in {{CS}} 1},
  author = {Pattis, Richard E.},
  year = {1993},
  month = mar,
  journal = {ACM SIGCSE Bulletin},
  volume = {25},
  number = {1},
  pages = {122--126},
  issn = {0097-8418},
  doi = {10.1145/169073.169362},
  url = {https://dl.acm.org/doi/10.1145/169073.169362},
  urldate = {2022-02-24},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/PJBF6F66/Pattis - 1993 - The “procedures early” approach in CS 1 a heresy.pdf}
}

@article{patton2019app,
  title = {{{MIT}} App Inventor: {{Objectives}}, Design, and Development},
  author = {Patton, Evan W and Tissenbaum, Michael and Harunani, Farzeen},
  year = {2019},
  journal = {Computational thinking education},
  pages = {31--49},
  publisher = {{Springer Singapore}}
}

@inproceedings{pawlikMinimalEditBasedDiffs2020,
  title = {Minimal {{Edit-Based Diffs}} for {{Large Trees}}},
  booktitle = {Proceedings of the 29th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Pawlik, Mateusz and Augsten, Nikolaus},
  year = {2020},
  month = oct,
  series = {{{CIKM}} '20},
  pages = {1225--1234},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3340531.3412026},
  url = {https://doi.org/10.1145/3340531.3412026},
  urldate = {2022-07-01},
  abstract = {Hierarchically structured data are commonly represented as trees and have given rise to popular data formats like XML or JSON. An interesting query computes the difference between two versions of a tree, expressed as the minimum set of node edits (deletion, insertion, label rename) that transform one tree into another, commonly known as the tree edit distance. Unfortunately, the fastest tree edit distance algorithms run in cubic time and quadratic space and are therefore not feasible for large inputs. In this paper, we leverage the fact that the difference between two versions of a tree is typically much smaller than the overall tree size. We propose a new tree edit distance algorithm that is linear in the tree size for similar trees. Our algorithm is based on the new concept of top node pairs and avoids redundant distance computations, the main issue with previous solutions for tree diffs. We empirically evaluate the runtime of our algorithm on large synthetic and real-world trees; our algorithm clearly outperforms the state of the art, often by orders of magnitude.},
  isbn = {978-1-4503-6859-9},
  keywords = {minimal tree difference,similarity search,tree edit distance,tree-structured data},
  file = {/home/charlotte/sync/Zotero/storage/QUQPD2BZ/Pawlik and Augsten - 2020 - Minimal Edit-Based Diffs for Large Trees.pdf}
}

@article{pedregosaScikitlearnMachineLearning2011,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  shorttitle = {Scikit-Learn},
  author = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, {\'E}douard},
  year = {2011},
  journal = {Journal of Machine Learning Research},
  volume = {12},
  number = {85},
  pages = {2825--2830},
  url = {http://jmlr.org/papers/v12/pedregosa11a.html},
  urldate = {2021-04-01},
  abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language.  Emphasis is put on ease of use, performance, documentation, and API consistency.  It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings.  Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
  file = {/home/charlotte/sync/Zotero/storage/BSENXYMJ/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf}
}

@misc{peternorvigTeachYourselfProgramming2001,
  title = {Teach {{Yourself Programming}} in {{Ten Years}}},
  author = {{Peter Norvig}},
  year = {2001},
  url = {http://norvig.com/21-days.html},
  urldate = {2022-08-16},
  file = {/home/charlotte/sync/Zotero/storage/VTNWVKYG/21-days.html}
}

@inproceedings{petitJutgeOrgEducational2012,
  title = {Jutge.Org: An Educational Programming Judge},
  shorttitle = {Jutge.Org},
  booktitle = {Proceedings of the 43rd {{ACM}} Technical Symposium on {{Computer Science Education}}},
  author = {Petit, Jordi and Gim{\'e}nez, Omer and Roura, Salvador},
  year = {2012},
  month = feb,
  series = {{{SIGCSE}} '12},
  pages = {445--450},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2157136.2157267},
  url = {https://doi.org/10.1145/2157136.2157267},
  urldate = {2021-10-07},
  abstract = {Jutge.org is an open access educational online programming judge where students can try to solve more than 800 problems using 22 programming languages. The verdict of their solutions is computed using exhaustive test sets run under time, memory and security restrictions. By contrast to many popular online judges, Jutge.org is designed for students and instructors: On one hand, the problem repository is mainly aimed to beginners, with a clear organization and gradding. On the other hand, the system is designed as a virtual learning environment where instructors can administer their own courses, manage their roster of students and tutors, add problems, attach documents, create lists of problems, assignments, contests and exams. This paper presents Jutge.org and offers some case studies of courses using it.},
  isbn = {978-1-4503-1098-7},
  keywords = {active learning,CS1/2,experiences,instructional technologies,tools},
  file = {/home/charlotte/sync/Zotero/storage/XKRRSNVH/Petit et al. - 2012 - Jutge.org an educational programming judge.pdf}
}

@inproceedings{pevelerComparingJailedSandboxes2019,
  title = {Comparing {{Jailed Sandboxes}} vs {{Containers Within}} an {{Autograding System}}},
  booktitle = {Proceedings of the 50th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  author = {Peveler, Matthew and Maicus, Evan and Cutler, Barbara},
  year = {2019},
  month = feb,
  series = {{{SIGCSE}} '19},
  pages = {139--145},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3287324.3287507},
  url = {https://doi.org/10.1145/3287324.3287507},
  urldate = {2022-08-16},
  abstract = {With the continued growth of enrollment within computer science courses, it has become an increasing necessity to utilize autograding systems. These systems have historically graded assignments through either a jailed sandbox environment or within a virtual machine (VM). For a VM, each submission is given its own instantiation of a guest operating system and virtual hardware that runs atop the host system, preventing anything that runs within the VM communicating with any other VM or the host. However, using these VMs are costly in terms of system resources, making it less than ideal for running student submissions given reasonable, limited resources. Jailed sandboxes, on the other hand, run on the host itself, thus taking up minimal resources, and utilize a security model that restricts the process to specified directories on the system. However, due to running on the host machine, the approach suffers as new courses utilize autograding and bring their own set of potentially conflicting requirements for programming languages and system packages. Over the past several years, {\textbackslash}em containers have seen growing popularity in usage within the software engineering industry as well as within autograding systems. Containers provide similar benefits of isolation as a VM while maintaining similar resource cost to running within a jailed sandbox environment. We present the implementation of both a jailed sandbox and container-based autograder, compare the running time and memory usage of the two implementations, and discuss the overall resource usage.},
  isbn = {978-1-4503-5890-3},
  keywords = {autograding,containers,docker,jailed sandbox},
  file = {/home/charlotte/sync/Zotero/storage/T4U4QBDS/Peveler et al. - 2019 - Comparing Jailed Sandboxes vs Containers Within an.pdf}
}

@inproceedings{phamMiningPatternsSource2019,
  title = {Mining {{Patterns}} in {{Source Code Using Tree Mining Algorithms}}},
  booktitle = {Discovery {{Science}}},
  author = {Pham, Hoang Son and Nijssen, Siegfried and Mens, Kim and Di Nucci, Dario and Molderez, Tim and De Roover, Coen and Fabry, Johan and Zaytsev, Vadim},
  editor = {Kralj Novak, Petra and {\v S}muc, Tomislav and D{\v z}eroski, Sa{\v s}o},
  year = {2019},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {471--480},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-33778-0_35},
  abstract = {Discovering regularities in source code is of great interest to software engineers, both in academia and in industry, as regularities can provide useful information to help in a variety of tasks such as code comprehension, code refactoring, and fault localisation. However, traditional pattern mining algorithms often find too many patterns of little use and hence are not suitable for discovering useful regularities. In this paper we propose FREQTALS, a new algorithm for mining patterns in source code based on the FREQT tree mining algorithm. First, we introduce several constraints that effectively enable us to find more useful patterns; then, we show how to efficiently include them in FREQT. To illustrate the usefulness of the constraints we carried out a case study in collaboration with software engineers, where we identified a number of interesting patterns in a repository of Java code.},
  isbn = {978-3-030-33778-0},
  langid = {english},
  keywords = {Frequent tree mining,Pattern mining,Source code regularities},
  file = {/home/charlotte/sync/Zotero/storage/PBSLJNQM/Pham et al. - 2019 - Mining Patterns in Source Code Using Tree Mining A.pdf}
}

@article{pierresCouldUseAI2024,
  title = {Could {{The Use Of AI In Higher Education Hinder Students With Disabilities}}? {{A Scoping Review}}},
  shorttitle = {Could {{The Use Of AI In Higher Education Hinder Students With Disabilities}}?},
  author = {Pierr{\`e}s, Oriane and Christen, Markus and {Schmitt-Koopmann}, Felix and Darvishy, Alireza},
  year = {2024},
  journal = {IEEE Access},
  pages = {1--1},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3365368},
  url = {https://ieeexplore.ieee.org/document/10433192},
  urldate = {2024-02-15},
  abstract = {Literature reviews on artificial intelligence (AI) have focused on the different applications of AI in higher education, the AI techniques used, and the benefits/risks of the use of AI. One of the greatest potentials of AI is to personalize higher education to the needs of students and offer timely feedback. This could benefit students with disabilities tremendously if their needs are also considered in the development of new AI educational technologies (EdTech). However, current reviews have failed to address the perspective of students with disabilities, which prompts ethical concerns. For instance, AI could treat people with disabilities as outliers in the data and end up discriminating against them. For that reason, this systematic literature review raises the following two questions: To what extent are ethical concerns considered in articles presenting AI applications assessing students (with disabilities) in higher education? What are the potential risks of using AI that assess students with disabilities in higher education? This scoping review highlights the lack of ethical reflection on AI technologies and an absence of discussion and inclusion of people with disabilities. Moreover, it identifies eight risks associated with the use of AI EdTech for students with disabilities. The review concludes with suggestions on how to mitigate these potential risks. Specifically, it advocates for increased attention to ethics within the field, the involvement of people with disabilities in research and development, as well as careful adoption of AI EdTech in higher education.},
  keywords = {Artificial intelligence,Artificial Intelligence,Assistive technologies,Bibliographies,Disabilities,Education,Educational technologies (EdTech),Educational technology,Ethics,Higher Education,Privacy,Protocols,Risk Assessment,Risk management},
  file = {/home/charlotte/sync/Zotero/storage/MTCRAXRI/Pierrès et al. - 2024 - Could The Use Of AI In Higher Education Hinder Stu.pdf}
}

@article{pintrichUnderstandingSelfregulatedLearning1995,
  title = {Understanding Self-Regulated Learning},
  author = {Pintrich, Paul R.},
  year = {1995},
  journal = {New Directions for Teaching and Learning},
  volume = {1995},
  number = {63},
  pages = {3--12},
  issn = {1536-0768},
  doi = {10.1002/tl.37219956304},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/tl.37219956304},
  urldate = {2022-09-09},
  abstract = {Self-regulated learning is an important component of learning for college students. Students can learn how to become self-regulated learners, and faculty can foster self-regulated learning in their classrooms.},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/J2Y2PLWK/tl.html}
}

@article{plesserReproducibilityVsReplicability2018,
  title = {Reproducibility vs. {{Replicability}}: {{A Brief History}} of a {{Confused Terminology}}},
  shorttitle = {Reproducibility vs. {{Replicability}}},
  author = {Plesser, Hans E.},
  year = {2018},
  month = jan,
  journal = {Frontiers in Neuroinformatics},
  volume = {11},
  pages = {76},
  issn = {1662-5196},
  doi = {10.3389/fninf.2017.00076},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5778115/},
  urldate = {2022-06-14},
  pmcid = {PMC5778115},
  pmid = {29403370},
  file = {/home/charlotte/sync/Zotero/storage/BN6DSKBP/Plesser - 2018 - Reproducibility vs. Replicability A Brief History.pdf}
}

@article{pophamWhatWrongWhat1997,
  title = {What's {{Wrong--and What}}'s {{Right--with Rubrics}}},
  author = {Popham, W. James},
  year = {1997},
  journal = {Educational Leadership},
  volume = {55},
  number = {2},
  pages = {72--75},
  issn = {0013-1784},
  urldate = {2022-08-16},
  abstract = {The term "rubric" refers to a scoring guide used to evaluate the quality of students' constructed responses (written compositions, oral presentations, or science projects). Although educators rave about rubrics, the vast majority are instructionally fraudulent. Problems arise when rubrics are too task-specific or general or lengthy and confuse the skill tested with the test itself. (MLH)},
  langid = {english},
  keywords = {Definitions,Elementary Secondary Education,Evaluation Criteria,Grading,Guidelines,Holistic Approach,Misconceptions,Scoring Rubrics,Student Evaluation},
  file = {/home/charlotte/sync/Zotero/storage/BK7JK52D/eric.ed.gov.html}
}

@article{princeDoesActiveLearning2004,
  title = {Does {{Active Learning Work}}? {{A Review}} of the {{Research}}},
  shorttitle = {Does {{Active Learning Work}}?},
  author = {Prince, Michael},
  year = {2004},
  journal = {Journal of Engineering Education},
  volume = {93},
  number = {3},
  pages = {223--231},
  issn = {2168-9830},
  doi = {10.1002/j.2168-9830.2004.tb00809.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/j.2168-9830.2004.tb00809.x},
  urldate = {2021-08-26},
  abstract = {This study examines the evidence for the effectiveness of active learning. It defines the common forms of active learning most relevant for engineering faculty and critically examines the core element of each method. It is found that there is broad but uneven support for the core elements of active, collaborative, cooperative and problem-based learning.},
  langid = {english},
  keywords = {active,collaborative,cooperative,problem-based learning},
  file = {/home/charlotte/sync/Zotero/storage/XU3JRRU4/Prince - 2004 - Does Active Learning Work A Review of the Researc.pdf;/home/charlotte/sync/Zotero/storage/FVRMLRB5/j.2168-9830.2004.tb00809.html}
}

@article{prvanMethodsTeachingComputer2020,
  title = {Methods in {{Teaching Computer Networks}}: {{A Literature Review}}},
  shorttitle = {Methods in {{Teaching Computer Networks}}},
  author = {Prvan, Marina and O{\v z}EGOVI{\'c}, Julije},
  year = {2020},
  month = jun,
  journal = {ACM Transactions on Computing Education},
  volume = {20},
  number = {3},
  pages = {19:1--19:35},
  doi = {10.1145/3394963},
  url = {https://doi.org/10.1145/3394963},
  urldate = {2021-09-30},
  abstract = {This article provides a survey of methods and paradigms for teaching Computer Networks (CN). Since the theoretical concepts are rather abstract in this subject, and students often find them too technical and difficult to understand, many authors attempt to answer the question on how to improve students' motivation and interest for the complex teaching material of CN. In this work, we follow a rigorous paper collection methodology and extract a large number of previous studies that relate to the stated research questions. Also, we find that there is no review article in the current literature that would provide a clear systematization or a guided study on this topic. Hence, this work provides a literature overview by binding all the previously used methods for teaching CN in one place, and brings contribution by classifying the existing approaches into four basic classes: methods based on using visualization objects such as network simulators, multimedia applications, packet-tracing tools or visual analogies; methods based on using the virtualization techniques; methods precipitating active learning paradigm and methods based on the practical hands-on laboratory exercises. Moreover, the research in this article goes beyond the proposed classification. The classes of methods and tools are compared and contrasted based on the findings from the literature. Methods are evaluated by a detailed cross-comparison based on their advantages, disadvantages and challenges in the perspective of both teachers and students. The review is additionally strengthened by comparing the educational effectiveness of the classified methods. We examine, classify, and contrast the usual approaches used in teaching CN, provide useful insights on how appropriate they are in achieving specific educational goals and determine the future research directions.},
  keywords = {Computer networks,literature survey,network simulators,teaching methods},
  file = {/home/charlotte/sync/Zotero/storage/GTAZHIMV/Prvan and OžEGOVIć - 2020 - Methods in Teaching Computer Networks A Literatur.pdf}
}

@article{raesWebbasedCollaborativeInquiry2014,
  title = {Web-Based {{Collaborative Inquiry}} to {{Bridge Gaps}} in {{Secondary Science Education}}},
  author = {Raes, Annelies and Schellens, Tammy and De Wever, Bram},
  year = {2014},
  month = jul,
  journal = {Journal of the Learning Sciences},
  volume = {23},
  number = {3},
  pages = {316--347},
  publisher = {{Routledge}},
  issn = {1050-8406},
  doi = {10.1080/10508406.2013.836656},
  url = {https://doi.org/10.1080/10508406.2013.836656},
  urldate = {2021-09-15},
  abstract = {As secondary students' interest in science is decreasing, schools are faced with the challenging task of providing adequate instruction to engage students---and more particularly the disadvantaged students---to learn science and improve their science inquiry skills. In this respect, the integration of Web-based collaborative inquiry can be seen as a possible answer. However, the differential effects of Web-based inquiry on disadvantaged students have barely been studied. To bridge this gap, this study deals with the implementation of a Web-based inquiry project in 19 secondary classes and focuses specifically on gender, achievement level, and academic track. Multilevel analysis was applied to uncover the effects on knowledge acquisition, inquiry skills, and interest in science. The study provides quantitative evidence not only that a Web-based collaborative inquiry project is an effective approach for science learning, but that this approach can also offer advantages for students who are not typically successful in science or who are not enrolled in a science track. This approach can contribute to narrowing the gap between boys and girls in science and can give low-achieving students and general-track students an opportunity to develop confidence and skills for learning science, bringing them to a performance level that is closer to that of high-achieving students.},
  file = {/home/charlotte/sync/Zotero/storage/5A6P3CLX/Raes et al. - 2014 - Web-based Collaborative Inquiry to Bridge Gaps in .pdf;/home/charlotte/sync/Zotero/storage/ECGB3N97/10508406.2013.html}
}

@article{rameshPredictingStudentPerformance2013,
  title = {Predicting {{Student Performance}}: {{A Statistical}} and {{Data Mining Approach}}},
  shorttitle = {Predicting {{Student Performance}}},
  author = {RAMESH, {\relax VAMANAN} and {P.PARKAVI} and Ramar, K.},
  year = {2013},
  month = feb,
  journal = {INTERNATIONAL JOURNAL OF COMPUTER APPLICATIONS},
  volume = {63},
  pages = {975--8887},
  abstract = {Predicting the performance of a student is a great concern to the higher education managements. The scope of this paper is to identify the factors influencing the performance of students in final examinations and find out a suitable data mining algorithm to predict the grade of students so as to a give timely and an appropriate warning to students those who are at risk. In the present investigation, a survey cum experimental methodology was adopted to generate a database and it was constructed from a primary and a secondary source. The obtained results from hypothesis testing reveals that type of school is not influence student performance and parents' occupation plays a major role in predicting grades. This work will help the educational institutions to identify the students who are at risk and to and provide better additional training for the weak students.}
}

@inproceedings{reekTRYSystemHow1989,
  title = {The {{TRY}} System -or- How to Avoid Testing Student Programs},
  booktitle = {Proceedings of the Twentieth {{SIGCSE}} Technical Symposium on {{Computer}} Science Education},
  author = {Reek, Kenneth A.},
  year = {1989},
  month = feb,
  series = {{{SIGCSE}} '89},
  pages = {112--116},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/65293.71198},
  url = {https://dl.acm.org/doi/10.1145/65293.71198},
  urldate = {2024-02-07},
  abstract = {This paper discusses TRY, a software package for the UNIX1 operating system that tests student programs. The motivation for developing the system is established by describing problems associated with traditional grading methods and electronic program submission. The design and use of the TRY system is discussed, along with the advantages it provides to both the student and the instructor.},
  isbn = {978-0-89791-298-3},
  file = {/home/charlotte/sync/Zotero/storage/U3PGR5DM/Reek - 1989 - The TRY system -or- how to avoid testing student p.pdf;/home/charlotte/sync/Zotero/storage/UU7NTE7B/reek1989.pdf.pdf}
}

@inproceedings{renzellaEnrichingProgrammingStudent2020,
  title = {Enriching Programming Student Feedback with Audio Comments},
  booktitle = {Proceedings of the {{ACM}}/{{IEEE}} 42nd {{International Conference}} on {{Software Engineering}}: {{Software Engineering Education}} and {{Training}}},
  author = {Renzella, Jake and Cain, Andrew},
  year = {2020},
  month = sep,
  series = {{{ICSE-SEET}} '20},
  pages = {173--183},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3377814.3381712},
  url = {https://dl.acm.org/doi/10.1145/3377814.3381712},
  urldate = {2024-01-10},
  abstract = {Introductory programming is challenging for many students, requiring them to engage with a deep approach to learning concepts in order to succeed. These challenges compound for online students who do not have direct face-to-face interactions with teaching staff. With the growing demand for online education, we need to examine approaches that assist in building supportive learning environments for these students. A growing body of work from other education disciplines indicates that audio feedback provides an opportunity for developing stronger relationships with students. Further studies recommend an integrated implementation of audio recording into the virtual learning environment. To evaluate audio feedback for use in programming education, we developed an integrated, cross-browser audio feedback feature into the open-source Doubtfire learning management system. Doubtfire is used to support and scale a task-oriented teaching and learning system built upon the principles of constructive alignment and has been shown to help students engage with programming concepts in campus-only units. Our findings from experimental and observational activities indicate that programming tutors can use a blended approach of audio and text feedback via the learning management system to better support student learning. The blended approach provides more nuanced feedback, conveying personality and feelings of connectedness to students, while retaining the benefits of specificity for code-specific issues.},
  isbn = {978-1-4503-7124-7},
  keywords = {audio feedback,formative feedback,introductory programming,learning management system,online students},
  file = {/home/charlotte/sync/Zotero/storage/DLNJ94WY/Renzella and Cain - 2020 - Enriching programming student feedback with audio .pdf;/home/charlotte/sync/Zotero/storage/VAEJXWPZ/renzella2020.pdf.pdf}
}

@article{riversDataDrivenHintGeneration2017,
  title = {Data-{{Driven Hint Generation}} in {{Vast Solution Spaces}}: A {{Self-Improving Python Programming Tutor}}},
  shorttitle = {Data-{{Driven Hint Generation}} in {{Vast Solution Spaces}}},
  author = {Rivers, Kelly and Koedinger, Kenneth R.},
  year = {2017},
  month = mar,
  journal = {International Journal of Artificial Intelligence in Education},
  volume = {27},
  number = {1},
  pages = {37--64},
  issn = {1560-4306},
  doi = {10.1007/s40593-015-0070-z},
  url = {https://doi.org/10.1007/s40593-015-0070-z},
  urldate = {2022-08-03},
  abstract = {To provide personalized help to students who are working on code-writing problems, we introduce a data-driven tutoring system, ITAP (Intelligent Teaching Assistant for Programming). ITAP uses state abstraction, path construction, and state reification to automatically generate personalized hints for students, even when given states that have not occurred in the data before. We provide a detailed description of the system's implementation and perform a technical evaluation on a small set of data to determine the effectiveness of the component algorithms and ITAP's potential for self-improvement. The results show that ITAP is capable of producing hints for almost any given state after being given only a single reference solution, and that it can improve its performance by collecting data over time.},
  langid = {english},
  keywords = {Automatic hint generation,Data-driven tutoring,Programming tutors,Solution space},
  file = {/home/charlotte/sync/Zotero/storage/CY5SEWI3/Rivers and Koedinger - 2017 - Data-Driven Hint Generation in Vast Solution Space.pdf}
}

@article{robinsLearningTeachingProgramming2003,
  title = {Learning and {{Teaching Programming}}: {{A Review}} and {{Discussion}}},
  shorttitle = {Learning and {{Teaching Programming}}},
  author = {Robins, Anthony and Rountree, Janet and Rountree, Nathan},
  year = {2003},
  month = jun,
  journal = {Computer Science Education},
  volume = {13},
  number = {2},
  pages = {137--172},
  publisher = {{Routledge}},
  issn = {0899-3408},
  doi = {10.1076/csed.13.2.137.14200},
  url = {https://doi.org/10.1076/csed.13.2.137.14200},
  urldate = {2022-02-24},
  abstract = {In this paper we review the literature relating to the psychological/educational study of programming. We identify general trends comparing novice and expert programmers, programming knowledge and strategies, program generation and comprehension, and object-oriented versus procedural programming. (We do not cover research relating specifically to other programming styles.) The main focus of the review is on novice programming and topics relating to novice teaching and learning. Various problems experienced by novices are identified, including issues relating to basic program design, to algorithmic complexity in certain language features, to the ``fragility'' of novice knowledge, and so on. We summarise this material and suggest some practical implications for teachers. We suggest that a key issue that emerges is the distinction between effective and ineffective novices. What characterises effective novices? Is it possible to identify the specific deficits of ineffective novices and help them to become effective learners of programming?},
  file = {/home/charlotte/sync/Zotero/storage/VIAWJTPE/Robins et al. - 2003 - Learning and Teaching Programming A Review and Di.pdf;/home/charlotte/sync/Zotero/storage/WJFWFIHW/csed.13.2.137.html}
}

@inproceedings{rogersACCEAutomaticCoding2014,
  title = {{{ACCE}}: Automatic Coding Composition Evaluator},
  shorttitle = {{{ACCE}}},
  booktitle = {Proceedings of the First {{ACM}} Conference on {{Learning}} @ Scale Conference},
  author = {Rogers, Stephanie and Tang, Steven and Canny, John},
  year = {2014},
  month = mar,
  series = {L@{{S}} '14},
  pages = {191--192},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2556325.2567876},
  url = {https://doi.org/10.1145/2556325.2567876},
  urldate = {2022-08-16},
  abstract = {Coding style is important to teach to beginning programmers, so that bad habits don't become permanent. This is often done manually at the University level because automated Python static analyzers cannot accurately grade based on a given rubric. However, even manual analysis of coding style encounters problems, as we have seen quite a bit of inconsistency among our graders. We introduce ACCE--Automated Coding Composition Evaluator--a module that automates grading for the composition of programs. ACCE, given certain constraints, assesses the composition of a program through static analysis, conversion from code to AST, and clustering (unsupervised learning), helping automate the subjective process of grading based on style and identifying common mistakes. Further, we create visual representations of the clusters to allow readers and students understand where a submission falls, and the overall trends. We have applied this tool to CS61A--a CS1 level course at UC, Berkeley experiencing rapid growth in student enrollment--in an attempt to help expedite the involved process as well as reduce human grader inconsistencies.},
  isbn = {978-1-4503-2669-8},
  keywords = {assessment,autograding,clustering,composition,cs1,evaluation,gephi,grading,style,unsupervised learning,visualization},
  file = {/home/charlotte/sync/Zotero/storage/ZRN5QMRC/Rogers et al. - 2014 - ACCE automatic coding composition evaluator.pdf}
}

@article{romeroDataMiningCourse2008,
  title = {Data Mining in Course Management Systems: {{Moodle}} Case Study and Tutorial},
  shorttitle = {Data Mining in Course Management Systems},
  author = {Romero, Crist{\'o}bal and Ventura, Sebasti{\'a}n and Garc{\'i}a, Enrique},
  year = {2008},
  month = aug,
  journal = {Computers \& Education},
  volume = {51},
  number = {1},
  pages = {368--384},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2007.05.016},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131507000590},
  urldate = {2024-02-13},
  abstract = {Educational data mining is an emerging discipline, concerned with developing methods for exploring the unique types of data that come from the educational context. This work is a survey of the specific application of data mining in learning management systems and a case study tutorial with the Moodle system. Our objective is to introduce it both theoretically and practically to all users interested in this new research area, and in particular to online instructors and e-learning administrators. We describe the full process for mining e-learning data step by step as well as how to apply the main data mining techniques used, such as statistics, visualization, classification, clustering and association rule mining of Moodle data. We have used free data mining tools so that any user can immediately begin to apply data mining without having to purchase a commercial tool or program a specific personalized tool.},
  keywords = {Data mining,Distance education and telelearning,E-learning,Evaluation of CAL systems,Web mining},
  file = {/home/charlotte/sync/Zotero/storage/6RIZ3VUP/romero2008.pdf.pdf;/home/charlotte/sync/Zotero/storage/BVU6QZKD/S0360131507000590.html}
}

@article{romeroEducationalDataMining2010,
  title = {Educational {{Data Mining}}: {{A Review}} of the {{State}} of the {{Art}}},
  shorttitle = {Educational {{Data Mining}}},
  author = {Romero, Crist{\'o}bal and Ventura, Sebasti{\'a}n},
  year = {2010},
  month = nov,
  journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume = {40},
  number = {6},
  pages = {601--618},
  issn = {1558-2442},
  doi = {10.1109/TSMCC.2010.2053532},
  abstract = {Educational data mining (EDM) is an emerging interdisciplinary research area that deals with the development of methods to explore data originating in an educational context. EDM uses computational approaches to analyze educational data in order to study educational questions. This paper surveys the most relevant studies carried out in this field to date. First, it introduces EDM and describes the different groups of user, types of educational environments, and the data they provide. It then goes on to list the most typical/common tasks in the educational environment that have been resolved through data-mining techniques, and finally, some of the most promising future lines of research are discussed.},
  keywords = {Data analysis,Data mining,Data mining (DM),Databases,Delta modulation,educational data mining (EDM),educational systems,Electronic learning,Gold,Instruments,Internet,knowledge discovery,Least squares approximation,Psychometric testing},
  file = {/home/charlotte/sync/Zotero/storage/J5JNI6J8/Romero and Ventura - 2010 - Educational Data Mining A Review of the State of .pdf;/home/charlotte/sync/Zotero/storage/H7MJHSEM/5524021.html}
}

@article{rosslingEnhancingLearningManagement2008,
  title = {Enhancing Learning Management Systems to Better Support Computer Science Education},
  author = {R{\"o}{\ss}ling, Guido and Joy, Mike and Moreno, Andr{\'e}s and Radenski, Atanas and Malmi, Lauri and Kerren, Andreas and Naps, Thomas and Ross, Rockford J. and Clancy, Michael and Korhonen, Ari and Oechsle, Rainer and Iturbide, J. {\'A}ngel Vel{\'a}zquez},
  year = {2008},
  month = nov,
  journal = {ACM SIGCSE Bulletin},
  volume = {40},
  number = {4},
  pages = {142--166},
  issn = {0097-8418},
  doi = {10.1145/1473195.1473239},
  url = {https://doi.org/10.1145/1473195.1473239},
  urldate = {2022-08-16},
  abstract = {Many individual instructors -- and, in some cases, entire universities -- are gravitating towards the use of comprehensive learning management systems (LMSs), such as Blackboard and Moodle, for managing courses and enhancing student learning. As useful as LMSs are, they are short on features that meet certain needs specific to computer science education. On the other hand, computer science educators have developed--and continue to develop-computer-based software tools that aid in management, teaching, and/or learning in computer science courses. In this report we provide an overview of current CS specific on-line learning resources and guidance on how one might best go about extending an LMS to include such tools and resources. We refer to an LMS that is extended specifically for computer science education as a Computing Augmented Learning Management System, or CALMS. We also discuss sound pedagogical practices and some practical and technical principles for building a CALMS. However, we do not go into details of creating a plug-in for some specific LMS. Further, the report does not favor one LMS over another as the foundation for a CALMS.},
  keywords = {CALMS,computer science education,computing augmented learning management system,learning management system,LMS},
  file = {/home/charlotte/sync/Zotero/storage/X9CD4XXV/Rößling et al. - 2008 - Enhancing learning management systems to better su.pdf}
}

@inproceedings{rountreeInteractingFactorsThat2004,
  title = {Interacting Factors That Predict Success and Failure in a {{CS1}} Course},
  booktitle = {Working Group Reports from {{ITiCSE}} on {{Innovation}} and Technology in Computer Science Education},
  author = {Rountree, Nathan and Rountree, Janet and Robins, Anthony and Hannah, Robert},
  year = {2004},
  month = jun,
  series = {{{ITiCSE-WGR}} '04},
  pages = {101--104},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1044550.1041669},
  url = {https://doi.org/10.1145/1044550.1041669},
  urldate = {2021-02-19},
  abstract = {The factors that contribute to success and failure in introductory programming courses continue to be a topic of lively debate, with recent conference panels and papers devoted to the subject (e.g. Rountree et al. 2004, Ventura et al., 2004, Gal-Ezer et al., 2003). Most work in this area has concentrated on the ability of single factors (e.g. gender, math background, etc.) to predict success, with the exception of Wilson et al. (2001), which used a general linear model to gauge the effect of combined factors. In Rountree et al. (2002) we presented the results of a survey of our introductory programming class that considered factors (such as student expectations of success, among other things) in isolation. In this paper, we reassess the data from that survey by using a decision tree classifier to identify combinations of factors that interact to predict success or failure more strongly than single, isolated factors.},
  isbn = {978-1-4503-7794-2},
  keywords = {CS1,decision tree,modelling,predictors of success,student background},
  file = {/home/charlotte/sync/Zotero/storage/AMVV4A5W/Rountree et al. - 2004 - Interacting factors that predict success and failu.pdf}
}

@article{sakimuraOpenidConnectCore2014,
  title = {Openid Connect Core 1.0},
  author = {Sakimura, Natsuhiko and Bradley, John and Jones, Mike and De Medeiros, Breno and Mortimore, Chuck},
  year = {2014},
  journal = {The OpenID Foundation},
  pages = {S3}
}

@article{salazarparedesComparingPythonPrograms2020,
  title = {Comparing Python Programs Using Abstract Syntax Trees},
  author = {Salazar Paredes, Pedro},
  year = {2020},
  journal = {instname:Universidad de los Andes},
  publisher = {{Universidad de los Andes}},
  url = {https://repositorio.uniandes.edu.co/handle/1992/44754},
  urldate = {2022-07-06},
  abstract = {"Determinar si dos programas son similares no es una tarea simple. En este trabajo exploramos e implementamos un acercamiento hacia determinar qu{\'e} tan similares son dos programas de Python usando arboles sint{\'a}cticos abstractos similar al trabajo realizado por Avery et al. [1]. Luego se us{\'o} esta implementaci{\'o}n para analizar los programas previamente recopilados y clasificados por la herramienta Senecode con la intenci{\'o}n de poder dar retroalimentaci{\'o}n autom{\'a}tica significativa." -- Tomado del Formato de Documento de Grado.},
  copyright = {Al consultar y hacer uso de este recurso, est{\'a} aceptando las condiciones de uso establecidas por los autores.},
  langid = {english},
  annotation = {Accepted: 2020-09-03T15:00:44Z},
  file = {/home/charlotte/sync/Zotero/storage/P99CDWYX/Salazar Paredes - 2020 - Comparing python programs using abstract syntax tr.pdf;/home/charlotte/sync/Zotero/storage/LH37DR2A/44754.html}
}

@inproceedings{scatalonSoftwareTestingIntroductory2019,
  title = {Software {{Testing}} in {{Introductory Programming Courses}}: {{A Systematic Mapping Study}}},
  shorttitle = {Software {{Testing}} in {{Introductory Programming Courses}}},
  booktitle = {Proceedings of the 50th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  author = {Scatalon, Lilian Passos and Carver, Jeffrey C. and Garcia, Rog{\'e}rio Eduardo and Barbosa, Ellen Francine},
  year = {2019},
  month = feb,
  series = {{{SIGCSE}} '19},
  pages = {421--427},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3287324.3287384},
  url = {https://doi.org/10.1145/3287324.3287384},
  urldate = {2022-03-03},
  abstract = {Traditionally, students learn about software testing during intermediate or advanced computing courses. However, it is widely advocated that testing should be addressed beginning in introductory programming courses. In this context, testing practices can help students think more critically while working on programming assignments. At the same time, students can develop testing skills throughout the computing curriculum. Considering this scenario, we conducted a systematic mapping of the literature about software testing in introductory programming courses, resulting in 293 selected papers. We mapped the papers to categories with respect to their investigated topic (curriculum, teaching methods, programming assignments, programming process, tools, program/test quality, concept understanding, and students' perceptions and behaviors) and evaluation method (literature review, exploratory study, descriptive/persuasive study, survey, qualitative study, experimental and experience report). We also identified the benefits and drawbacks of this teaching approach, as pointed out in the selected papers. The goal is to provide an overview of research performed in the area, highlighting gaps that should be further investigated.},
  isbn = {978-1-4503-5890-3},
  keywords = {introductory programming courses,software testing,systematic mapping},
  file = {/home/charlotte/sync/Zotero/storage/YVQ7WW4I/Scatalon et al. - 2019 - Software Testing in Introductory Programming Cours.pdf}
}

@inproceedings{schleimerWinnowingLocalAlgorithms2003,
  title = {Winnowing: Local Algorithms for Document Fingerprinting},
  shorttitle = {Winnowing},
  booktitle = {Proceedings of the 2003 {{ACM SIGMOD}} International Conference on {{Management}} of Data},
  author = {Schleimer, Saul and Wilkerson, Daniel S. and Aiken, Alex},
  year = {2003},
  month = jun,
  series = {{{SIGMOD}} '03},
  pages = {76--85},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/872757.872770},
  url = {https://doi.org/10.1145/872757.872770},
  urldate = {2022-08-16},
  abstract = {Digital content is for copying: quotation, revision, plagiarism, and file sharing all create copies. Document fingerprinting is concerned with accurately identifying copying, including small partial copies, within large sets of documents.We introduce the class of local document fingerprinting algorithms, which seems to capture an essential property of any finger-printing technique guaranteed to detect copies. We prove a novel lower bound on the performance of any local algorithm. We also develop winnowing, an efficient local fingerprinting algorithm, and show that winnowing's performance is within 33\% of the lower bound. Finally, we also give experimental results on Web data, and report experience with MOSS, a widely-used plagiarism detection service.},
  isbn = {978-1-58113-634-0},
  file = {/home/charlotte/sync/Zotero/storage/ZUX3DU4P/Schleimer et al. - 2003 - Winnowing local algorithms for document fingerpri.pdf}
}

@inproceedings{schneiderIntroductoryProgrammingCourse1978,
  title = {The Introductory Programming Course in Computer Science: Ten Principles},
  booktitle = {Papers of the {{SIGCSE}}/{{CSA}} Technical Symposium on {{Computer}} Science Education},
  author = {Schneider, G Michael},
  year = {1978},
  pages = {107--114},
  file = {/home/charlotte/sync/Zotero/storage/XNH98V4D/Schneider - 1978 - The introductory programming course in computer sc.pdf}
}

@article{schulteThinkingObjectsTheir2003,
  title = {Thinking in {{Objects}} and Their {{Collaboration}}: {{Introducing Object-Oriented Technology}}},
  shorttitle = {Thinking in {{Objects}} and Their {{Collaboration}}},
  author = {Schulte, Carsten and Magenheim, Johannes and Niere, J{\"o}rg and Sch{\"a}fer, Wilhelm},
  year = {2003},
  month = dec,
  journal = {Computer Science Education},
  volume = {13},
  number = {4},
  pages = {269--288},
  publisher = {{Routledge}},
  issn = {0899-3408},
  doi = {10.1076/csed.13.4.269.17492},
  url = {https://doi.org/10.1076/csed.13.4.269.17492},
  urldate = {2022-02-24},
  abstract = {Although many professionals in education believe that an `objects first' approach is the best method of introducing object-oriented technology, there is no common agreement on how to start such courses. Current study programs often begin by teaching a chosen object-oriented programing language, where students are confronted by a large amount of syntactical detail. Instead of focusing on the basics of object-oriented technology, namely objects and their collaborations, difficulties in handling the details of the programing language lead to a very scattered knowledge of object-oriented concepts. This is dangerous, as learners are left with a set of unconnected knowledge fragments. Approaches which embed different knowledge fragments in an overall knowledge view are known as ``cognitive apprenticeship'' approaches. The main idea of cognitive apprenticeship is continuous practice. We present a learning environment for introducing object-oriented technology in upper secondary schools based on cognitive apprenticeship. We use a visual programing language to away from the details and provide tool support to aid practice. We present the learning sequencewhich is used and show the impacts it makes on the course structure in our experiment in the chosen object-oriented programming language The Joint Task Force on Computing Curricula IEEE Computer Society.},
  file = {/home/charlotte/sync/Zotero/storage/SJNFC4UR/csed.13.4.269.html}
}

@book{schunkSelfregulationLearningPerformance1994,
  title = {Self-Regulation of Learning and Performance: {{Issues}} and Educational Applications.},
  author = {Schunk, Dale H and Zimmerman, Barry J},
  year = {1994},
  publisher = {{Lawrence Erlbaum Associates, Inc}}
}

@mastersthesis{selsTESTedProgrammeertaalonafhankelijkTesten2021,
  title = {{TESTed: programmeertaal-onafhankelijk testen van oplossingen voor programmeeroefeningen: Eenvoudig oefeningen opstellen met een DSL}},
  author = {Sels, Boris and Dawyndt, Peter and Mesuere, Bart and Strijbol, Niko and Van Petegem, Charlotte},
  year = {2021},
  url = {http://lib.ugent.be/catalog/rug01:003008250},
  langid = {und},
  school = {Ghent University},
  file = {/home/charlotte/sync/Zotero/storage/34VD6QYR/Sels et al. - 2021 - TESTed programmeertaal-onafhankelijk testen van o.pdf}
}

@phdthesis{shah2003web,
  title = {Web-Cat: {{A}} Web-Based Center for Automated Testing},
  author = {Shah, Anuj Ramesh},
  year = {2003},
  school = {Virginia Tech},
  file = {/home/charlotte/sync/Zotero/storage/QM974S89/Shah - 2003 - Web-cat A web-based center for automated testing.pdf}
}

@article{shanaIdentifyingKeyPerformance2011,
  title = {Identifying Key Performance Indicators and Predicting the Result from Student Data},
  author = {Shana, J. and Venkatachalam, T.},
  year = {2011},
  journal = {International Journal of Computer Applications},
  volume = {25},
  number = {9},
  pages = {45--48},
  publisher = {{Citeseer}},
  file = {/home/charlotte/sync/Zotero/storage/9JUYK7I5/Shana and Venkatachalam - 2011 - Identifying key performance indicators and predict.pdf}
}

@article{smartStudentsPerceptionsOnline2006,
  title = {Students' {{Perceptions}} of {{Online Learning}}: {{A Comparative Study}}},
  shorttitle = {Students' {{Perceptions}} of {{Online Learning}}},
  author = {Smart, Karl L. and Cappel, James J.},
  year = {2006},
  month = jan,
  journal = {Journal of Information Technology Education: Research},
  volume = {5},
  number = {1},
  pages = {201--219},
  publisher = {{Informing Science Institute}},
  issn = {1539-3585},
  url = {https://www.learntechlib.org/p/111541/},
  urldate = {2021-04-30},
  abstract = {In search of better, more cost effective ways to deliver instruction and training, universities and corporations have expanded their use of e-learning. Although several studies suggest that online education and blended instruction (a ``blend'' of online and traditional approaches) can be as effective as traditional classroom models, few studies have focused on learner satisfaction with online instruction, particularly in the transition to online learning from traditional approaches. This study examines students' perceptions of integrating online components in two undergraduate business...},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/BGEJXIYU/Smart and Cappel - 2006 - Students’ Perceptions of Online Learning A Compar.pdf}
}

@incollection{soaresCodeflexExperienceCompetitive2023,
  title = {Codeflex 2.0: {{Experience With Competitive Programming}} in {{Logical}} and {{Functional Paradigms}}},
  shorttitle = {Codeflex 2.0},
  booktitle = {Internet of {{Behaviors Implementation}} in {{Organizational Contexts}}},
  author = {Soares, Jos{\'e} M. and Brito, Miguel and Gon{\c c}alves, Celestino},
  year = {2023},
  pages = {40--67},
  publisher = {{IGI Global}},
  doi = {10.4018/978-1-6684-9039-6.ch003},
  url = {https://www.igi-global.com/chapter/codeflex-20/www.igi-global.com/chapter/codeflex-20/333551},
  urldate = {2023-12-01},
  abstract = {This work presents the design and implementation of Codeflex, a web-based platform and repository of programming problems, that enables the learning and practice of competitive programming in multiple programming language paradigms. The Codeflex programming platform performs automatic evaluation of...},
  copyright = {Access limited to members},
  isbn = {978-1-66849-039-6},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/NFTCCUDI/Soares et al. - 2023 - Codeflex 2.0 Experience With Competitive Programm.pdf}
}

@inproceedings{sorourStudentPerformanceEstimation2015,
  title = {Student {{Performance Estimation Based}} on {{Topic Models Considering}} a {{Range}} of {{Lessons}}},
  booktitle = {Artificial {{Intelligence}} in {{Education}}},
  author = {Sorour, Shaymaa E. and Goda, Kazumasa and Mine, Tsunenori},
  editor = {Conati, Cristina and Heffernan, Neil and Mitrovic, Antonija and Verdejo, M. Felisa},
  year = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {790--793},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-19773-9_117},
  abstract = {This paper proposes a prediction framework for student performance based on comment data mining. Given the comments containing multiple topics, we seek to discover the topics that help to predict final student grades as their performance. To this end, the paper proposes methods that analyze students' comments by two topic models: Probabilistic Latent Semantic Analysis (PLSA), and Latent Dirichlet Allocation (LDA). The methods employ Support Vector Machine (SVM) to generate prediction models of final student grades. In addition, Considering the student grades predicted in a range of lessons can deal with prediction error occurred in each lesson, and achieve further improvement of the student grade prediction.},
  isbn = {978-3-319-19773-9},
  langid = {english},
  keywords = {Comments data mining,Prediction model,Topic models},
  file = {/home/charlotte/sync/Zotero/storage/XZM8562Y/Sorour et al. - 2015 - Student Performance Estimation Based on Topic Mode.pdf}
}

@inproceedings{staubitzPracticalProgrammingExercises2015,
  title = {Towards Practical Programming Exercises and Automated Assessment in {{Massive Open Online Courses}}},
  booktitle = {2015 {{IEEE International Conference}} on {{Teaching}}, {{Assessment}}, and {{Learning}} for {{Engineering}} ({{TALE}})},
  author = {Staubitz, Thomas and Klement, Hauke and Renz, Jan and Teusner, Ralf and Meinel, Christoph},
  year = {2015},
  month = dec,
  pages = {23--30},
  doi = {10.1109/TALE.2015.7386010},
  abstract = {In recent years, Massive Open Online Courses (MOOCs) have become a phenomenon presenting the prospect of free high class education to everybody. They bear a tremendous potential for teaching programming to a large and diverse audience. The typical MOOC components, such as video lectures, reading material, and easily assessable quizzes, however, are not sufficient for proper programming education. To learn programming, participants need an option to work on practical programming exercises and to solve actual programming tasks. It is crucial that the participants receive proper feedback on their work in a timely manner. Without a tool for automated assessment of programming assignments, the teaching teams would be restricted to offer optional ungraded exercises only. The paper at hand sketches scenarios how practical programming exercises could be provided and examines the landscape of potentially helpful tools in this context. Automated assessment has a long record in the history of computer science education. We give an overview of existing tools in this field and also explore the question what can and/or should be assessed.},
  keywords = {Assessment,Automated Assessment,Browsers,Context,Education,Games,Massive Open Online Courses,MOOC,Programming,Programming profession,Servers},
  file = {/home/charlotte/sync/Zotero/storage/KK5RJQAY/Staubitz et al. - 2015 - Towards practical programming exercises and automa.pdf;/home/charlotte/sync/Zotero/storage/IUKCITP7/7386010.html}
}

@techreport{stenersonInternetCalendaringScheduling1998,
  type = {Request for {{Comments}}},
  title = {Internet {{Calendaring}} and {{Scheduling Core Object Specification}} ({{iCalendar}})},
  author = {Stenerson, Derik and Dawson, Frank},
  year = {1998},
  month = nov,
  number = {RFC 2445},
  institution = {{Internet Engineering Task Force}},
  doi = {10.17487/RFC2445},
  url = {https://datatracker.ietf.org/doc/rfc2445},
  urldate = {2022-08-16},
  abstract = {This memo has been defined to provide the definition of a common format for openly exchanging calendaring and scheduling information across the Internet. [STANDARDS-TRACK]},
  file = {/home/charlotte/sync/Zotero/storage/FUXY8PH9/Stenerson and Dawson - 1998 - Internet Calendaring and Scheduling Core Object Sp.pdf}
}

@article{stevensQueryingDistilledCode2019,
  title = {Querying Distilled Code Changes to Extract Executable Transformations},
  author = {Stevens, Reinout and Molderez, Tim and De Roover, Coen},
  year = {2019},
  month = feb,
  journal = {Empirical Software Engineering},
  volume = {24},
  number = {1},
  pages = {491--535},
  issn = {1573-7616},
  doi = {10.1007/s10664-018-9644-3},
  url = {https://doi.org/10.1007/s10664-018-9644-3},
  urldate = {2022-07-06},
  abstract = {Change distilling algorithms compute a sequence of fine-grained changes that, when executed in order, transform a given source AST into a given target AST. The resulting change sequences are used in the field of mining software repositories to study source code evolution. Unfortunately, detecting and specifying source code evolutions in such a change sequence is cumbersome. We therefore introduce a tool-supported approach that identifies minimal executable subsequences in a sequence of distilled changes that implement a particular evolution pattern, specified in terms of intermediate states of the AST that undergoes each change. This enables users to describe the effect of multiple changes, irrespective of their execution order, while ensuring that different change sequences that implement the same code evolution are recalled. Correspondingly, our evaluation is two-fold. We show that our approach is able to recall different implementation variants of the same source code evolution in histories of different software projects. We also evaluate the expressiveness and ease-of-use of our approach in a user study.},
  langid = {english},
  keywords = {Change distilling,Change querying,Logic meta-programming},
  file = {/home/charlotte/sync/Zotero/storage/AEZPC7HS/Stevens et al. - 2019 - Querying distilled code changes to extract executa.pdf}
}

@article{stevensStructuredDesign1999,
  title = {Structured Design},
  author = {Stevens, W. P. and Myers, G. J. and Constantive, L. L.},
  year = {1999},
  journal = {IBM Systems Journal},
  volume = {38},
  number = {2.3},
  pages = {231--256},
  issn = {0018-8670},
  doi = {10.1147/sj.382.0231},
  abstract = {The HIPO Hierarchy chart is being used as an aid during general systems design. The considerations and techniques presented here are useful for evaluating alternatives for those portions of the system that will be programmed on a computer. The charting technique used here depicts more details about the interfaces than the HIPO Hierarchy chart. This facilitates consideration during general program design of each individual connection and its associated passed parameters. The resulting design can be documented with the Hero charts. (If the designer decides to have more than one function in any module, the structure chart should show them in the same block. However, the HIPO Hierarchy chart would still show all the functions in separate blocks.) The output of the general program design is the input for the detailed module design. The HIPO input-process-output chart is useful for describing and designing each module.},
  file = {/home/charlotte/sync/Zotero/storage/KM7R4LCV/5387105.html}
}

@techreport{streibelCriticalAnalysisComputerBased1985,
  title = {A {{Critical Analysis}} of {{Computer-Based Approaches}} to {{Education}}: {{Drill-and-Practice}}, {{Tutorials}}, and {{Programming}}/{{Simulations}}},
  shorttitle = {A {{Critical Analysis}} of {{Computer-Based Approaches}} to {{Education}}},
  author = {Streibel, Michael J.},
  year = {1985},
  month = apr,
  url = {https://eric.ed.gov/?id=ED263881},
  urldate = {2024-02-07},
  abstract = {Three major approaches to the use of computers in education are examined, serious limitations of each are presented, and questions are raised as to the efficacy of technologolizing education. The drill and practice approach is shown to embody a deterministic, behavioral technology that turns learning into a systematically-designed and quality-controlled form of work. Computerized tutorial programs are shown to extend the behavioral and technological approach to learning even further by shaping interactions via an external agent's intentions in order to maximize the learner's performance gains. Most seriously, computerized tutorial interactions pre-empt the personal intellectual agency and ultimately inner-directed learning. Finally, the use of computers is shown to limit the  learner's mental landscape to objective, quantitative, and procedural tools. A list of references completes the document. (JB)},
  langid = {english},
  keywords = {Computer Assisted Instruction,Computer Simulation,Computer Software,Drills (Practice),Futures (of Society),Man Machine Systems,Mastery Learning,Problem Solving,Programed Tutoring,Programing,Teaching Methods},
  annotation = {ERIC Number: ED263881},
  file = {/home/charlotte/sync/Zotero/storage/XIYNVFIA/Streibel - 1985 - A Critical Analysis of Computer-Based Approaches t.pdf}
}

@inproceedings{strijbolBlinkEducationalSoftware2023,
  title = {Blink: {{An Educational Software Debugger}} for {{Scratch}}},
  shorttitle = {Blink},
  booktitle = {Proceedings of the 2023 {{Conference}} on {{Innovation}} and {{Technology}} in {{Computer Science Education V}}. 2},
  author = {Strijbol, Niko and Scholliers, Christophe and Dawyndt, Peter},
  year = {2023},
  month = jun,
  series = {{{ITiCSE}} 2023},
  pages = {648},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3587103.3594189},
  url = {https://dl.acm.org/doi/10.1145/3587103.3594189},
  urldate = {2023-11-16},
  abstract = {Debugging is an important aspect of programming. Most programming languages have some features and tools to facilitate debugging. As the debugging process is also frustrating, it requires good scaffolding, in which a debugger can be a useful tool [3]. Scratch is a visual block-based programming language that is commonly used to teach programming to children, aged 10--14 [4]. It comes with its own integrated development environment (IDE), where children can edit and run their code. This IDE misses some of the tools that are available in traditional IDEs, such as a debugger. In response to this challenge, we developed Blink. Blink is a debugger for Scratch with the aim of being usable to the young audience that typically uses Scratch. We present the currently implemented features of the debugger, and the challenges we faced while implementing those, both from a user-experience standpoint and a technical standpoint.},
  isbn = {9798400701399},
  keywords = {programming education,scratch debugger,visual programming languages},
  file = {/home/charlotte/sync/Zotero/storage/B67ZZRDB/Strijbol et al. - 2023 - Blink An Educational Software Debugger for Scratc.pdf}
}

@article{strijbolTESTedEducationalTesting2023,
  title = {{{TESTed}}---{{An}} Educational Testing Framework with Language-Agnostic Test Suites for Programming Exercises},
  author = {Strijbol, Niko and Van Petegem, Charlotte and Maertens, Rien and Sels, Boris and Scholliers, Christophe and Dawyndt, Peter and Mesuere, Bart},
  year = {2023},
  month = may,
  journal = {SoftwareX},
  volume = {22},
  pages = {101404},
  issn = {2352-7110},
  doi = {10.1016/j.softx.2023.101404},
  url = {https://www.sciencedirect.com/science/article/pii/S2352711023001000},
  urldate = {2023-05-16},
  abstract = {In educational contexts, automated assessment tools (AAT) are commonly used to provide formative feedback on programming exercises. However, designing exercises for AAT remains a laborious task or imposes limitations on the exercises. Most AAT use either output comparison, where the generated output is compared against an expected output, or unit testing, where the tool has access to the code of the submission under test. While output comparison has the advantage of being programming language independent, the testing capabilities are limited to the output. Conversely, unit testing can generate more granular feedback, but is tightly coupled with the programming language of the submission. In this paper, we introduce TESTed, which enables the best of both worlds: combining the granular feedback of unit testing with the programming language independence of output comparison. Educators can save time by designing exercises that can be used across programming languages. Finally, we report on using TESTed in educational practice.},
  langid = {english},
  keywords = {Automated assessment tools,Educational software testing,Feedback,Programming},
  file = {/home/charlotte/sync/Zotero/storage/WBTY5M4I/Strijbol et al. - 2023 - TESTed—An educational testing framework with langu.pdf;/home/charlotte/sync/Zotero/storage/KD2266YV/S2352711023001000.html}
}

@mastersthesis{strijbolTESTedOneJudge2020,
  title = {{TESTed: one judge to rule them all}},
  author = {Strijbol, Niko and Dawyndt, Peter and Mesuere, Bart},
  year = {2020},
  url = {http://lib.ugent.be/catalog/rug01:002836313},
  langid = {dutch},
  school = {Ghent University},
  file = {/home/charlotte/sync/Zotero/storage/4QXZ2HIJ/Strijbol et al. - 2020 - TESTed one judge to rule them all.pdf}
}

@inproceedings{suCodeRelativesDetecting2016,
  title = {Code Relatives: Detecting Similarly Behaving Software},
  shorttitle = {Code Relatives},
  booktitle = {Proceedings of the 2016 24th {{ACM SIGSOFT International Symposium}} on {{Foundations}} of {{Software Engineering}}},
  author = {Su, Fang-Hsiang and Bell, Jonathan and Harvey, Kenneth and Sethumadhavan, Simha and Kaiser, Gail and Jebara, Tony},
  year = {2016},
  month = nov,
  series = {{{FSE}} 2016},
  pages = {702--714},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2950290.2950321},
  url = {https://dl.acm.org/doi/10.1145/2950290.2950321},
  urldate = {2023-11-23},
  abstract = {Detecting ``similar code'' is useful for many software engineering tasks. Current tools can help detect code with statically similar syntactic and--or semantic features (code clones) and with dynamically similar functional input/output (simions). Unfortunately, some code fragments that behave similarly at the finer granularity of their execution traces may be ignored. In this paper, we propose the term ``code relatives'' to refer to code with similar execution behavior. We define code relatives and then present DyCLINK, our approach to detecting code relatives within and across codebases. DyCLINK records instruction-level traces from sample executions, organizes the traces into instruction-level dynamic dependence graphs, and employs our specialized subgraph matching algorithm to efficiently compare the executions of candidate code relatives. In our experiments, DyCLINK analyzed 422+ million prospective subgraph matches in only 43 minutes. We compared DyCLINK to one static code clone detector from the community and to our implementation of a dynamic simion detector. The results show that DyCLINK effectively detects code relatives with a reasonable analysis time.},
  isbn = {978-1-4503-4218-6},
  keywords = {code clones,Code relatives,link analysis,runtime behavior,subgraph matching},
  file = {/home/charlotte/sync/Zotero/storage/TGV3LVY3/Su et al. - 2016 - Code relatives detecting similarly behaving softw.pdf}
}

@article{svetnikRandomForestClassification2003,
  title = {Random {{Forest}}:\, {{A Classification}} and {{Regression Tool}} for {{Compound Classification}} and {{QSAR Modeling}}},
  shorttitle = {Random {{Forest}}},
  author = {Svetnik, Vladimir and Liaw, Andy and Tong, Christopher and Culberson, J. Christopher and Sheridan, Robert P. and Feuston, Bradley P.},
  year = {2003},
  month = nov,
  journal = {Journal of Chemical Information and Computer Sciences},
  volume = {43},
  number = {6},
  pages = {1947--1958},
  publisher = {{American Chemical Society}},
  issn = {0095-2338},
  doi = {10.1021/ci034160g},
  url = {https://doi.org/10.1021/ci034160g},
  urldate = {2021-02-19},
  abstract = {A new classification and regression tool, Random Forest, is introduced and investigated for predicting a compound's quantitative or categorical biological activity based on a quantitative description of the compound's molecular structure. Random Forest is an ensemble of unpruned classification or regression trees created by using bootstrap samples of the training data and random feature selection in tree induction. Prediction is made by aggregating (majority vote or averaging) the predictions of the ensemble. We built predictive models for six cheminformatics data sets. Our analysis demonstrates that Random Forest is a powerful tool capable of delivering performance that is among the most accurate methods to date. We also present three additional features of Random Forest:\, built-in performance assessment, a measure of relative importance of descriptors, and a measure of compound similarity that is weighted by the relative importance of descriptors. It is the combination of relatively high prediction accuracy and its collection of desired features that makes Random Forest uniquely suited for modeling in cheminformatics.},
  file = {/home/charlotte/sync/Zotero/storage/NXAQCTYB/Svetnik et al. - 2003 - Random Forest  A Classification and Regression To.pdf;/home/charlotte/sync/Zotero/storage/KLIJU6B7/ci034160g.html}
}

@article{temperlyGradingProcedurePL1968,
  title = {A {{Grading Procedure}} for {{PL}}/1 {{Student Exercises}}},
  author = {Temperly, J. F. and Smith, Barry W.},
  year = {1968},
  month = feb,
  journal = {The Computer Journal},
  volume = {10},
  number = {4},
  pages = {368--373},
  issn = {0010-4620},
  doi = {10.1093/comjnl/10.4.368},
  url = {https://doi.org/10.1093/comjnl/10.4.368},
  urldate = {2024-02-07},
  abstract = {A procedure to supply test data for a number of undergraduate programming exercises in the PL/1 language and check the validity of the programs is described. The procedure provides diagnostic information to the student and performs all necessary output, as well as maintaining complete records of student performance on magnetic disc storage. The procedure differs from many previous grading routines in being called as a precompiled library subroutine, and is the first known grading procedure for PL/1. The initial set of class problems and specimen output listings are appended.},
  file = {/home/charlotte/sync/Zotero/storage/KUPEZD7J/temperly1968.pdf.pdf;/home/charlotte/sync/Zotero/storage/YN8PSZBD/Temperly and Smith - 1968 - A Grading Procedure for PL1 Student Exercises.pdf;/home/charlotte/sync/Zotero/storage/DDYSUANU/463937.html}
}

@inproceedings{thurnerObjectsFirstTests2015,
  title = {An ``Objects First, Tests Second'' Approach for Software Engineering Education},
  booktitle = {2015 {{IEEE Frontiers}} in {{Education Conference}} ({{FIE}})},
  author = {Thurner, Veronika and B{\"o}ttcher, Axel},
  year = {2015},
  month = oct,
  pages = {1--5},
  doi = {10.1109/FIE.2015.7344027},
  abstract = {Since unit testing is a skill required of professional software developers, lecturers have to develop this skill in their software engineering students. Therefore, we introduce the approach of ``objects first, tests second'', which incorporates unit testing into introductory programming classes. We discuss requirements that teaching materials must meet to effectively support this approach, and present a concept for assessing the quality of student written tests. An analysis of students' results illustrates the effectiveness of this teaching approach.},
  keywords = {Computer science education,Design for testability,Education,Programming,Software,Software engineering,Testing,Visualization},
  file = {/home/charlotte/sync/Zotero/storage/Q55BSAFA/Thurner and Böttcher - 2015 - An “objects first, tests second” approach for soft.pdf;/home/charlotte/sync/Zotero/storage/MMGCZF8E/7344027.html}
}

@article{tirronenIncorporatingTeacherstudentDialogue2020,
  title = {Incorporating Teacher-Student Dialogue into Digital Course Material : {{Usage}} Patterns and First Experiences},
  shorttitle = {Incorporating Teacher-Student Dialogue into Digital Course Material},
  author = {Tirronen, Ville and Lappalainen, Vesa and Isom{\"o}tt{\"o}nen, Ville and Lakanen, Antti-Jussi and Taipalus, Toni and Nieminen, Paavo and Ogbechie, Anthony},
  year = {2020},
  journal = {Conference proceedings : Frontiers in Education Conference},
  publisher = {{IEEE}},
  doi = {10.1109/FIE44824.2020.9274123},
  url = {https://jyx.jyu.fi/handle/123456789/73098},
  urldate = {2022-09-15},
  abstract = {This work-in-progress research investigates teacher-student communication via Learning Management Systems (LMS) in highly populated courses. An LMS called TIM (The Interactive Material) includes a specific commenting technology that attempts to make teacher-student dialog effortless. The research goal is to explore students' willingness to use the technology and identify patterns of usage. To these ends, a survey with both Likert and open-ended questions was issued to CS1 and CS2 students. A favorable student evaluation was observed while several critical viewpoints that inform technology development were revealed. We noticed that besides appreciating the possibility of making comments, many students found benefit from peripheral participation without being active in commenting themselves. Informal communication appared to be preferred, and the commenting technology was considered second to best channel in this regard, following face-to-face interaction. The results are discussed in the light of Transactional Distance Theory and related literature to inform basic research.},
  copyright = {In Copyright},
  langid = {english},
  annotation = {Accepted: 2020-12-10T10:41:31Z},
  file = {/home/charlotte/sync/Zotero/storage/3JXISR4Q/Tirronen et al. - 2020 - Incorporating teacher-student dialogue into digita.pdf;/home/charlotte/sync/Zotero/storage/LVLPWI6Q/73098.html}
}

@article{tuckerFlippedClassroom2012,
  title = {The Flipped Classroom},
  author = {Tucker, Bill},
  year = {2012},
  journal = {Education next},
  volume = {12},
  number = {1},
  pages = {82--83}
}

@article{tuckFeedbackgivingSocialPractice2012,
  title = {Feedback-Giving as Social Practice: Teachers' Perspectives on Feedback as Institutional Requirement, Work and Dialogue},
  shorttitle = {Feedback-Giving as Social Practice},
  author = {Tuck, Jackie},
  year = {2012},
  month = apr,
  journal = {Teaching in Higher Education},
  volume = {17},
  number = {2},
  pages = {209--221},
  publisher = {{Routledge}},
  issn = {1356-2517},
  doi = {10.1080/13562517.2011.611870},
  url = {https://doi.org/10.1080/13562517.2011.611870},
  urldate = {2024-02-05},
  abstract = {The lived experience of academic teachers as they engage in feedback has received relatively little attention compared to student perspectives on feedback. The present study used an ethnographically informed methodology to investigate the everyday practices around undergraduates' writing of fourteen UK HE teachers, in a range of disciplines and institutions, focusing on teachers' perspectives. This paper presents analysis of interviews conducted as part of the study, in which feedback-giving emerged as significant, understood by participants in several potentially dissonant ways: as institutional requirement, as work and as dialogue. Findings suggest participants sometimes managed to reconcile these conflicts and carve out small spaces for dialogue with students, and also indicate that attempts to create greater opportunities for such work, by offering greater support and recognition at institutional level, must take account of teachers' need for a sense of personal investment in student writing in their disciplinary contexts.},
  keywords = {academic literacies,dialogue,feedback,marking,student writing},
  file = {/home/charlotte/sync/Zotero/storage/ADGIU3TT/tuck2012.pdf.pdf;/home/charlotte/sync/Zotero/storage/BATEHHLL/Tuck - 2012 - Feedback-giving as social practice teachers’ pers.pdf}
}

@article{tuomiOpenEducationalResources2013,
  title = {Open {{Educational Resources}} and the {{Transformation}} of {{Education}}},
  author = {Tuomi, Ilkka},
  year = {2013},
  journal = {European Journal of Education},
  volume = {48},
  number = {1},
  pages = {58--78},
  issn = {1465-3435},
  doi = {10.1111/ejed.12019},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ejed.12019},
  urldate = {2022-10-03},
  abstract = {The extremely rapid expansion of open educational resource (OER) initiatives and the millions of learners they attract can be understood as an indicator of an emerging revolution in education and learning. This article describes recent developments in this area and develops conceptual foundations for studies and policies on OER. We describe four different types of OER, locate these in a field of learning theories, and discuss how the wide adoption of OER may constrain and accelerate the transformation of learning and education in the knowledge society.},
  langid = {english},
  keywords = {alternative learning models,future of learning,Hayekian benefits,knowledge society,OER definitions,open educational resources,societal functions of education,technology-enabled learning},
  file = {/home/charlotte/sync/Zotero/storage/ZMDUB6MW/Tuomi - 2013 - Open Educational Resources and the Transformation .pdf;/home/charlotte/sync/Zotero/storage/ZBQ7CIRL/ejed.html}
}

@inproceedings{ureeliiAutomatedCritiqueEarly2019,
  title = {Automated {{Critique}} of {{Early Programming Antipatterns}}},
  booktitle = {Proceedings of the 50th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  author = {Ureel II, Leo C. and Wallace, Charles},
  year = {2019},
  month = feb,
  series = {{{SIGCSE}} '19},
  pages = {738--744},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3287324.3287463},
  url = {https://doi.org/10.1145/3287324.3287463},
  urldate = {2022-02-25},
  abstract = {The introductory programming lab, with small cycles of teaching, coding, testing, and critique from instructors, is an extraordinarily productive learning experience for novice programmers. We wish to extend the availability of such critique through automation, capturing the essence of interaction between student and instructor as closely as possible. Integrated Development Environments and Automated Grading Systems provide constant feedback through static analysis and unit testing. But we also wish to tailor automated feedback to acknowledge commonly recurring issues with novice programmers, in keeping with the practice of a human instructor. We argue that the kinds of mistakes that novice programmers make, and the way they are reported to the novices, deserve special care. In this paper we provide examples of early programming antipatterns that have arisen from our teaching experience, and describe different ways of identifying and dealing with them automatically through our tool WebTA. Novice students may produce code that is close to a correct solution but contains syntactic errors; WebTA attempts to salvage the promising portions of the student's submission and suggest repairs that are more meaningful than typical compiler error messages. Alternatively, a student misunderstanding may result in well-formed code that passes unit tests yet contains clear design flaws; through additional analysis, WebTA can identify and flag them. Finally, certain types of antipattern can be anticipated and flagged by the instructor, based on the context of the course and the programming exercise; WebTA allows for customizable critique triggers and messages.},
  isbn = {978-1-4503-5890-3},
  keywords = {autograder,critiquing systems,cs1,design patterns},
  file = {/home/charlotte/sync/Zotero/storage/ADNTANNI/Ureel II and Wallace - 2019 - Automated Critique of Early Programming Antipatter.pdf}
}

@inproceedings{vanpetegemActivatingLearningExperience2002,
  title = {The Activating Learning Experience Supported by {{ICT}}},
  booktitle = {E-{{Learn}}: {{World Conference}} on {{E-Learning}} in {{Corporate}}, {{Government}}, {{Healthcare}}, and {{Higher Education}}},
  author = {Van Petegem, Peter and De Loght, Toby},
  year = {2002},
  pages = {2577--2578},
  publisher = {{Association for the Advancement of Computing in Education (AACE)}},
  url = {https://www.learntechlib.org/primary/p/9603/},
  urldate = {2024-01-31},
  abstract = {The starting point of this contribution is the concept of Powerful Learning. It contains 6 characteristics which we transformed into a structured model. The centre of the model consists of student-centred education and it's accompanying coaching component. Surrounding the centre, there are three satellites: Content, problem-based learning and collaborative learning which are linked and in constant interaction with each other and the centre part. The improved concept is then illustrated with cases from different teacher education programmes at the university of Antwerp. In these cases we...},
  isbn = {978-1-880094-46-4},
  langid = {english}
}

@mastersthesis{vanpetegemComputationeleBenaderingenVoor2018,
  title = {{Computationele benaderingen voor deductie van de computationele complexiteit van computerprogramma's}},
  author = {Van Petegem, Charlotte and Dawyndt, Peter},
  year = {2018},
  url = {http://lib.ugent.be/catalog/rug01:002479652},
  langid = {dutch},
  school = {Ghent University}
}

@article{vanpetegemDodonaLearnCode2023,
  title = {Dodona: {{Learn}} to Code with a Virtual Co-Teacher That Supports Active Learning},
  shorttitle = {Dodona},
  author = {Van Petegem, Charlotte and Maertens, Rien and Strijbol, Niko and Van Renterghem, Jorg and {Van der Jeugt}, Felix and De Wever, Bram and Dawyndt, Peter and Mesuere, Bart},
  year = {2023},
  month = dec,
  journal = {SoftwareX},
  volume = {24},
  pages = {101578},
  issn = {2352-7110},
  doi = {10.1016/j.softx.2023.101578},
  url = {https://www.sciencedirect.com/science/article/pii/S2352711023002741},
  urldate = {2023-11-16},
  abstract = {Dodona () is an intelligent tutoring system for computer programming. It provides real-time data and feedback to help students learn better and teachers teach better. Dodona is free to use and has more than 61 thousand registered users across many educational and research institutes, including 20 thousand new users in the last year. The source code of Dodona is available on GitHub under the permissive MIT open-source license. This paper presents Dodona and its design and look-and-feel. We highlight some of the features built into Dodona that make it possible to shorten feedback loops, and discuss an example of how these features can be used in practice. We also highlight some of the research opportunities that Dodona has opened up and present some future developments.},
  keywords = {Computer-assisted instruction,Education,Interactive learning environments},
  file = {/home/charlotte/sync/Zotero/storage/J5SWQJST/Van Petegem et al. - 2023 - Dodona Learn to code with a virtual co-teacher th.pdf;/home/charlotte/sync/Zotero/storage/MK2GCFAF/S2352711023002741.html}
}

@inproceedings{vanpetegemDodonaLearnCode2023a,
  title = {Dodona: {{Learn}} to {{Code}} with a {{Virtual Co-teacher}} That {{Supports Active Learning}}},
  shorttitle = {Dodona},
  booktitle = {Proceedings of the 2023 {{Conference}} on {{Innovation}} and {{Technology}} in {{Computer Science Education V}}. 2},
  author = {Van Petegem, Charlotte and Dawyndt, Peter and Mesuere, Bart},
  year = {2023},
  month = jun,
  series = {{{ITiCSE}} 2023},
  pages = {633},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3587103.3594165},
  url = {https://dl.acm.org/doi/10.1145/3587103.3594165},
  urldate = {2023-11-16},
  abstract = {Dodona (dodona.ugent.be) is an intelligent tutoring system for learning computer programming, statistics and data science. It bridges the gap between assessment and learning by providing real-time data and feedback to help students learn better, teachers teach better and educational technology become more effective. We show how Dodona can be used as a virtual co-teacher to stimulate active learning and support challenge-based education in open and collaborative learning environments. We also highlight some of the opportunities and challenges we have faced in practice. Dodona is free to use and has more than 50 thousand registered users across many educational and research institutions, including 15 thousand new users in the last year. Dodona's source code is available on GitHub under the permissive MIT open-source license.},
  isbn = {9798400701399},
  keywords = {active learning,automated assessment,classroom management,computer programming,computer-assisted learning,computer-assisted teaching,feedback,intelligent tutoring system,learning analytics},
  file = {/home/charlotte/sync/Zotero/storage/VJLK34R8/Van Petegem et al. - 2023 - Dodona Learn to Code with a Virtual Co-teacher th.pdf}
}

@article{vanpetegemPassFailPrediction2022,
  title = {Pass/{{Fail Prediction}} in {{Programming Courses}}},
  author = {Van Petegem, Charlotte and Deconinck, Louise and Mourisse, Dieter and Maertens, Rien and Strijbol, Niko and Dhoedt, Bart and De Wever, Bram and Dawyndt, Peter and Mesuere, Bart},
  year = {2022},
  month = jun,
  journal = {Journal of Educational Computing Research},
  pages = {68--95},
  publisher = {{SAGE Publications Inc}},
  issn = {0735-6331},
  doi = {10.1177/07356331221085595},
  url = {https://doi.org/10.1177/07356331221085595},
  urldate = {2022-08-16},
  abstract = {We present a privacy-friendly early-detection framework to identify students at risk of failing in introductory programming courses at university. The framework was validated for two different courses with annual editions taken by higher education students (N = 2\,080) and was found to be highly accurate and robust against variation in course structures, teaching and learning styles, programming exercises and classification algorithms. By using interpretable machine learning techniques, the framework also provides insight into what aspects of practising programming skills promote or inhibit learning or have no or minor effect on the learning process. Findings showed that the framework was capable of predicting students' future success already early on in the semester.},
  langid = {english},
  keywords = {computer programming,computer science education,educational data mining,intelligent tutoring systems,pass/fail prediction},
  file = {/home/charlotte/sync/Zotero/storage/49LUPXRI/Van Petegem et al. - 2022 - PassFail Prediction in Programming Courses.pdf}
}

@article{vanpetegemPowerfulLearningInteractive2004,
  title = {Powerful {{Learning Is Interactive}}: {{A Cross-Cultural Perspective}}},
  shorttitle = {Powerful {{Learning Is Interactive}}},
  author = {Van Petegem, Peter and De Loght, Toby and Shortridge, Ann M.},
  year = {2004},
  journal = {E-Journal of Instructional Science and Technology},
  volume = {7},
  number = {1},
  publisher = {{University of Southern Queensland}},
  issn = {1324-0781},
  url = {https://eric.ed.gov/?id=EJ850351},
  urldate = {2024-01-31},
  abstract = {For centuries traditional university education has primarily focused on building foundational skills in particular disciplines via the transfer of knowledge from instructor to student. Today however, simply being able to reproduce knowledge is no longer adequate; students must also be able to apply their knowledge to changing, real world contexts. By sharing lessons learned and drawing parallels across cultural boundaries, the University of Antwerp, Belgium and the University of Arkansas, USA provide additional insight into how to effectively teach students these skills. Topics that are addressed include: the concepts of powerful learning, interactivity, adequate dialogue, and the post-development evaluation and effective use of e learning environments. (Contains 2 figures and 4 tables.)},
  langid = {english},
  keywords = {Agricultural Education,College Students,Computer Mediated Communication,Computer Peripherals,Computer Software Evaluation,Concept Mapping,Constructivism (Learning),Courseware,Cross Cultural Studies,Discussion Groups,Distance Education,Educational Policy,Electronic Learning,Foreign Countries,Instructional Design,Instructional Effectiveness,Internet,Student Attitudes,Teacher Education,Technology Integration,Web Based Instruction},
  annotation = {ERIC Number: EJ850351},
  file = {/home/charlotte/sync/Zotero/storage/LX7YWGJC/Van Petegem et al. - 2004 - Powerful Learning Is Interactive A Cross-Cultural.pdf}
}

@phdthesis{vanpetegemScholenOpZoek1997,
  title = {{Scholen op zoek naar hun kwaliteit: effectieve-scholenonderzoek als inspiratiebron voor de zelfevaluatie van scholen}},
  shorttitle = {{Scholen op zoek naar hun kwaliteit}},
  author = {Van Petegem, Peter},
  year = {1997},
  langid = {dutch},
  school = {Ghent University},
  file = {/home/charlotte/sync/Zotero/storage/YF5LL4R5/Van Petegem - 1997 - Scholen op zoek naar hun kwaliteit  effectieve-sc.pdf;/home/charlotte/sync/Zotero/storage/7VEWX7NX/rug01000400481.html}
}

@article{vasyliukDesignImplementationUkrainianLanguage2023,
  title = {Design and {{Implementation}} of a {{Ukrainian-Language Educational Platform}} for {{Learning Programming Languages}}},
  author = {Vasyliuk, Andrii and Lytvyn, Taras Basyukand Vasyl},
  year = {2023},
  journal = {Proceedings http://ceur-ws. org ISSN},
  volume = {1613},
  pages = {0073},
  url = {https://ceur-ws.org/Vol-3426/paper32.pdf},
  urldate = {2023-10-04},
  file = {/home/charlotte/sync/Zotero/storage/LPSH3EJT/Vasyliuk and Lytvyn - 2023 - Design and Implementation of a Ukrainian-Language .pdf}
}

@article{verhoeffProgrammingTaskPackages2008,
  title = {Programming {{Task Packages}}: {{Peach Exchange}}},
  author = {Verhoeff, Tom},
  year = {2008},
  journal = {Olympiads in Informatics},
  pages = {192},
  publisher = {{Citeseer}}
}

@inproceedings{vihavainenPredictingStudentsPerformance2013,
  title = {Predicting {{Students}}' {{Performance}} in an {{Introductory Programming Course Using Data}} from {{Students}}' {{Own Programming Process}}},
  booktitle = {2013 {{IEEE}} 13th {{International Conference}} on {{Advanced Learning Technologies}}},
  author = {Vihavainen, A.},
  year = {2013},
  month = jul,
  pages = {498--499},
  issn = {2161-377X},
  doi = {10.1109/ICALT.2013.161},
  abstract = {As the amount of data, facilities, and tools for understanding students' programming process are improving, the time is ripe for analyzing students' actual programming process. In our current work we are investigating how students' behavior during her programming process (e.g. eagerness to start working on freshly released exercises, following best programming practises) affects the course outcome. We purposefully utilize only data gathered automatically using snapshots from the students' programming process, and do not gather any additional background information. Currently, we are able to predict whether the student is a high-performer, passes the course, or fails the course with a 78\%accuracy.},
  keywords = {Accuracy,Bayes methods,Code Snapshots,computer science education,Computer Science Education,Context,Education,Extreme Apprenticeship,introductory programming course,Performance analysis,programming,Programming profession,student behavior,Student Performance,student performance prediction,student programming process analysis,student programming process data},
  file = {/home/charlotte/sync/Zotero/storage/7CI2RMMK/Vihavainen - 2013 - Predicting Students' Performance in an Introductor.pdf;/home/charlotte/sync/Zotero/storage/YBDIRKFE/6602003.html}
}

@inproceedings{vihavainenScaffoldingStudentsLearning2013,
  title = {Scaffolding Students' Learning Using Test My Code},
  booktitle = {Proceedings of the 18th {{ACM}} Conference on {{Innovation}} and Technology in Computer Science Education},
  author = {Vihavainen, Arto and Vikberg, Thomas and Luukkainen, Matti and P{\"a}rtel, Martin},
  year = {2013},
  month = jul,
  series = {{{ITiCSE}} '13},
  pages = {117--122},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2462476.2462501},
  url = {https://dl.acm.org/doi/10.1145/2462476.2462501},
  urldate = {2023-08-21},
  abstract = {As programming is the basis of many CS courses, meaningful activities in supporting students on their journey towards being better programmers is a matter of utmost importance. Programming is not only about learning simple syntax constructs and their applications, but about honing practical problem-solving skills in meaningful contexts. In this article, we describe our current work on an automated assessment system called Test My Code (TMC), which is one of the feedback and support mechanisms that we use in our programming courses. TMC is an assessment service that (1) enables building of scaffolding into programming exercises; (2) retrieves and updates tasks into the students' programming environment as students work on them, and (3) causes no additional overhead to students' programming process. Instructors benefit from TMC as it can be used to perform code reviews, and collect and send feedback even on fully on-line courses.},
  isbn = {978-1-4503-2078-8},
  keywords = {automatic assessment,extreme apprenticeship,programming,situated learning,testing,verification},
  file = {/home/charlotte/sync/Zotero/storage/PW9J9GLY/Vihavainen et al. - 2013 - Scaffolding students' learning using test my code.pdf}
}

@inproceedings{vihavainenUsingStudentsProgramming2013,
  title = {Using Students' Programming Behavior to Predict Success in an Introductory Mathematics Course},
  booktitle = {Educational {{Data Mining}} 2013},
  author = {Vihavainen, Arto and Luukkainen, Matti and Kurhila, Jaakko},
  year = {2013},
  publisher = {{Citeseer}},
  file = {/home/charlotte/sync/Zotero/storage/PQRWFWLJ/Vihavainen et al. - 2013 - Using students' programming behavior to predict su.pdf}
}

@article{vittoriniAIBasedSystemFormative2021,
  title = {An {{AI-Based System}} for {{Formative}} and {{Summative Assessment}} in {{Data Science Courses}}},
  author = {Vittorini, Pierpaolo and Menini, Stefano and Tonelli, Sara},
  year = {2021},
  month = jun,
  journal = {International Journal of Artificial Intelligence in Education},
  volume = {31},
  number = {2},
  pages = {159--185},
  issn = {1560-4306},
  doi = {10.1007/s40593-020-00230-2},
  url = {https://doi.org/10.1007/s40593-020-00230-2},
  urldate = {2024-01-10},
  abstract = {Massive open online courses (MOOCs) provide hundreds of students with teaching materials, assessment tools, and collaborative instruments. The assessment activity, in particular, is demanding in terms of both time and effort; thus, the use of artificial intelligence can be useful to address and reduce the time and effort required. This paper reports on a system and related experiments finalised to improve both the performance and quality of formative and summative assessments in specific data science courses. The system is developed to automatically grade assignments composed of R commands commented with short sentences written in natural language. In our opinion, the use of the system can (i) shorten the correction times and reduce the possibility of errors and (ii) support the students while solving the exercises assigned during the course through automated feedback. To investigate these aims, an ad-hoc experiment was conducted in three courses containing the specific topic of statistical analysis of health data. Our evaluation demonstrated that automated grading has an acceptable correlation with human grading. Furthermore, the students who used the tool did not report usability issues, and those that used it for more than half of the exercises obtained (on average) higher grades in the exam. Finally, the use of the system reduced the correction time and assisted the professor in identifying correction errors.},
  langid = {english},
  keywords = {Assessment,Automated grading,Embeddings,ML,NLP,SVM},
  file = {/home/charlotte/sync/Zotero/storage/MCE4XEVP/Vittorini et al. - 2021 - An AI-Based System for Formative and Summative Ass.pdf;/home/charlotte/sync/Zotero/storage/YR42PAT9/vittorini2020.pdf.pdf}
}

@article{vonderwellActiveLearningPreservice2005,
  title = {Active {{Learning}} and {{Preservice Teachers}}' {{Experiences}} in an {{Online Course}}: {{A Case Study}}},
  shorttitle = {Active {{Learning}} and {{Preservice Teachers}}' {{Experiences}} in an {{Online Course}}},
  author = {Vonderwell, Selma and Turner, Sandra},
  year = {2005},
  journal = {Journal of Technology and Teacher Education},
  volume = {13},
  number = {1},
  pages = {65--84},
  publisher = {{Society for Information Technology \& Teacher Education}},
  issn = {1059-7069},
  url = {https://www.learntechlib.org/primary/p/18892/},
  urldate = {2021-10-01},
  abstract = {The purpose of this qualitative case study was to examine preservice teachers' experiences and the meaning they gave to their experiences in a "Technology Applications in Education" online course. The theoretical framework was based on the "Rich Environments for Active Learning" proposed by Grabinger and Dunlap (2000). The attributes of rich learning environments for active learning are student responsibility and initiative, generative learning activities, authentic learning contexts, authentic assessment strategies, and cooperative support. The study findings imply that the online learning...},
  langid = {english}
}

@article{wagner2000plagiarism,
  title = {Plagiarism by Student Programmers},
  author = {Wagner, Neal R},
  year = {2000},
  journal = {The University of Texas at San Antonio Division Computer Science San Antonio, TX},
  volume = {78249},
  publisher = {{Citeseer}},
  file = {/home/charlotte/sync/Zotero/storage/NHLWSAV9/Wagner - 2000 - Plagiarism by student programmers.pdf}
}

@article{wasikSurveyOnlineJudge2018,
  title = {A {{Survey}} on {{Online Judge Systems}} and {{Their Applications}}},
  author = {Wasik, Szymon and Antczak, Maciej and Badura, Jan and Laskowski, Artur and Sternal, Tomasz},
  year = {2018},
  month = jan,
  journal = {ACM Computing Surveys},
  volume = {51},
  number = {1},
  pages = {3:1--3:34},
  issn = {0360-0300},
  doi = {10.1145/3143560},
  url = {https://doi.org/10.1145/3143560},
  urldate = {2021-08-24},
  abstract = {Online judges are systems designed for the reliable evaluation of algorithm source code submitted by users, which is next compiled and tested in a homogeneous environment. Online judges are becoming popular in various applications. Thus, we would like to review the state of the art for these systems. We classify them according to their principal objectives into systems supporting organization of competitive programming contests, enhancing education and recruitment processes, facilitating the solving of data mining challenges, online compilers and development platforms integrated as components of other custom systems. Moreover, we introduce a formal definition of an online judge system and summarize the common evaluation methodology supported by such systems. Finally, we briefly discuss an Optil.io platform as an example of an online judge system, which has been proposed for the solving of complex optimization problems. We also analyze the competition results conducted using this platform. The competition proved that online judge systems, strengthened by crowdsourcing concepts, can be successfully applied to accurately and efficiently solve complex industrial- and science-driven challenges.},
  keywords = {challenge,contest,crowdsourcing,evaluation as a service,Online judge},
  file = {/home/charlotte/sync/Zotero/storage/WBTT6RTG/Wasik et al. - 2018 - A Survey on Online Judge Systems and Their Applica.pdf}
}

@article{watanobeNextGenerationProgrammingLearning2020,
  title = {Next-{{Generation Programming Learning Platform}}: {{Architecture}} and {{Challenges}}},
  shorttitle = {Next-{{Generation Programming Learning Platform}}},
  author = {Watanobe, Yutaka and Intisar, Chowdhury and Cortez, Ruth and Vazhenin, Alexander},
  year = {2020},
  journal = {SHS Web of Conferences},
  volume = {77},
  pages = {01004},
  publisher = {{EDP Sciences}},
  issn = {2261-2424},
  doi = {10.1051/shsconf/20207701004},
  url = {https://www.shs-conferences.org/articles/shsconf/abs/2020/05/shsconf_etltc2020_01004/shsconf_etltc2020_01004.html},
  urldate = {2023-10-02},
  abstract = {With the rapid development of information technology, programming has become a vital skill. An online judge system can be used as a programming education platform, where the daily activities of users and judges are used to generate useful learning objects (e.g., tasks, solution codes, evaluations). Intelligent software agents can utilize such objects to create an ecosystem. To implement such an ecosystem, a generic architecture that covers the whole lifecycle of data on the platform and the functionalities of an e-learning system should take into account the particularities of the online judge system. In this paper, an architecture that implements such an ecosystem based on an online judge system is proposed. The potential benefits and research challenges are discussed.},
  copyright = {{\copyright} The Authors, published by EDP Sciences, 2020},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/N4WMWTYP/Watanobe et al. - 2020 - Next-Generation Programming Learning Platform Arc.pdf}
}

@inproceedings{watsonFailureRatesIntroductory2014,
  title = {Failure Rates in Introductory Programming Revisited},
  booktitle = {Proceedings of the 2014 Conference on {{Innovation}} \& Technology in Computer Science Education},
  author = {Watson, Christopher and Li, Frederick W.B.},
  year = {2014},
  month = jun,
  series = {{{ITiCSE}} '14},
  pages = {39--44},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2591708.2591749},
  url = {https://doi.org/10.1145/2591708.2591749},
  urldate = {2021-02-19},
  abstract = {Whilst working on an upcoming meta-analysis that synthesized fifty years of research on predictors of programming performance, we made an interesting discovery. Despite several studies citing a motivation for research as the high failure rates of introductory programming courses, to date, the majority of available evidence on this phenomenon is at best anecdotal in nature, and only a single study by Bennedsen and Caspersen has attempted to determine a worldwide pass rate of introductory programming courses. In this paper, we answer the call for further substantial evidence on the CS1 failure rate phenomenon, by performing a systematic review of introductory programming literature, and a statistical analysis on pass rate data extracted from relevant articles. Pass rates describing the outcomes of 161 CS1 courses that ran in 15 different countries, across 51 institutions were extracted and analysed. An almost identical mean worldwide pass rate of 67.7\% was found. Moderator analysis revealed significant, but perhaps not substantial differences in pass rates based upon: grade level, country, and class size. However, pass rates were found not to have significantly differed over time, or based upon the programming language taught in the course. This paper serves as a motivation for researchers of introductory programming education, and provides much needed quantitative evidence on the potential difficulties and failure rates of this course.},
  isbn = {978-1-4503-2833-3},
  keywords = {cs1,fail rates,failure rates,introductory programming,pass rates,programming,statistics},
  file = {/home/charlotte/sync/Zotero/storage/PTM64G3B/Watson and Li - 2014 - Failure rates in introductory programming revisite.pdf}
}

@article{werthPredictingStudentPerformance1986,
  title = {Predicting Student Performance in a Beginning Computer Science Class},
  author = {Werth, Laurie Honour},
  year = {1986},
  month = feb,
  journal = {ACM SIGCSE Bulletin},
  volume = {18},
  number = {1},
  pages = {138--143},
  issn = {0097-8418},
  doi = {10.1145/953055.5701},
  url = {https://dl.acm.org/doi/10.1145/953055.5701},
  urldate = {2024-01-22},
  abstract = {This study investigated the relationship between the student's grade in a beginning computer science course and their sex, age, high school and college academic performance, number of mathematics courses, and work experience. Standard measures of cognitive development, cognitive style, and personality factors were also given to 58 students in three sections of the beginning Pascal programming class. Significant relationships were found between the letter grade and the students' college grades, the number of hours worked and the number of high school mathematics classes. Both the Group Embedded Figures Test (GEFT) and the measure of Piagetian intellectual development stages were also significantly correlated with grade in the course. There was no relationship between grade and the personality type, as measured by the Myers-Briggs Type Indicator (MBTI); however, an interesting and distinctive personality profile was evident.},
  file = {/home/charlotte/sync/Zotero/storage/4FDEYD73/werth1986.pdf.pdf;/home/charlotte/sync/Zotero/storage/VYZFFEPK/Werth - 1986 - Predicting student performance in a beginning comp.pdf}
}

@misc{wickhamGgplot2CreateElegant2023,
  title = {Ggplot2: {{Create Elegant Data Visualisations Using}} the {{Grammar}} of {{Graphics}}},
  shorttitle = {Ggplot2},
  author = {Wickham, Hadley and Chang, Winston and Henry, Lionel and Pedersen, Thomas Lin and Takahashi, Kohske and Wilke, Claus and Woo, Kara and Yutani, Hiroaki and Dunnington, Dewey and Posit and PBC},
  year = {2023},
  month = oct,
  url = {https://cran.r-project.org/web/packages/ggplot2/index.html},
  urldate = {2023-12-08},
  abstract = {A system for 'declaratively' creating graphics, based on "The Grammar of Graphics". You provide the data, tell 'ggplot2' how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details.},
  copyright = {MIT + file LICENSE},
  keywords = {Phylogenetics,Spatial,TeachingStatistics}
}

@book{wiegersCreatingSoftwareEngineering1996,
  title = {Creating a Software Engineering Culture},
  author = {Wiegers, Karl Eugene},
  year = {1996},
  publisher = {{Pearson Education}}
}

@inproceedings{wilcoxTestingStrategiesAutomated2016,
  title = {Testing {{Strategies}} for the {{Automated Grading}} of {{Student Programs}}},
  booktitle = {Proceedings of the 47th {{ACM Technical Symposium}} on {{Computing Science Education}}},
  author = {Wilcox, Chris},
  year = {2016},
  month = feb,
  series = {{{SIGCSE}} '16},
  pages = {437--442},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2839509.2844616},
  url = {https://doi.org/10.1145/2839509.2844616},
  urldate = {2022-08-16},
  abstract = {Enrollments in introductory computer science courses are growing rapidly, thereby taxing scarce teaching resources and motivating the increased use of automated tools for program grading. Such tools commonly rely on regression testing methods from industry. However, the goals of automated grading differ from those of testing for software production. In academia, a primary motivation for testing is to provide timely and accurate feedback to students so that they can understand and fix defects in their programs. Testing strategies for program grading are therefore distinct from those of traditional software testing. This paper enumerates and describes a number of testing strategies that improve the quality of feedback for different types of programming assignments.},
  isbn = {978-1-4503-3685-7},
  keywords = {automated assessment,automated grading},
  file = {/home/charlotte/sync/Zotero/storage/C2EJRVNJ/Wilcox - 2016 - Testing Strategies for the Automated Grading of St.pdf}
}

@incollection{wileyOpenEducationalResources2014,
  title = {Open {{Educational Resources}}: {{A Review}} of the {{Literature}}},
  shorttitle = {Open {{Educational Resources}}},
  booktitle = {Handbook of {{Research}} on {{Educational Communications}} and {{Technology}}},
  author = {Wiley, David and Bliss, T. J. and McEwen, Mary},
  editor = {Spector, J. Michael and Merrill, M. David and Elen, Jan and Bishop, M. J.},
  year = {2014},
  pages = {781--789},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4614-3185-5_63},
  url = {https://doi.org/10.1007/978-1-4614-3185-5_63},
  urldate = {2022-10-03},
  abstract = {This chapter begins by reviewing the many definitions of the term open educational resources and concludes by discussing challenges and opportunities for the approach. Open educational resources (OER) are educational materials either licensed under an open copyright license or in the public domain. Neither the term ``open educational resources'' nor the term ``open'' itself has an agreed upon definition in the literature. Research regarding open educational resources focuses on methods of producing OER, methods of sharing OER, and the benefits of OER. Significant issues relating to OER remain unresolved, including business model and discovery problems.},
  isbn = {978-1-4614-3185-5},
  langid = {english},
  keywords = {Affordability,Open educational resources,Remix,Reuse}
}

@article{wiliamWhatAssessmentLearning2011,
  title = {What Is Assessment for Learning?},
  author = {Wiliam, Dylan},
  year = {2011},
  month = mar,
  journal = {Studies in Educational Evaluation},
  series = {Assessment for {{Learning}}},
  volume = {37},
  number = {1},
  pages = {3--14},
  issn = {0191-491X},
  doi = {10.1016/j.stueduc.2011.03.001},
  url = {https://www.sciencedirect.com/science/article/pii/S0191491X11000149},
  urldate = {2021-08-10},
  abstract = {The idea that assessment is intrinsic to effective instruction is traced from early experiments in the individualization of learning through the work of Benjamin Bloom to reviews of the impact of feedback on learners in classrooms. While many of these reviews detailed the adverse impact of assessment on learning, they also indicated that under certain conditions assessment had considerable potential to enhance learning. It is shown that understanding the impact that assessment has on learning requires a broader focus than the feedback intervention itself, particularly the learner's responses to the feedback, and the learning milieu in which the feedback operates. Different definitions of the terms ``formative assessment'' and ``assessment for learning'' are discussed, and subsumed within a broad definition that focuses on the extent to which instructional decisions are supported by evidence. The paper concludes by exploring some of the consequences of this definition for classroom practice.},
  langid = {english},
  keywords = {Assessment for learning,Feedback,Formative assessment},
  file = {/home/charlotte/sync/Zotero/storage/SQ4MVMKH/Wiliam - 2011 - What is assessment for learning.pdf;/home/charlotte/sync/Zotero/storage/MKWZ2ECS/S0191491X11000149.html}
}

@article{wilkinsonFAIRGuidingPrinciples2016,
  title = {The {{FAIR Guiding Principles}} for Scientific Data Management and Stewardship},
  author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and {da Silva Santos}, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Merc{\`e} and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and {Gonzalez-Beltran}, Alejandra and Gray, Alasdair J. G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and {'t Hoen}, Peter A. C. and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and {Rocca-Serra}, Philippe and Roos, Marco and {van Schaik}, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and {van der Lei}, Johan and {van Mulligen}, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
  year = {2016},
  month = mar,
  journal = {Scientific Data},
  volume = {3},
  number = {1},
  pages = {160018},
  publisher = {{Nature Publishing Group}},
  issn = {2052-4463},
  doi = {10.1038/sdata.2016.18},
  url = {https://www.nature.com/articles/sdata201618},
  urldate = {2021-08-24},
  abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders---representing academia, industry, funding agencies, and scholarly publishers---have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
  copyright = {2016 The Author(s)},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Comments \& Opinion Subject\_term: Publication characteristics;Research data Subject\_term\_id: publication-characteristics;research-data},
  file = {/home/charlotte/sync/Zotero/storage/46MUMICP/Wilkinson et al. - 2016 - The FAIR Guiding Principles for scientific data ma.pdf;/home/charlotte/sync/Zotero/storage/ZRCAWIZQ/sdata201618.html}
}

@article{williamsSupportPairProgramming2002,
  title = {In {{Support}} of {{Pair Programming}} in the {{Introductory Computer Science Course}}},
  author = {Williams, Laurie and Wiebe, Eric and Yang, Kai and Ferzli, Miriam and Miller, Carol},
  year = {2002},
  month = sep,
  journal = {Computer Science Education},
  volume = {12},
  number = {3},
  pages = {197--212},
  publisher = {{Routledge}},
  issn = {0899-3408},
  doi = {10.1076/csed.12.3.197.8618},
  url = {https://doi.org/10.1076/csed.12.3.197.8618},
  urldate = {2022-08-16},
  abstract = {A formal pair programming experiment was run at North Carolina to empirically assess the educational efficacy of the technique in a CS1 course. Results indicate that students who practice pair programming perform better on programming projects and are more likely to succeed by completing the class with a C or better. Student pairs are more self-sufficient which reduces their reliance on the teaching staff. Qualitatively, paired students demonstrate higher order thinking skills than students who work alone. These results are supportive of pair programming as a collaborative learning technique.}
}

@article{wingComputationalThinking2006,
  title = {Computational Thinking},
  author = {Wing, Jeannette M},
  year = {2006},
  journal = {Communications of the ACM},
  volume = {49},
  number = {3},
  pages = {33--35},
  publisher = {{ACM New York, NY, USA}}
}

@article{winstoneItBeUseful2017,
  title = {`{{It}}'d Be Useful, but {{I}} Wouldn't Use It': Barriers to University Students' Feedback Seeking and Recipience},
  shorttitle = {`{{It}}'d Be Useful, but {{I}} Wouldn't Use It'},
  author = {Winstone, Naomi E. and Nash, Robert A. and Rowntree, James and Parker, Michael},
  year = {2017},
  month = nov,
  journal = {Studies in Higher Education},
  volume = {42},
  number = {11},
  pages = {2026--2041},
  publisher = {{Routledge}},
  issn = {0307-5079},
  doi = {10.1080/03075079.2015.1130032},
  url = {https://doi.org/10.1080/03075079.2015.1130032},
  urldate = {2022-03-04},
  abstract = {For feedback to be effective, it must be used by the receiver. Prior research has outlined numerous reasons why students' use of feedback is sometimes limited, but there has been little systematic exploration of these barriers. In 11 activity-oriented focus groups, 31 undergraduate Psychology students discussed how they use assessment feedback. The data revealed many barriers that inhibit use of feedback, ranging from students' difficulties with decoding terminology, to their unwillingness to expend effort. Thematic analysis identified four underlying psychological processes: awareness, cognisance, agency, and volition. We argue that these processes should be considered when designing interventions to encourage students' engagement with feedback. Whereas the barriers identified could all in principle be removed, we propose that doing so would typically require -- or would at least benefit from -- a sharing of responsibility between teacher and student. The data highlight the importance of training students to be proactive receivers of feedback.},
  keywords = {communication,feedback,focus groups,interventions,proactivity,student engagement},
  file = {/home/charlotte/sync/Zotero/storage/YAYDZ6ZE/Winstone et al. - 2017 - ‘It'd be useful, but I wouldn't use it’ barriers .pdf;/home/charlotte/sync/Zotero/storage/5RVZ6F2W/03075079.2015.html}
}

@inproceedings{woitEffectivenessOnlineAssessment2003,
  title = {Effectiveness of Online Assessment},
  booktitle = {Proceedings of the 34th {{SIGCSE}} Technical Symposium on {{Computer}} Science Education},
  author = {Woit, Denise and Mason, David},
  year = {2003},
  month = jan,
  series = {{{SIGCSE}} '03},
  pages = {137--141},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/611892.611952},
  url = {https://doi.org/10.1145/611892.611952},
  urldate = {2022-08-16},
  abstract = {For five academic years we have engaged in an on-going study of the effectiveness of online assessment of student programming abilities for introductory programming courses in Computer Science. Our results show that online evaluation can be implemented securely, efficiently, and can result in increased student motivation and programming efficacy; however, unless online components are integrated throughout the course evaluations, student competence will be underestimated. Our data reveals disadvantages of online evaluations, but also shows that both students and faculty benefit when online evaluations are implemented appropriately.},
  isbn = {978-1-58113-648-7},
  keywords = {comparative study,evaluation styles},
  file = {/home/charlotte/sync/Zotero/storage/UA4MW7HZ/Woit and Mason - 2003 - Effectiveness of online assessment.pdf}
}

@article{woottonEncouragingLearningMeasuring2002,
  title = {Encouraging {{Learning}} or {{Measuring Failure}}?},
  author = {Wootton, Sally},
  year = {2002},
  month = jul,
  journal = {Teaching in Higher Education},
  volume = {7},
  number = {3},
  pages = {353--357},
  publisher = {{Routledge}},
  issn = {1356-2517},
  doi = {10.1080/13562510220144833},
  url = {https://doi.org/10.1080/13562510220144833},
  urldate = {2022-08-16},
  abstract = {This paper calls for a debate on effects that the current education system is having on our learners. Many students entering Higher Education struggle to rise to its rigorous academic demands. The need for support services is on the increase with greater focus on key skills, study skills and self-management. Students undertaking higher study can face financial hardship and emotional turmoil in striving to achieve, but the problems do not start here. Much of the trepidation felt by students comes as a result of earlier educational experiences, and is merely exacerbated as their learning experience progresses. It is time to re-assess the whole educational process and to question whether the system exists to encourage learning or to measure failure.}
}

@article{xingDropoutPredictionMOOCs2019,
  title = {Dropout {{Prediction}} in {{MOOCs}}: {{Using Deep Learning}} for {{Personalized Intervention}}},
  shorttitle = {Dropout {{Prediction}} in {{MOOCs}}},
  author = {Xing, Wanli and Du, Dongping},
  year = {2019},
  month = jun,
  journal = {Journal of Educational Computing Research},
  volume = {57},
  number = {3},
  pages = {547--570},
  publisher = {{SAGE Publications Inc}},
  issn = {0735-6331},
  doi = {10.1177/0735633118757015},
  url = {https://doi.org/10.1177/0735633118757015},
  urldate = {2021-09-16},
  abstract = {Massive open online courses (MOOCs) show great potential to transform traditional education through the Internet. However, the high attrition rates in MOOCs have often been cited as a scale-efficacy tradeoff. Traditional educational approaches are usually unable to identify such large-scale number of at-risk students in danger of dropping out in time to support effective intervention design. While building dropout prediction models using learning analytics are promising in informing intervention design for these at-risk students, results of the current prediction model construction methods do not enable personalized intervention for these students. In this study, we take an initial step to optimize the dropout prediction model performance toward intervention personalization for at-risk students in MOOCs. Specifically, based on a temporal prediction mechanism, this study proposes to use the deep learning algorithm to construct the dropout prediction model and further produce the predicted individual student dropout probability. By taking advantage of the power of deep learning, this approach not only constructs more accurate dropout prediction models compared with baseline algorithms but also comes up with an approach to personalize and prioritize intervention for at-risk students in MOOCs through using individual drop out probabilities. The findings from this study and implications are then discussed.},
  langid = {english},
  keywords = {deep learning,dropout prediction,intervention,machine learning,MOOCs,personalization},
  file = {/home/charlotte/sync/Zotero/storage/KZU22XRH/Xing and Du - 2019 - Dropout Prediction in MOOCs Using Deep Learning f.pdf}
}

@article{xuArtificialIntelligenceConstructing2023,
  title = {Artificial Intelligence in Constructing Personalized and Accurate Feedback Systems for Students},
  author = {Xu, Wenzhong and Meng, Jun and Raja, S. Kanaga Suba and Priya, M. Padma and Kiruthiga Devi, M.},
  year = {2023},
  month = feb,
  journal = {International Journal of Modeling, Simulation, and Scientific Computing},
  volume = {14},
  number = {01},
  pages = {2341001},
  publisher = {{World Scientific Publishing Co.}},
  issn = {1793-9623},
  doi = {10.1142/S1793962323410015},
  url = {https://www.worldscientific.com/doi/abs/10.1142/S1793962323410015},
  urldate = {2024-01-10},
  abstract = {Artificial Intelligence (AI) systems have evolved with digital learning developments to provide thriving soft groups with digital opportunities in response to feedback. When it comes to learning environments, educators' training feedback is often used as a response recourse. Through the use of final evaluations, students receive feedback that improves their education abilities. To improve academic achievement and explore knowledge in the learning process, this section provides an AI-assisted personalized feedback system (AI-PFS). An individualized feedback system is implemented to learn more about the student's lack of academic experience interactivity and different collaboration behaviors. According to their benchmark, PFS aims to establish a personalized and reliable feedback process for each class based on their collaborative process and learn analytics modules. It has been proposed to use multi-objective implementations to evaluate students regarding the learning results and teaching methods. With different series of questions sessions for students, AI-PFS has been designed, and the findings showed that it greatly enhances the performance rate of 95.32\% with personalized and reasonable predictive.},
  keywords = {artificial intelligence,feedback system,Students feedback},
  file = {/home/charlotte/sync/Zotero/storage/45YZ53JJ/Xu et al. - 2023 - Artificial intelligence in constructing personaliz.pdf}
}

@article{yangFacilitatingInteractionsStructured2008,
  title = {Facilitating Interactions through Structured Web-Based Bulletin Boards: {{A}} Quasi-Experimental Study on Promoting Learners' Critical Thinking Skills},
  shorttitle = {Facilitating Interactions through Structured Web-Based Bulletin Boards},
  author = {Yang, Ya-Ting C. and Newby, Timothy and Bill, Robert},
  year = {2008},
  month = may,
  journal = {Computers \& Education},
  volume = {50},
  number = {4},
  pages = {1572--1585},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2007.04.006},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131507000255},
  urldate = {2021-09-15},
  abstract = {This experimental study investigated the effectiveness of structured Web-Based Bulletin Board (WBB) discussions in improving the critical thinking (CT) skills of learners involved in veterinary distance learning, as well as their attitudes toward learning via WBBs. The two dependent variables were learners' CT skills and their attitudes toward learning via WBBs. The learners' CT skills were examined in different ways: (a) quantitative method: California Critical Thinking Skills Test (CCTST) to holistically investigate the changes in learners' CT skills, and (b) qualitative method: Interaction Analysis Model to investigate learners' interaction patterns in different phases of the WBB discussions. Detailed information about inter-rater reliability, the training of the coders, and the coding process is provided. The findings indicated that structured WBBs significantly improved learners' CT skills and attitudes toward learning via WBBs.},
  langid = {english},
  keywords = {Computer-mediated communication,Distance education,Interactive learning environments,Teaching/learning strategies},
  file = {/home/charlotte/sync/Zotero/storage/DENFTDX5/Yang et al. - 2008 - Facilitating interactions through structured web-b.pdf;/home/charlotte/sync/Zotero/storage/2BFNCHLD/S0360131507000255.html}
}

@inproceedings{yangPropertyDifferencingIncremental2014,
  title = {Property Differencing for Incremental Checking},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Software Engineering}}},
  author = {Yang, Guowei and Khurshid, Sarfraz and Person, Suzette and Rungta, Neha},
  year = {2014},
  month = may,
  series = {{{ICSE}} 2014},
  pages = {1059--1070},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2568225.2568319},
  url = {https://doi.org/10.1145/2568225.2568319},
  urldate = {2022-06-30},
  abstract = {This paper introduces iProperty, a novel approach that facilitates incremental checking of programs based on a property differencing technique. Specifically, iProperty aims to reduce the cost of checking properties as they are initially developed and as they co-evolve with the program. The key novelty of iProperty is to compute the differences between the new and old versions of expected properties to reduce the number and size of the properties that need to be checked during the initial development of the properties. Furthermore, property differencing is used in synergy with program behavior differencing techniques to optimize common regression scenarios, such as detecting regression errors or checking feature additions for conformance to new expected properties. Experimental results in the context of symbolic execution of Java programs annotated with properties written as assertions show the effectiveness of iProperty in utilizing change information to enable more efficient checking.},
  isbn = {978-1-4503-2756-5},
  keywords = {assertions,change-impact analysis,Daikon,Incremental symbolic execution,Symbolic PathFinder},
  file = {/home/charlotte/sync/Zotero/storage/X8Q8HMNN/Yang et al. - 2014 - Property differencing for incremental checking.pdf}
}

@inproceedings{yanImpactIterativeAssessment2020,
  title = {The {{Impact}} of {{Iterative Assessment System}} on {{Programming Learning Behavior}}},
  booktitle = {Proceedings of the 2020 9th {{International Conference}} on {{Educational}} and {{Information Technology}}},
  author = {Yan, Yi-Xiang and Wu, Jung-Pin and Nguyen, Bao-An and Chen, Hsi-Min},
  year = {2020},
  month = apr,
  series = {{{ICEIT}} 2020},
  pages = {89--94},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3383923.3383939},
  url = {https://dl.acm.org/doi/10.1145/3383923.3383939},
  urldate = {2023-08-21},
  abstract = {Automated programming assessment systems (APAS) are useful supporting tools adopted in novice programming courses. They allow educators to reduce the amount of work required for homework assessment as well as students to have feedback and correct their code. In this study, we analyzed students' learning behavior from an APAS, called ProgEdu, which provides an iterative learning environment for object-oriented programming courses. Answers to research questions are obtained by mean of a quantitative research. Analysis results showed that all expectations about the system effectiveness are satisfied: 1) almost students agree with the assessment method and feedback given by the system; 2) iterative learning is helpful in improving students' programming skill; 3) and it facilitates students to pay more attention to code quality. This study also points out issues of the current system and propose suggestions to improve system performance.},
  isbn = {978-1-4503-7508-5},
  keywords = {Automated programming assessment system,code quality,immediate feedback,iterative learning,Java programming},
  file = {/home/charlotte/sync/Zotero/storage/SS82JQE4/Yan et al. - 2020 - The Impact of Iterative Assessment System on Progr.pdf}
}

@article{yourdonStructuredDesignFundamentals1979,
  title = {Structured Design. {{Fundamentals}} of a Discipline of Computer Program and Systems Design},
  author = {Yourdon, Edward and Constantine, Larry L.},
  year = {1979},
  journal = {Englewood Cliffs: Yourdon Press},
  url = {https://ui.adsabs.harvard.edu/abs/1979sdfd.book.....Y/abstract},
  urldate = {2022-08-16},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/9GD5BKV2/abstract.html}
}

@inproceedings{zakiEfficientlyMiningFrequent2002,
  title = {Efficiently Mining Frequent Trees in a Forest},
  booktitle = {Proceedings of the Eighth {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining},
  author = {Zaki, Mohammed J.},
  year = {2002},
  month = jul,
  series = {{{KDD}} '02},
  pages = {71--80},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/775047.775058},
  url = {https://doi.org/10.1145/775047.775058},
  urldate = {2022-09-01},
  abstract = {Mining frequent trees is very useful in domains like bioinformatics, web mining, mining semistructured data, and so on. We formulate the problem of mining (embedded) subtrees in a forest of rooted, labeled, and ordered trees. We present TREEMINER, a novel algorithm to discover all frequent subtrees in a forest, using a new data structure called scope-list. We contrast TREEMINER with a pattern matching tree mining algorithm (PATTERNMATCHER). We conduct detailed experiments to test the performance and scalability of these methods. We find that TREEMINER outperforms the pattern matching approach by a factor of 4 to 20, and has good scaleup properties. We also present an application of tree mining to analyze real web logs for usage patterns.},
  isbn = {978-1-58113-567-1},
  file = {/home/charlotte/sync/Zotero/storage/5M2WBIXQ/Zaki - 2002 - Efficiently mining frequent trees in a forest.pdf}
}

@article{zakiEfficientlyMiningFrequent2005,
  title = {Efficiently Mining Frequent Trees in a Forest: Algorithms and Applications},
  shorttitle = {Efficiently Mining Frequent Trees in a Forest},
  author = {Zaki, M.J.},
  year = {2005},
  month = aug,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {17},
  number = {8},
  pages = {1021--1035},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2005.125},
  abstract = {Mining frequent trees is very useful in domains like bioinformatics, Web mining, mining semistructured data, etc. We formulate the problem of mining (embedded) subtrees in a forest of rooted, labeled, and ordered trees. We present TREEMINER, a novel algorithm to discover all frequent subtrees in a forest, using a new data structure called scope-list. We contrast TREEMINER with a pattern matching tree mining algorithm (PATTERNMATCHER), and we also compare it with TREEMINERD, which counts only distinct occurrences of a pattern. We conduct detailed experiments to test the performance and scalability of these methods. We also use tree mining to analyze RNA structure and phylogenetics data sets from bioinformatics domain.},
  keywords = {Bioinformatics,Data mining,data mining.,Databases,Index Terms- Frequent tree mining,labeled trees,ordered,pattern matching,Pattern matching,phylogenetic trees,Phylogeny,RNA,RNA structure,rooted,subtree enumeration,Testing,Tree data structures,Tree graphs,Web mining},
  file = {/home/charlotte/sync/Zotero/storage/P3K9NEA3/Zaki - 2005 - Efficiently mining frequent trees in a forest alg.pdf;/home/charlotte/sync/Zotero/storage/YWH4E4NN/1458697.html}
}

@article{zhidkikhReproducingPredictiveLearning2024,
  title = {Reproducing {{Predictive Learning Analytics}} in {{CS1}}: {{Toward Generalizable}} and {{Explainable Models}} for {{Enhancing Student Retention}}},
  shorttitle = {Reproducing {{Predictive Learning Analytics}} in {{CS1}}},
  author = {Zhidkikh, Denis and Heilala, Ville and Van Petegem, Charlotte and Dawyndt, Peter and J{\"a}rvinen, Miitta and Viitanen, Sami and De Wever, Bram and Mesuere, Bart and Lappalainen, Vesa and Kettunen, Lauri and H{\"a}m{\"a}l{\"a}inen, Raija},
  year = {2024},
  month = jan,
  journal = {Journal of Learning Analytics},
  pages = {1--21},
  issn = {1929-7750},
  doi = {10.18608/jla.2024.7979},
  url = {https://learning-analytics.info/index.php/JLA/article/view/7979},
  urldate = {2024-01-29},
  abstract = {Predictive learning analytics has been widely explored in educational research to improve student retention and academic success in an introductory programming course in computer science (CS1). General-purpose and interpretable dropout predictions still pose a challenge. Our study aims to reproduce and extend the data analysis of a privacy-first student pass--fail prediction approach proposed by Van Petegem and colleagues (2022) in a different CS1 course. Using student submission and self-report data, we investigated the reproducibility of the original approach, the effect of adding self-reports to the model, and the interpretability of the model features. The results showed that the original approach for student dropout prediction could be successfully reproduced in a different course context and that adding self-report data to the prediction model improved accuracy for the first four weeks. We also identified relevant features associated with dropout in the CS1 course, such as timely submission of tasks and iterative problem solving. When analyzing student behaviour, submission data and self-report data were found to complement each other. The results highlight the importance of transparency and generalizability in learning analytics and the need for future research to identify other factors beyond self-reported aptitude measures and student behaviour that can enhance dropout prediction.},
  copyright = {Copyright (c) 2024 Journal of Learning Analytics},
  langid = {english},
  keywords = {research paper},
  file = {/home/charlotte/sync/Zotero/storage/8XEPDBJY/Zhidkikh et al. - 2024 - Reproducing Predictive Learning Analytics in CS1 .pdf}
}

@article{zinovievaUseOnlineCoding2021,
  title = {The Use of Online Coding Platforms as Additional Distance Tools in Programming Education},
  author = {Zinovieva, I. S. and Artemchuk, V. O. and Iatsyshyn, Anna V. and Popov, O. O. and Kovach, V. O. and Iatsyshyn, Andrii V. and Romanenko, Y. O. and Radchenko, O. V.},
  year = {2021},
  month = mar,
  journal = {Journal of Physics: Conference Series},
  volume = {1840},
  number = {1},
  pages = {012029},
  publisher = {{IOP Publishing}},
  issn = {1742-6596},
  doi = {10.1088/1742-6596/1840/1/012029},
  url = {https://dx.doi.org/10.1088/1742-6596/1840/1/012029},
  urldate = {2023-10-02},
  abstract = {This study analyzes various publications of scientists on the training of future IT specialists and the features of training programming using online simulators. The authors of the article made a comparative description of different online platforms for teaching programming according to certain criteria, selected interesting tasks from the online platform hackerrank.com, which have already been used to teach students. Online programming simulators have significant potential in organizing an effective distance learning system in Ukrainian universities. It is important to use online simulators in the learning process as an additional tool for the formation of professional competencies, which provides more intensive involvement of students in the process of writing code and practical (situational) application of existing knowledge. Gamification of the process of training future IT specialists helps to increase cognitive activity, and hence -- the quality of the educational process and distance learning in particular. The authors recommend the use of online programming simulators as an additional tool for teaching computer science disciplines, taking into account their functionality, as well as the level of preparation of students and the expected learning outcomes.},
  langid = {english},
  file = {/home/charlotte/sync/Zotero/storage/PHEIIZ9J/Zinovieva et al. - 2021 - The use of online coding platforms as additional d.pdf}
}
